import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from utils import compress_image_to_jpeg, convert_image_to_base64, compress_full_document 
from models import graph_classify_llm, vision_llm, script_llm
from fastapi import UploadFile
from PIL import Image
from langchain.schema import SystemMessage, HumanMessage
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from typing import List
import fitz
import re
import base64

class PDFProcessor:
    def __init__(self, pdf_file: UploadFile):
        self.pdf_file = pdf_file
        self.pdf_data = []
        self.doc = fitz.open(stream=pdf_file.file.read(), filetype="pdf")

    def get_total_image_area_ratio(self,page, images):
        """í˜ì´ì§€ì—ì„œ ê°ì§€ëœ ëª¨ë“  ì´ë¯¸ì§€ì˜ ì´ ë©´ì  ë¹„ìœ¨ì„ ê³„ì‚°."""
        total_ratio = 0
        for img in images:
            xref = img[0]
            img_rects = page.get_image_rects(xref)
            if img_rects:
                x0, y0, x1, y1 = img_rects[0]
                img_width = x1 - x0
                img_height = y1 - y0
                img_area = img_width * img_height
                
                page_width, page_height = page.rect.width, page.rect.height
                page_area = page_width * page_height
                
                total_ratio += img_area / page_area
        
        return total_ratio

    def classify_image_type(self, image_bytes):
        """ì´ë¯¸ì§€ê°€ ë„í‘œ/ê·¸ë˜í”„ ë¶„ë¥˜"""
        llm = graph_classify_llm()

        # âœ… ì••ì¶•í•´ì„œ base64 ìš©ëŸ‰ ì¤„ì´ê¸°
        compressed_bytes = compress_image_to_jpeg(image_bytes, quality=50)
        base64_image = convert_image_to_base64(compressed_bytes)

        prompt = (
            "ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ ì•„ë˜ ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:\n"
            "1. ê·¸ë˜í”„/ë„í‘œ\n"
            "2. ê·¸ì™¸\n"
            "ë°˜ë“œì‹œ ìœ„ ì¤‘ í•˜ë‚˜ì˜ í•­ëª©ë§Œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”."
        )

        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ë¶„ë¥˜ ì „ë¬¸ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤."),
            HumanMessage(content=[
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
            ])
        ]

        response = llm.invoke(messages)
        label = response.content.strip()
        return label == "ê·¸ë˜í”„/ë„í‘œ"
    
    def should_interpret_image(self,image_bytes, total_area_ratio):
        """ì´ë¯¸ì§€ í•´ì„ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜."""
        # ë¨¼ì € ë©´ì  ë¹„ìœ¨ í™•ì¸
        if total_area_ratio >= 0.5:
            return True
        
        # ë©´ì  ë¹„ìœ¨ì´ 0.5 ë¯¸ë§Œì¸ ê²½ìš°ì—ë§Œ LLMìœ¼ë¡œ ê·¸ë˜í”„/ë„í‘œ ì—¬ë¶€ í™•ì¸
        is_graph_or_chart = self.classify_image_type(image_bytes)
        return is_graph_or_chart    
    
    def extract_page(self):
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì¶”ì¶œ."""
        doc = self.doc
        total_pages = len(doc)
        pdf_data = []

        for page_num in range(total_pages):
            page = doc[page_num]
            text = page.get_text("text")
            images = page.get_images(full=True)
            image_data = []

            # í˜ì´ì§€ì˜ ì´ ì´ë¯¸ì§€ ë©´ì  ë¹„ìœ¨ ê³„ì‚°
            total_area_ratio = self.get_total_image_area_ratio(page, images)

            for img in images:
                xref = img[0]
                img_rects = page.get_image_rects(xref)
                
                if img_rects:
                    # ì´ë¯¸ì§€ ì¶”ì¶œ
                    pix = fitz.Pixmap(doc, xref)
                    if pix.n > 4:  # CMYKë¥¼ RGBë¡œ ë³€í™˜
                        pix = fitz.Pixmap(fitz.csRGB, pix)
                    
                    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
                    img_bytes = pix.tobytes()
                    img_base64 = convert_image_to_base64(img_bytes)
                    
                    # ì´ë¯¸ì§€ í•´ì„ ì—¬ë¶€ ê²°ì • (ë©´ì  ë¹„ìœ¨ ë¨¼ì € í™•ì¸ í›„ í•„ìš”ì‹œ LLM ì‚¬ìš©)
                    should_interpret = self.should_interpret_image(img_bytes, total_area_ratio)
                    
                    image_data.append({
                        "image": img_base64,
                        "image_type": should_interpret
                    })
                    
                    pix = None  # ë©”ëª¨ë¦¬ í•´ì œ

            pdf_data.append({
                "page": page_num + 1,
                "text": text,
                "images": image_data
            })
        self.pdf_data = pdf_data
        return pdf_data
    
    def filter_important_images(self):
        """
        PDF ë°ì´í„°ì—ì„œ í•´ì„ì´ í•„ìš”í•œ ì´ë¯¸ì§€(image_typeì´ True)ë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜
        í˜ì´ì§€ëŠ” ëª¨ë‘ ìœ ì§€í•˜ê³  ì´ë¯¸ì§€ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
        """
        filtered_data = []
        
        for page_info in self.pdf_data:
            # image_typeì´ Trueì¸ ì´ë¯¸ì§€ë§Œ í•„í„°ë§
            important_images = [img for img in page_info['images'] if img['image_type']]
            
            # ëª¨ë“  í˜ì´ì§€ë¥¼ í¬í•¨í•˜ë˜, í•„í„°ë§ëœ ì´ë¯¸ì§€ë§Œ í¬í•¨
            filtered_data.append({
                "page": page_info['page'],
                "text": page_info['text'],
                "images": important_images  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ê°€ ë  ìˆ˜ë„ ìˆìŒ
            })
        
        self.pdf_data = filtered_data
        return self.pdf_data
    
class Generate_Script(PDFProcessor):
    def __init__(self, pdf_file: UploadFile, full_document: str):
        super().__init__(pdf_file)
        self.full_document = compress_full_document(full_document)
        self.llm = script_llm()
        self.vision_llm = vision_llm()
        self.previous_script: List[str] = []

        # Buffer memory ì ìš©
        self.memory = ConversationBufferMemory(return_messages=True)
        self.conversation = ConversationChain(
            llm=self.llm,
            memory=self.memory,
            verbose=False
        )

        self.system_msg = SystemMessage(
            content=(
                "ë‹¹ì‹ ì€ ë°œí‘œ ëŒ€ë³¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°œí‘œìëŠ” ì—¬ëŸ¬ ì¥ì˜ ìŠ¬ë¼ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë°œí‘œë¥¼ í•©ë‹ˆë‹¤.\n"
                "- ì˜¤ì§ ì²« ë²ˆì§¸ í˜ì´ì§€ì—ì„œë§Œ ì¸ì‚¬ë¥¼ í•©ë‹ˆë‹¤.\n"
                "- ê° í˜ì´ì§€ëŠ” ì´ì „ ë°œí‘œì™€ ì´ì–´ì§€ëŠ” íë¦„ì˜ ì¼ë¶€ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n"
                "- í˜„ì¬ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë°˜ì˜í•´ì•¼ í•˜ë©°, í•µì‹¬ ë‚´ìš©ì„ ê°•ì¡°í•˜ì‹­ì‹œì˜¤.\n"
                "- ì „ì²´ ë¬¸ì„œ ë‚´ìš©ê³¼ ì´ì „ í˜ì´ì§€ ëŒ€ë³¸ì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤.\n"
                "- ìŠ¬ë¼ì´ë“œê°€ ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ 'ë§ˆì§€ë§‰ìœ¼ë¡œ', 'ëìœ¼ë¡œ' ë“±ì˜ í‘œí˜„ë„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                "- ë°˜ë“œì‹œ [ìŠ¬ë¼ì´ë“œ n] í˜•ì‹ìœ¼ë¡œ ê° ìŠ¬ë¼ì´ë“œ ì‹œì‘ì„ ëª…ì‹œí•˜ê³ , ìŠ¬ë¼ì´ë“œ ìˆ˜ì— ë§ê²Œ ì •í™•íˆ ì‘ì„±í•˜ì„¸ìš”."
            )
        )

    def image_analysis(self, page_idx: int) -> str:
        page_data = self.pdf_data[page_idx]
        images = page_data["images"]
        image_descriptions = []

        for image in images:
            if image["image_type"]:
                # âœ… ì´ë¯¸ì§€ base64ë¥¼ ë‹¤ì‹œ ë””ì½”ë”©í•´ì„œ ì••ì¶• ì²˜ë¦¬
                image_bytes = base64.b64decode(image["image"])
                compressed_bytes = compress_image_to_jpeg(image_bytes, quality=50)
                compressed_base64 = convert_image_to_base64(compressed_bytes)

                template = """
                ë‹¤ìŒì€ ë°œí‘œ ìë£Œì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤:
                - ì „ì²´ ë¬¸ì„œ ìš”ì•½: {full_document}
                - í˜„ì¬ í˜ì´ì§€ í…ìŠ¤íŠ¸: {page_text}
                - ì´ë¯¸ì§€(base64): {image}

                ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì´ ì´ë¯¸ì§€ë¥¼ ë°œí‘œìê°€ ì–´ë–»ê²Œ ì„¤ëª…í• ì§€ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
                prompt = PromptTemplate.from_template(template)
                image_desc = self.vision_llm.invoke(prompt.format(
                    full_document=self.full_document,
                    page_text=page_data["text"],
                    image=compressed_base64
                ))
                image_descriptions.append(image_desc.content.strip())  # âœ… í•µì‹¬ ìˆ˜ì •

        return '\n'.join(image_descriptions) if image_descriptions else ""

    def generate_script(self, page_idx: int) -> str:
        page_data = self.pdf_data[page_idx]
        text = page_data["text"]
        image_descriptions = self.image_analysis(page_idx)
        previous_script_text = "\n".join(self.previous_script[-2:]) if self.previous_script else "ì—†ìŒ"

        prompt_text = f"""
    [ìŠ¬ë¼ì´ë“œ {page_idx + 1}]

    ë‹¤ìŒì€ ë°œí‘œ ìë£Œì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤:
    - ì „ì²´ ë¬¸ì„œ ìš”ì•½ (ì°¸ê³ ìš©): {self.full_document}
    - í˜„ì¬ ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸: {text}
    - ì´ë¯¸ì§€ ì„¤ëª…: {image_descriptions}
    - ì§ì „ ë°œí‘œ ë‚´ìš© (ì°¸ê³ ìš©): {previous_script_text}

    ë°œí‘œìëŠ” í˜„ì¬ ìŠ¬ë¼ì´ë“œë¥¼ **í˜¼ìì„œ ì„¤ëª…**í•˜ëŠ” ìƒí™©ì…ë‹ˆë‹¤.

    â— ë°˜ë“œì‹œ í˜„ì¬ ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    â— ë‹¤ìŒ ìŠ¬ë¼ì´ë“œì— ë‚˜ì˜¬ ë‚´ìš©ì„ ë¯¸ë¦¬ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”.
    â— ë°œí‘œ íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ë˜, **ë¯¸ë¦¬ ê²°ë¡  ë‚´ë¦¬ì§€ ë§ˆì„¸ìš”.**
    â— ëŒ€ë³¸ì€ 3~5ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê³ , ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

    ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

        input_text = f"{self.system_msg.content}\n\n{prompt_text}"
        response = self.conversation.predict(input=input_text)
        script = response.strip()

        self.previous_script.append(script)
        return script

    def generate_full_script(self, chunk_size: int = 5) -> List[str]:
        all_scripts = []
        total_pages = len(self.pdf_data)
        chunks = [self.pdf_data[i:i + chunk_size] for i in range(0, total_pages, chunk_size)]

        for chunk_idx, chunk_pages in enumerate(chunks):
            pages_text = []
            is_last_chunk = (chunk_idx == len(chunks) - 1)

            for page in chunk_pages:
                page_number = page["page"]
                text = page["text"].strip()
                image_summaries = []

                for img in page["images"]:
                    if img["image_type"]:
                        image_prompt = PromptTemplate.from_template("""
                        ì•„ë˜ ìŠ¬ë¼ì´ë“œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, ë°œí‘œìê°€ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.
                        - ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸: {page_text}
                        """)
                        image_desc = self.vision_llm.invoke(image_prompt.format(page_text=text)).content.strip()
                        image_summaries.append(image_desc)

                combined = f"[ìŠ¬ë¼ì´ë“œ {page_number} / ì´ {total_pages} ìŠ¬ë¼ì´ë“œ ì¤‘]\n- í…ìŠ¤íŠ¸: {text}\n- ì´ë¯¸ì§€ ì„¤ëª…: {' / '.join(image_summaries)}"
                pages_text.append(combined)

            combined_text = "\n\n".join(pages_text)

            system_msg_content = (
                "ë‹¹ì‹ ì€ ë°œí‘œ ëŒ€ë³¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ì—¬ëŸ¬ ìŠ¬ë¼ì´ë“œ ë‚´ìš©ì…ë‹ˆë‹¤.\n"
                "- ê° í˜ì´ì§€ë§ˆë‹¤ '[ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸]' í˜•ì‹ìœ¼ë¡œ ìŠ¬ë¼ì´ë“œ êµ¬ë¶„ì„ ëª…í™•íˆ í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
                "- ìŠ¬ë¼ì´ë“œëŠ” ì´ {total_pages}ê°œì…ë‹ˆë‹¤. ì •í™•íˆ {total_pages}ê°œì˜ ìŠ¬ë¼ì´ë“œë§Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n"
                "- ì²« ë²ˆì§¸ í˜ì´ì§€ë§Œ ì¸ì‚¬ë¥¼ í¬í•¨í•˜ì„¸ìš”.\n"
                "- ë°œí‘œ íë¦„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ì‘ì„±í•˜ì„¸ìš”.\n"
                "- ì´ chunkëŠ” ì „ì²´ ë°œí‘œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ chunkì—ì„œ ë°œí‘œë¥¼ ë§ˆì¹˜ì§€ ë§ˆì„¸ìš”.\n"
                "- 'ì´ìƒìœ¼ë¡œ ë°œí‘œë¥¼ ë§ˆì¹©ë‹ˆë‹¤', 'ê°ì‚¬í•©ë‹ˆë‹¤' ë“±ì˜ ë§ˆë¬´ë¦¬ ë©˜íŠ¸ë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.\n"
                "- ìŠ¬ë¼ì´ë“œê°€ ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ 'ë§ˆì§€ë§‰ìœ¼ë¡œ', 'ëìœ¼ë¡œ' ë“±ì˜ í‘œí˜„ë„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
            ).format(total_pages=total_pages)

            if is_last_chunk:
                system_msg_content += (
                    "- ì´ë²ˆ chunkëŠ” ë§ˆì§€ë§‰ ë°œí‘œ ë¶€ë¶„ì´ë¯€ë¡œ, ì—¬ê¸°ì„œë§Œ ë§ˆë¬´ë¦¬ ë©˜íŠ¸ë¥¼ í¬í•¨í•´ë„ ë©ë‹ˆë‹¤.\n"
                )

            prompt_text = f"""
            ë‹¤ìŒì€ ë°œí‘œ ìë£Œ ì¼ë¶€ì…ë‹ˆë‹¤. ê° í˜ì´ì§€ëŠ” ìŠ¬ë¼ì´ë“œ í•˜ë‚˜ì— í•´ë‹¹í•˜ë©°, ë²ˆí˜¸ëŠ” ìˆœì„œì…ë‹ˆë‹¤.

            {combined_text}

            ê° ìŠ¬ë¼ì´ë“œì— ëŒ€í•´ '[ìŠ¬ë¼ì´ë“œ n]' í˜•ì‹ìœ¼ë¡œ ëŒ€ë³¸ì„ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """

            input_text = f"{system_msg_content}\n\n{prompt_text}"
            response = self.conversation.predict(input=input_text)

            scripts = re.split(r"\[ìŠ¬ë¼ì´ë“œ \d+\]", response.strip())
            scripts = [s.strip() for s in scripts if s.strip()]

            if len(scripts) != len(chunk_pages):
                print(f" ê²½ê³ : ìŠ¬ë¼ì´ë“œ ìˆ˜({len(chunk_pages)})ì™€ ìƒì„±ëœ ëŒ€ë³¸ ìˆ˜({len(scripts)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            all_scripts.extend(scripts)

        return all_scripts
    

# import os
# from fastapi import UploadFile
# import io

# # í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
# TEST_PDF_PATH = r"C:\wanted\Lang\Presentation-Agent\data\save_pdf\O3.pdf"  # ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.

# def simulate_upload_file(file_path: str) -> UploadFile:
#     """ë¡œì»¬ PDF íŒŒì¼ì„ UploadFileì²˜ëŸ¼ ì‹œë®¬ë ˆì´ì…˜"""
#     filename = os.path.basename(file_path)
#     with open(file_path, "rb") as f:
#         contents = f.read()
#     file_like = io.BytesIO(contents)
#     upload_file = UploadFile(filename=filename, file=file_like)
#     return upload_file

# def main():
#     print("âœ… PDF íŒŒì¼ ì¤€ë¹„ ì¤‘...")
#     fake_upload = simulate_upload_file(TEST_PDF_PATH)

#     # ì „ì²´ ë¬¸ì„œ ìš”ì•½ì„ ê°„ë‹¨íˆ ì œê³µ
#     with open(r"C:\wanted\Lang\Presentation-Agent\data\txt\presentation_agent.txt", "r", encoding="utf-8") as f:
#         full_doc_summary = f.read()

#     print("âœ… Generate_Script ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
#     generator = Generate_Script(pdf_file=fake_upload, full_document=full_doc_summary)

#     print("ğŸ“„ PDF í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘...")
#     pdf_data = generator.extract_page()
#     print(f"ğŸ“„ ì´ {len(pdf_data)}í˜ì´ì§€ ë¶„ì„ ì™„ë£Œ")

#     for i, page in enumerate(pdf_data):
#         print(f"  - í˜ì´ì§€ {i+1}: í…ìŠ¤íŠ¸ ê¸¸ì´ {len(page['text'])} / ì´ë¯¸ì§€ ìˆ˜: {len(page['images'])}")

#     print("ğŸ” ì¤‘ìš”í•œ ì´ë¯¸ì§€ í•„í„°ë§ ì¤‘...")
#     filtered_data = generator.filter_important_images()
#     for i, page in enumerate(filtered_data):
#         print(f"  - í˜ì´ì§€ {i+1}: í•´ì„ì´ í•„ìš”í•œ ì´ë¯¸ì§€ ìˆ˜: {len(page['images'])}")

#     print("ğŸ§  í˜ì´ì§€ë³„ ë°œí‘œ ëŒ€ë³¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì¤‘...")
#     for idx in range(min(4, len(filtered_data))):
#         print(f"\nğŸ“¢ [ìŠ¬ë¼ì´ë“œ {idx+1}] ëŒ€ë³¸ ìƒì„± ì¤‘...")
#         script = generator.generate_script(idx)
#         print(f"ğŸ™ï¸ ìƒì„±ëœ ëŒ€ë³¸:\n{script}")

#     print("\nğŸ“š ì „ì²´ ë¬¸ì„œ ê¸°ë°˜ ëŒ€ë³¸ ìƒì„± ì¤‘...")
#     full_scripts = generator.generate_full_script(chunk_size=3)
#     for idx, s in enumerate(full_scripts):
#         print(f"\n[ìŠ¬ë¼ì´ë“œ {idx+1}]\n{s}")

# if __name__ == "__main__":
#     main()