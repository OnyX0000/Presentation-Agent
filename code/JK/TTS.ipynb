{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP TTS API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강조할 단어 :  {'기획', '인공지능', 'AI'}\n",
      "[SSML 미리보기]\n",
      "<speak>이제 최초의 발표하는 <prosody pitch=\"+10%\" volume=\"+2dB\"><emphasis level=\"strong\">인공지능!</emphasis></prosody> 모델인 오인용에 대해 소개하겠습니다.</speak>\n",
      "→ output_0.wav\n",
      "\n",
      "output_0.wav 저장 완료\n",
      "\n",
      "[SSML 미리보기]\n",
      "<speak>이 프로젝트는 중요한 내용을 중심으로 발표용 대본을 생성하는 기능을 가지고 있습니다.</speak>\n",
      "→ output_1.wav\n",
      "\n",
      "output_1.wav 저장 완료\n",
      "\n",
      "[SSML 미리보기]\n",
      "<speak><prosody pitch=\"+10%\" volume=\"+2dB\"><emphasis level=\"strong\">AI!</emphasis></prosody> 음성 합성을 활용하여 자동으로 발표할 수 있는 기능을 제공함으로써, 기업, 연구자, 학생 등이 보다 효율적으로 정보를 활용할 수 있게 됩니다.</speak>\n",
      "→ output_2.wav\n",
      "\n",
      "output_2.wav 저장 완료\n",
      "\n",
      "[SSML 미리보기]\n",
      "<speak>이 시스템은 일관된 발표 퀄리티를 유지하며, 발표에 드는 시간을 단축하는 기대 효과를 가지고 있습니다.</speak>\n",
      "→ output_3.wav\n",
      "\n",
      "output_3.wav 저장 완료\n",
      "\n",
      "[SSML 미리보기]\n",
      "<speak>다음은 프로젝트 기획에 대해 설명드리겠습니다.</speak>\n",
      "→ output_4.wav\n",
      "\n",
      "output_4.wav 저장 완료\n",
      "\n",
      "[SSML 미리보기]\n",
      "<speak>이 슬라이드에서는 프로젝트의 전반적인 <prosody pitch=\"+10%\" volume=\"+2dB\"><emphasis level=\"strong\">기획!</emphasis></prosody> 방향과 목표를 간략히 정리하겠습니다.</speak>\n",
      "→ output_5.wav\n",
      "\n",
      "output_5.wav 저장 완료\n",
      "\n",
      "[SSML 미리보기]\n",
      "<speak>프로젝트의 기획은 체계적인 진행을 위해 매우 중요합니다.</speak>\n",
      "→ output_6.wav\n",
      "\n",
      "output_6.wav 저장 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from google.cloud import texttospeech_v1 as tts\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 스크립트와 키워드\n",
    "script = \"\"\"이제 최초의 발표하는 인공지능 모델인 오인용에 대해 소개하겠습니다. 이 프로젝트는 중요한 내용을 중심으로 발표용 대본을 생성하는 기능을 가지고 있습니다. AI 음성 합성을 활용하여 자동으로 발표할 수 있는 기능을 제공함으로써, 기업, 연구자, 학생 등이 보다 효율적으로 정보를 활용할 수 있게 됩니다. 이 시스템은 일관된 발표 퀄리티를 유지하며, 발표에 드는 시간을 단축하는 기대 효과를 가지고 있습니다.\n",
    "\n",
    "다음은 프로젝트 기획에 대해 설명드리겠습니다. 이 슬라이드에서는 프로젝트의 전반적인 기획 방향과 목표를 간략히 정리하겠습니다. 프로젝트의 기획은 체계적인 진행을 위해 매우 중요합니다.\"\"\"\n",
    "input_keywords = [\"인공지능\"]\n",
    "\n",
    "# 문장 및 단어 추출\n",
    "sentences = re.split(r'(?<=[.?!])\\s+', script.strip())\n",
    "tokenized_sentences = [re.findall(r'\\w+', s) for s in sentences]\n",
    "unique_words = sorted(set(word for sent in tokenized_sentences for word in sent))\n",
    "\n",
    "# 임베딩\n",
    "embedder = OpenAIEmbeddings()\n",
    "word_embeddings = embedder.embed_documents(unique_words)\n",
    "keyword_embeddings = [embedder.embed_query(k) for k in input_keywords]\n",
    "\n",
    "# 유사도 기반 상위 3단어 추출 \n",
    "similarities = {}\n",
    "for word, w_emb in zip(unique_words, word_embeddings):\n",
    "    sims = [cosine_similarity([w_emb], [k_emb])[0][0] for k_emb in keyword_embeddings]\n",
    "    similarities[word] = max(sims)\n",
    "\n",
    "top_emphasized_words = {word for word, _ in sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:3]}\n",
    "print('강조할 단어 : ', top_emphasized_words)\n",
    "\n",
    "# SSML 생성 (emphasis + prosody)\n",
    "ssml_outputs = []\n",
    "for idx, sent in enumerate(sentences):\n",
    "    words = re.split(r'(\\W+)', sent)\n",
    "    processed = []\n",
    "    for w in words:\n",
    "        if w in top_emphasized_words:\n",
    "            emphasized = (\n",
    "                f'<prosody pitch=\"+10%\" volume=\"+2dB\">'\n",
    "                f'<emphasis level=\"strong\">{w}!</emphasis>'\n",
    "                f'</prosody>'\n",
    "            )\n",
    "            processed.append(emphasized)\n",
    "        else:\n",
    "            processed.append(w)\n",
    "    ssml = f\"<speak>{''.join(processed).strip()}</speak>\"\n",
    "    ssml_outputs.append((ssml, f\"output_{idx}.wav\"))\n",
    "\n",
    "# Google TTS 요청\n",
    "client = tts.TextToSpeechClient()\n",
    "voice = tts.VoiceSelectionParams(language_code=\"ko-KR\", name=\"ko-KR-Standard-B\") \n",
    "audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.LINEAR16)\n",
    "\n",
    "# WAV 생성\n",
    "for ssml, filename in ssml_outputs:\n",
    "    print(f\"[SSML 미리보기]\\n{ssml}\\n→ {filename}\\n\")\n",
    "    response = client.synthesize_speech(\n",
    "        input=tts.SynthesisInput(ssml=ssml),\n",
    "        voice=voice,\n",
    "        audio_config=audio_config\n",
    "    )\n",
    "    with open(filename, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        print(f\"{filename} 저장 완료\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "할 일 : 전체 대본을 JSON으로 키워드와 함꼐 입력받고 전체 대본에서 유사어 10개를 JSON으로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube 영상에서 WAV 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def time_convert(time_str):\n",
    "    minutes = time_str // 100  \n",
    "    seconds = time_str % 100   \n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "def download_audio(url, save_dir, clip_idx, start=None, end=None):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 확장자 포함된 yt-dlp 저장용 임시 파일 경로\n",
    "    temp_template = os.path.join(save_dir, f\"CTS_temp_{clip_idx}.%(ext)s\")\n",
    "    temp_wav = os.path.join(save_dir, f\"CTS_temp_{clip_idx}.wav\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'outtmpl': temp_template,\n",
    "        'quiet': True,\n",
    "        'force_ipv4': True,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "\n",
    "    # 자르고 저장\n",
    "    audio = AudioSegment.from_file(temp_wav, format=\"wav\")\n",
    "    if start and end:\n",
    "        start_ms = time_convert(start) * 1000\n",
    "        end_ms = time_convert(end) * 1000\n",
    "        audio = audio[start_ms:end_ms]\n",
    "\n",
    "    # 최종 파일명: cheo_1.wav, cheo_2.wav ...\n",
    "    final_path = os.path.join(save_dir, f\"CTS_{clip_idx}.wav\")\n",
    "    audio.export(final_path, format=\"wav\")\n",
    "\n",
    "    os.remove(temp_wav)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://youtu.be/tRn4W5n39U8?si=EGa2PYHHboa2xajA&t=481\"\n",
    "save_dir = \"../../data/test_wav\"\n",
    "audio_data = []\n",
    "start = 0\n",
    "end = 20\n",
    "i = 1 \n",
    "\n",
    "for time in range(480,40000,30):\n",
    "    start += time\n",
    "    end += time\n",
    "    audio = download_audio(\n",
    "        url = url,\n",
    "        save_dir=save_dir,\n",
    "        clip_idx=i,\n",
    "        start=start,\n",
    "        end=end\n",
    "    )\n",
    "    i += 1\n",
    "    audio_data.append(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZONOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\zonos\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "import torch._dynamo  # suppress warning if needed\n",
    "\n",
    "# ❗ phonemizer용 환경변수 설정 (espeak.dll 대응)\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\eSpeak NG\"\n",
    "os.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = r\"C:\\Program Files\\eSpeak NG\\espeak.dll\"\n",
    "\n",
    "# ❗ torch compile 비활성화 (C++ 컴파일러 없이 실행)\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "path = \"../../data/test_wav\"\n",
    "\n",
    "# 모델 불러오기\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# 입력 음성 로드\n",
    "wav, sampling_rate = torchaudio.load(os.path.join(path, \"ma_1_test.wav\"))\n",
    "\n",
    "# 스피커 임베딩 생성\n",
    "speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
    "\n",
    "text = \"\"\"\n",
    "현대 사회에서 *AI* 기술은 빠르게 발전하고 있습니다.\n",
    "우리의 '발표' 능력을 지원하는 시스템이 필요합니다.\n",
    "\"\"\"\n",
    "\n",
    "cond_dict = make_cond_dict(text=text, speaker=speaker, language=\"ko\")\n",
    "conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "wavs = model.autoencoder.decode(codes).cpu()\n",
    "\n",
    "# 원본 저장\n",
    "torchaudio.save(os.path.join(path, \"sample.wav\"), wavs[0], model.autoencoder.sampling_rate)\n",
    "print(\"🔊 sample.wav 생성 완료!\")\n",
    "\n",
    "# # 후처리\n",
    "# sr = model.autoencoder.sampling_rate\n",
    "# audio_np = wavs[0].squeeze().numpy()  # [1, N] → [N] 보장\n",
    "\n",
    "# # 1.3배 빠르게\n",
    "# y_fast = librosa.effects.time_stretch(audio_np, rate=1.3)\n",
    "\n",
    "# # +2 반음\n",
    "# y_shifted = librosa.effects.pitch_shift(y_fast, sr=sr, n_steps=2)\n",
    "\n",
    "# # shape 조정\n",
    "# if y_shifted.ndim == 1:\n",
    "#     y_shifted = np.expand_dims(y_shifted, axis=0)  # → [1, samples]\n",
    "\n",
    "# # numpy → torch\n",
    "# y_tensor = torch.from_numpy(y_shifted).float()  # float32로 맞춤\n",
    "\n",
    "# # 저장\n",
    "# output_path = os.path.join(path, \"fast_pitchup.wav\")\n",
    "# torchaudio.save(output_path, y_tensor, sr)\n",
    "\n",
    "# print(\"⚡ 1.3배 빠르게 + 🎵 피치 +2반음 적용 완료!\")\n",
    "# print(f\"📁 저장 위치: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zero_shot(path,file,text,name, model):\n",
    "    torch.cuda.empty_cache()\n",
    "    wav, sampling_rate = torchaudio.load(os.path.join(path, file))\n",
    "    speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
    "\n",
    "    cond_dict = make_cond_dict(\n",
    "        text = text,\n",
    "        speaker = speaker,\n",
    "        language = \"ko\"\n",
    "    )\n",
    "    conditioning = model.prepare_conditioning(cond_dict)\n",
    "    codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "    wavs = model.autoencoder.decode(codes).cpu()\n",
    "\n",
    "    # 결과 저장\n",
    "    torchaudio.save(os.path.join(path, f\"{name}_zero_shot.wav\"), wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "    # print(\"🔊 zero_shot.wav 생성 완료!\")\n",
    "    # sr = model.autoencoder.sampling_rate\n",
    "    # audio_np = wavs[0].numpy()\n",
    "\n",
    "    # # [1] 1.3배 속도 (tempo)\n",
    "    # y_fast = librosa.effects.time_stretch(audio_np, rate=1.3)\n",
    "\n",
    "    # # [2] +2 반음 pitch up\n",
    "    # y_shifted = librosa.effects.pitch_shift(y_fast, sr=sr, n_steps=2)\n",
    "\n",
    "    # # 저장\n",
    "    # final_out_path = os.path.join(path, f\"{name}_fast_pitchup.wav\")\n",
    "    # sf.write(final_out_path, y_shifted, sr)\n",
    "\n",
    "\n",
    "def few_shot(path, data, text, name, model):\n",
    "    '''few-shot 보이스 클리닝'''\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    embeddings = []\n",
    "    for file in data:\n",
    "        wav, sampling_rate = torchaudio.load(os.path.join(path, file))\n",
    "        emb = model.make_speaker_embedding(wav, sampling_rate)\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    speaker_embedding = torch.stack(embeddings).mean(dim=0)\n",
    "\n",
    "    cond_dict = make_cond_dict(\n",
    "        text = text,\n",
    "        speaker = speaker_embedding,\n",
    "        language=\"ko\"\n",
    "    )\n",
    "    conditioning = model.prepare_conditioning(cond_dict)\n",
    "    # 음성 생성 (컴파일러 비활성화)\n",
    "    codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "    wavs = model.autoencoder.decode(codes).cpu()\n",
    "\n",
    "    # 결과 저장\n",
    "    torchaudio.save(os.path.join(path, f\"{name}_few_shot.wav\"), wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "    print(\"🔊 few_shot.wav 생성 완료!\")\n",
    "    return codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/test_wav\"\n",
    "file = \"ma_1_test.wav\"\n",
    "data = [f\"karina_{i}.wav\" for i in range(1,5)]\n",
    "name = \"test01\"\n",
    "text = \"\"\"\n",
    "이러한 문제를 해결하기 위해, AI 기반 발표 지원 시스템인 \"저희 발표 안합니다!\" 프로젝트가 기획되었습니다.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot(path,file, text,name, model)\n",
    "# few_shot(path,data, text,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\zonos\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "import time\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# 🔧 환경 설정\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\eSpeak NG\"\n",
    "os.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = r\"C:\\Program Files\\eSpeak NG\\espeak.dll\"\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "# 📦 모델 로딩\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
    "\n",
    "# 📁 경로 설정\n",
    "TEXT_PATH = \"../../data/txt/test_script.txt\"\n",
    "AUDIO_PATH = \"../../data/test_wav\"\n",
    "os.makedirs(AUDIO_PATH, exist_ok=True)\n",
    "\n",
    "# 🔊 참조 음성\n",
    "zero_shot_ref = \"CTS_3.wav\"\n",
    "few_shot_refs = [\"CTS_4.wav\", \"CTS_5.wav\"]\n",
    "\n",
    "# 📄 텍스트 로드 및 페이지 분할\n",
    "with open(TEXT_PATH, encoding=\"utf-8\") as f:\n",
    "    script = f.read()\n",
    "pages = script.strip().split(\"\\n\\n\")\n",
    "\n",
    "# ✅ speaker 임베딩 캐싱 (단 1회)\n",
    "zero_wav, zero_sr = torchaudio.load(os.path.join(AUDIO_PATH, zero_shot_ref))\n",
    "zero_shot_speaker = model.make_speaker_embedding(zero_wav, zero_sr)\n",
    "\n",
    "few_embeddings = []\n",
    "for file in few_shot_refs:\n",
    "    wav, sr = torchaudio.load(os.path.join(AUDIO_PATH, file))\n",
    "    emb = model.make_speaker_embedding(wav, sr)\n",
    "    few_embeddings.append(emb)\n",
    "few_shot_speaker = torch.stack(few_embeddings).mean(dim=0)\n",
    "\n",
    "# 🎙 Zero-Shot 합성\n",
    "def zero_shot(text, name):\n",
    "    torch.cuda.empty_cache()\n",
    "    cond = make_cond_dict(text=text, speaker=zero_shot_speaker, language=\"ko\")\n",
    "    conditioning = model.prepare_conditioning(cond)\n",
    "    codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "    wavs = model.autoencoder.decode(codes).cpu()\n",
    "    torchaudio.save(os.path.join(AUDIO_PATH, f\"{name}_zero_shot.wav\"), wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "# 🎙 Few-Shot 합성\n",
    "def few_shot(text, name):\n",
    "    torch.cuda.empty_cache()\n",
    "    cond = make_cond_dict(text=text, speaker=few_shot_speaker, language=\"ko\")\n",
    "    conditioning = model.prepare_conditioning(cond)\n",
    "    codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "    wavs = model.autoencoder.decode(codes).cpu()\n",
    "    torchaudio.save(os.path.join(AUDIO_PATH, f\"{name}_few_shot.wav\"), wavs[0], model.autoencoder.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎤 처리 중: page_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [01:53<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 143.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:03<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 125.55s\n",
      "\n",
      "🎤 처리 중: page_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:05<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 134.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [01:58<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 119.78s\n",
      "\n",
      "🎤 처리 중: page_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  75%|███████▍  | 1937/2588 [01:18<00:26, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 79.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  82%|████████▏ | 2120/2588 [01:28<00:19, 23.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 89.5s\n",
      "\n",
      "🎤 처리 중: page_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:06<00:00, 20.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 127.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:05<00:00, 20.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 126.37s\n",
      "\n",
      "🎤 처리 중: page_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:15<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 137.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:14<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 136.45s\n",
      "\n",
      "🎤 처리 중: page_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:03<00:00, 20.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 125.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:04<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 129.81s\n",
      "\n",
      "🎤 처리 중: page_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  69%|██████▉   | 1791/2588 [01:13<00:32, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 73.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  66%|██████▋   | 1720/2588 [01:05<00:33, 26.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 66.38s\n",
      "\n",
      "🎤 처리 중: page_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:15<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 137.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:14<00:00, 19.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 135.93s\n",
      "\n",
      "🎤 처리 중: page_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  70%|███████   | 1817/2588 [01:12<00:30, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 73.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  77%|███████▋  | 1988/2588 [01:20<00:24, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 81.02s\n",
      "\n",
      "🎤 처리 중: page_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:02<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 124.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:02<00:00, 21.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 133.46s\n",
      "\n",
      "🎤 처리 중: page_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:06<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 128.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:06<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 128.11s\n",
      "\n",
      "🎤 처리 중: page_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:02<00:00, 21.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 124.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:00<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 132.2s\n",
      "\n",
      "🎤 처리 중: page_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:07<00:00, 20.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 129.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:04<00:00, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 126.78s\n",
      "\n",
      "🎤 처리 중: page_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  73%|███████▎  | 1888/2588 [01:16<00:28, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 77.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [01:57<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 131.24s\n",
      "\n",
      "🎤 처리 중: page_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  98%|█████████▊| 2535/2588 [02:02<00:02, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 124.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 2588/2588 [02:00<00:00, 21.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 133.79s\n",
      "\n",
      "🎤 처리 중: page_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  95%|█████████▌| 2470/2588 [01:53<00:05, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zero-Shot 완료: 122.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  75%|███████▍  | 1933/2588 [01:19<00:27, 24.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Few-Shot 완료: 80.61s\n",
      "\n",
      "⏱️ 페이지별 생성 시간:\n",
      "\n",
      "| page    |   zero_shot |   few_shot |\n",
      "|---------|-------------|------------|\n",
      "| page_0  |      143.52 |     125.55 |\n",
      "| page_1  |      134.99 |     119.78 |\n",
      "| page_2  |       79.26 |      89.5  |\n",
      "| page_3  |      127.08 |     126.37 |\n",
      "| page_4  |      137.22 |     136.45 |\n",
      "| page_5  |      125.05 |     129.81 |\n",
      "| page_6  |       73.77 |      66.38 |\n",
      "| page_7  |      137.52 |     135.93 |\n",
      "| page_8  |       73.29 |      81.02 |\n",
      "| page_9  |      124.1  |     133.46 |\n",
      "| page_10 |      128.26 |     128.11 |\n",
      "| page_11 |      124.38 |     132.2  |\n",
      "| page_12 |      129.16 |     126.78 |\n",
      "| page_13 |       77.17 |     131.24 |\n",
      "| page_14 |      124.6  |     133.79 |\n",
      "| page_15 |      122.51 |      80.61 |\n"
     ]
    }
   ],
   "source": [
    "# 🕒 합성 실행 및 시간 측정\n",
    "results = []\n",
    "for idx, text in enumerate(pages):\n",
    "    \n",
    "    page_name = f\"page_{idx}\"\n",
    "    print(f\"\\n🎤 처리 중: {page_name}\")\n",
    "\n",
    "    # Zero-Shot\n",
    "    start = time.time()\n",
    "    try:\n",
    "        zero_shot(text, page_name)\n",
    "        zero_time = round(time.time() - start, 2)\n",
    "        print(f\"✅ Zero-Shot 완료: {zero_time}s\")\n",
    "    except Exception as e:\n",
    "        zero_time = f\"Error: {str(e)}\"\n",
    "\n",
    "    # Few-Shot\n",
    "    start = time.time()\n",
    "    try:\n",
    "        few_shot(text, page_name)\n",
    "        few_time = round(time.time() - start, 2)\n",
    "        print(f\"✅ Few-Shot 완료: {few_time}s\")\n",
    "    except Exception as e:\n",
    "        few_time = f\"Error: {str(e)}\"\n",
    "\n",
    "    results.append({\n",
    "        \"page\": page_name,\n",
    "        \"zero_shot\": zero_time,\n",
    "        \"few_shot\": few_time\n",
    "    })\n",
    "\n",
    "# 📊 결과 출력\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n⏱️ 페이지별 생성 시간:\\n\")\n",
    "print(tabulate(df, headers='keys', tablefmt='github', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ speaker 임베딩 캐싱 (단 1회)\n",
    "zero_wav, zero_sr = torchaudio.load(os.path.join(AUDIO_PATH, zero_shot_ref))\n",
    "zero_shot_speaker = model.make_speaker_embedding(zero_wav, zero_sr)\n",
    "\n",
    "few_embeddings = []\n",
    "for file in few_shot_refs:\n",
    "    wav, sr = torchaudio.load(os.path.join(AUDIO_PATH, file))\n",
    "    emb = model.make_speaker_embedding(wav, sr)\n",
    "    few_embeddings.append(emb)\n",
    "few_shot_speaker = torch.stack(few_embeddings).mean(dim=0)\n",
    "\n",
    "# 🎙 Zero-Shot 합성\n",
    "def zero_shot(text, name):\n",
    "    torch.cuda.empty_cache()\n",
    "    cond = make_cond_dict(text=text, speaker=zero_shot_speaker, language=\"ko\")\n",
    "    conditioning = model.prepare_conditioning(cond)\n",
    "    codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "    wavs = model.autoencoder.decode(codes).cpu()\n",
    "    torchaudio.save(os.path.join(AUDIO_PATH, f\"{name}_zero_shot.wav\"), wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "# 🎙 Few-Shot 합성\n",
    "def few_shot(text, name):\n",
    "    torch.cuda.empty_cache()\n",
    "    cond = make_cond_dict(text=text, speaker=few_shot_speaker, language=\"ko\")\n",
    "    conditioning = model.prepare_conditioning(cond)\n",
    "    codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "    wavs = model.autoencoder.decode(codes).cpu()\n",
    "    torchaudio.save(os.path.join(AUDIO_PATH, f\"{name}_few_shot.wav\"), wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "# 🕒 합성 실행 및 시간 측정\n",
    "results = []\n",
    "for idx, text in enumerate(pages):\n",
    "    page_name = f\"page_{idx}\"\n",
    "    print(f\"\\n🎤 처리 중: {page_name}\")\n",
    "\n",
    "    # Zero-Shot\n",
    "    start = time.time()\n",
    "    try:\n",
    "        zero_shot(text, page_name)\n",
    "        zero_time = round(time.time() - start, 2)\n",
    "        print(f\"✅ Zero-Shot 완료: {zero_time}s\")\n",
    "    except Exception as e:\n",
    "        zero_time = f\"Error: {str(e)}\"\n",
    "\n",
    "    # Few-Shot\n",
    "    start = time.time()\n",
    "    try:\n",
    "        few_shot(text, page_name)\n",
    "        few_time = round(time.time() - start, 2)\n",
    "        print(f\"✅ Few-Shot 완료: {few_time}s\")\n",
    "    except Exception as e:\n",
    "        few_time = f\"Error: {str(e)}\"\n",
    "\n",
    "    results.append({\n",
    "        \"page\": page_name,\n",
    "        \"zero_shot\": zero_time,\n",
    "        \"few_shot\": few_time\n",
    "    })\n",
    "\n",
    "# 📊 결과 출력\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n⏱️ 페이지별 생성 시간:\\n\")\n",
    "print(tabulate(df, headers='keys', tablefmt='github', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZONOS 웹에서 gradio로 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio_client import Client\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "import numpy as np\n",
    "import soundfile as sf  # for saving the audio\n",
    "import numpy as np\n",
    "# 1. Gradio 앱 URL (예: 로컬 또는 share URL)\n",
    "client = Client(\"http://localhost:7860\")  # 또는 \"https://xxxx.gradio.live\"\n",
    "\n",
    "# 2. generate_audio에 맞게 입력값 설정\n",
    "result = client.predict(\n",
    "    \"Zyphra/Zonos-v0.1-transformer\",  # model_choice\n",
    "    \"안녕하세요. 반갑습니다. 오늘 수업할 내용을 말씀드리겠습니다.\",            # text\n",
    "    \"ko\",                          # language\n",
    "    None,                             # speaker_audio (None = 사용 안 함)\n",
    "    None,                             # prefix_audio (None = 사용 안 함)\n",
    "    1.0, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1, 0.2,  # emotion sliders\n",
    "    0.78,                             # vq_single\n",
    "    24000,                            # fmax\n",
    "    45.0,                             # pitch_std\n",
    "    15.0,                             # speaking_rate\n",
    "    4.0,                              # dnsmos\n",
    "    False,                            # speaker_noised\n",
    "    2.0,                              # cfg_scale\n",
    "    0,                              # top_p\n",
    "    0,                                # top_k (min_k로 전달됨)\n",
    "    0,                              # min_p\n",
    "    0.5, 0.4, 0.0,                    # linear, confidence, quadratic\n",
    "    42,                               # seed\n",
    "    False,                            # randomize_seed\n",
    "    [\"emotion\"],                     # unconditional_keys\n",
    "    api_name=\"/generate_audio\"              # 예: 함수가 자동 등록된 이름\n",
    ")\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "src = result[0]\n",
    "dst = \"test.wav\"\n",
    "\n",
    "shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTAPI & STREAMLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "import re\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def extract_top_similar_words(text: str, keywords: List[str], top_k: int = 10) -> List[str]:\n",
    "    # 텍스트에서 단어 토큰 추출\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    word_counts = Counter(words)\n",
    "    unique_words = list(word_counts.keys())\n",
    "\n",
    "    # 임베딩\n",
    "    embedder = OpenAIEmbeddings()\n",
    "    word_embeddings = embedder.embed_documents(unique_words)\n",
    "    keyword_embeddings = [embedder.embed_query(k) for k in keywords]\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarities = {}\n",
    "    for word, emb in zip(unique_words, word_embeddings):\n",
    "        sim_scores = [cosine_similarity([emb], [k_emb])[0][0] for k_emb in keyword_embeddings]\n",
    "        similarities[word] = max(sim_scores)\n",
    "\n",
    "    # 상위 N개 단어 반환\n",
    "    top_similar = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return [{\"word\": word, \"similarity\": round(score, 4)} for word, score in top_similar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script_generate.py\n",
    "from utils import extract_top_similar_words\n",
    "\n",
    "def combine_scripts_and_extract_keywords(scripts: List[str], keywords: List[str]):\n",
    "    \"\"\"전체 대본 통합 및 유사 단어 추출\"\"\"\n",
    "    full_script = \"\\n\\n\".join(scripts)\n",
    "    similar_words = extract_top_similar_words(full_script, keywords, top_k=10)\n",
    "    return {\n",
    "        \"full_script\": full_script,\n",
    "        \"top_similar_words\": similar_words\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# routes.py\n",
    "from fastapi import APIRouter, Body\n",
    "from typing import List\n",
    "from core.script_generate import combine_scripts_and_extract_keywords\n",
    "\n",
    "@router.post(\"/script/combine-and-analyze\")\n",
    "async def combine_and_analyze(\n",
    "    scripts: List[str] = Body(...),\n",
    "    keywords: List[str] = Body(...)\n",
    "):  \n",
    "    try:\n",
    "        result = combine_scripts_and_extract_keywords(scripts, keywords)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zonos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
