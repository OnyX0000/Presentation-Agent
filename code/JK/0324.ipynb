{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PDF load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "# def classify_page(page_num, total_pages) :\n",
    "#     \"\"\"\n",
    "#     페이지 번호를 기반으로 intro, body, end를 분류하는 함수.\n",
    "#     \"\"\"\n",
    "#     if page_num < 2 :\n",
    "#         return \"intro\"\n",
    "#     elif page_num >= total_pages - 2 :\n",
    "#         return \"end\"\n",
    "#     else :\n",
    "#         return \"body\"\n",
    "\n",
    "def get_image_area_ratio(page, img_rect) :\n",
    "    \"\"\"\n",
    "    개별 이미지의 크기를 전체 페이지 면적 대비 비율로 반환.\n",
    "    \"\"\"\n",
    "    page_width, page_height = page.rect.width, page.rect.height\n",
    "    page_area = page_width * page_height\n",
    "\n",
    "    x0, y0, x1, y1 = img_rect\n",
    "    img_width = x1 - x0\n",
    "    img_height = y1 - y0\n",
    "    img_area = img_width * img_height\n",
    "\n",
    "    return img_area / page_area  # 전체 페이지 대비 이미지 크기 비율\n",
    "\n",
    "def get_total_image_area_ratio(page, images) :\n",
    "    \"\"\"\n",
    "    페이지에서 감지된 모든 이미지의 총 면적 비율을 계산.\n",
    "    \"\"\"\n",
    "    total_ratio = sum(get_image_area_ratio(page, img_rect) for img_rect in images)\n",
    "    return total_ratio\n",
    "\n",
    "def extract_page(pdf_path, image_threshold = 0.5) :\n",
    "    \"\"\"\n",
    "    PDF에서 텍스트 및 이미지 정보를 추출.\n",
    "    페이지에서 인식된 이미지의 총 면적이 전체 페이지 면적의 40% 이상일 때만 이미지 내용을 해석.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = len(doc)\n",
    "    page_data = []\n",
    "\n",
    "    for page_num in range(total_pages) :\n",
    "        page = doc[page_num]\n",
    "\n",
    "        # 텍스트 추출\n",
    "        text = page.get_text(\"text\")\n",
    "\n",
    "        # 이미지 추출\n",
    "        images = page.get_images(full=True)\n",
    "        image_data = []\n",
    "        img_rects = []\n",
    "        for img in images :\n",
    "            xref = img[0]\n",
    "            img_rects_page = page.get_image_rects(xref)\n",
    "            if img_rects_page:\n",
    "                img_rects.append(img_rects_page[0])  # 이미지 위치 저장\n",
    "\n",
    "        # 페이지 내 이미지 총 면적 계산\n",
    "        total_img_ratio = get_total_image_area_ratio(page, img_rects)\n",
    "\n",
    "        # 이미지 분석 여부 결정\n",
    "        process_images = total_img_ratio >= image_threshold\n",
    "\n",
    "        for img_rect in img_rects :\n",
    "            x0, y0, x1, y1 = img_rect\n",
    "            image_entry = {\"x\": x0, \"y\": y0, \"width\": x1 - x0, \"height\": y1 - y0}\n",
    "\n",
    "            if process_images :\n",
    "                image_entry[\"processed\"] = True  # 이미지 내용 해석 수행\n",
    "            else :\n",
    "                image_entry[\"processed\"] = False  # 무시됨\n",
    "\n",
    "            image_data.append(image_entry)\n",
    "\n",
    "        # # 페이지 유형 결정\n",
    "        # section = classify_page(page_num, total_pages)\n",
    "\n",
    "        # 페이지 데이터 저장\n",
    "        page_data.append({\n",
    "            \"page\": page_num + 1,\n",
    "            \"text\": text,\n",
    "            \"images\": image_data,\n",
    "            \"total_image_ratio\": round(total_img_ratio, 2),\n",
    "            \"image_analysis\": process_images\n",
    "        })\n",
    "        \n",
    "    return page_data, doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_pdf_content(pdf_path):\n",
    "    pdf_doc = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "\n",
    "    for page_number in range(len(pdf_doc)):\n",
    "        page = pdf_doc[page_number]\n",
    "        page_text = page.get_text()\n",
    "        image_entries = []\n",
    "\n",
    "        images = page.get_images(full=True)\n",
    "        for img in images:\n",
    "            xref = img[0]\n",
    "            base_image = pdf_doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            pil_image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # 이미지 위치 추출\n",
    "            rects = page.get_image_rects(xref)\n",
    "            for rect in rects:\n",
    "                image_entries.append({\n",
    "                    \"x0\": rect.x0,\n",
    "                    \"y0\": rect.y0,\n",
    "                    \"x1\": rect.x1,\n",
    "                    \"y1\": rect.y1,\n",
    "                    \"image\": pil_image\n",
    "                })\n",
    "\n",
    "        # 페이지 데이터 구성\n",
    "        page_data = {\n",
    "            \"page\": page_number + 1,\n",
    "            \"text\": page_text,\n",
    "            \"images\": image_entries\n",
    "        }\n",
    "\n",
    "        pages.append(page_data)\n",
    "\n",
    "    pdf_doc.close()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '../../data/presentation_agent.pdf'\n",
    "pdf_data = extract_pdf_content(pdf_path)\n",
    "\n",
    "\n",
    "\n",
    "# pages, metadata = extract_page(pdf_path)\n",
    "# pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 이미지 해석(GPT-4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def pil_image_to_base64(image: Image.Image) -> str:\n",
    "    \"\"\"PIL 이미지를 base64로 인코딩\"\"\"\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "def classify_image_type(image: Image.Image, llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    이미지 분류 요청을 GPT-4o에 보내고 결과 반환.\n",
    "    \"\"\"\n",
    "    img_b64 = pil_image_to_base64(image)\n",
    "    data_url = f\"data:image/png;base64,{img_b64}\"\n",
    "\n",
    "    prompt = (\n",
    "        \"다음 이미지를 아래 세 가지 중 하나로 분류하세요:\\n\"\n",
    "        \"1. 그래프/도표\\n\"\n",
    "        \"2. 로고\\n\"\n",
    "        \"3. 그외\\n\"\n",
    "        \"반드시 위 중 하나의 항목만 정확히 출력하세요.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"당신은 이미지 분류 전문 AI 에이전트입니다.\"),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    label = response.content.strip()\n",
    "    return label if label in [\"그래프/도표\", \"로고\", \"그외\"] else \"그외\"\n",
    "\n",
    "def analyze_pdf_images(pdf_data: list) -> list:\n",
    "    \"\"\"\n",
    "    각 페이지의 이미지에 대해 GPT-4o로 분류 결과를 추가\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    for page in pdf_data:\n",
    "        for image in page[\"images\"]:\n",
    "            image_type = classify_image_type(image[\"image\"], llm)\n",
    "            image[\"image_type\"] = image_type\n",
    "\n",
    "    return pdf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyze_pdf_images(pdf_data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page': 1,\n",
       "  'text': 'Presentation Agent\\n저희 발표 안합니다!\\n정재식, 이진규\\nㅈ소 기업\\n',\n",
       "  'images': []},\n",
       " {'page': 2,\n",
       "  'text': '프로젝트 개요\\n기획 배경\\n프로젝트 소개\\n01\\nCONTENT\\n프로젝트 기획\\n자원 및 기술\\n시스템 구조\\n작업 흐름\\n02\\n프로젝트 방향성\\n발전 방안\\n03\\n',\n",
       "  'images': []},\n",
       " {'page': 3, 'text': '프로젝트 개요\\n프로젝트 개요\\n01\\n', 'images': []},\n",
       " {'page': 4,\n",
       "  'text': 'Wordcloud\\nNetworkx\\n01. 개요\\n기획 배경\\n“발표 준비”라는 키워드의 블로그, 뉴스, 카페, 지식인 등 에서\\n제목 및 내용을 크롤링하여 수집\\n발표는 우리 삶에 얼마나 밀접해 있을까?\\n',\n",
       "  'images': [{'x0': -19.18781089782715,\n",
       "    'y0': 292.3575134277344,\n",
       "    'x1': 696.5653076171875,\n",
       "    'y1': 659.5574951171875,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=790x405>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 713.5635986328125,\n",
       "    'y0': 214.59759521484375,\n",
       "    'x1': 1427.88232421875,\n",
       "    'y1': 736.7100830078125,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1019x745>,\n",
       "    'image_type': '그래프/도표'},\n",
       "   {'x0': 414.5634460449219,\n",
       "    'y0': 451.3218994140625,\n",
       "    'x1': 587.8134765625,\n",
       "    'y1': 587.0718994140625,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=656x512>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 182.5324249267578,\n",
       "    'y0': 383.59954833984375,\n",
       "    'x1': 355.78240966796875,\n",
       "    'y1': 519.3495483398438,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=656x512>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': -4.785785675048828,\n",
       "    'y0': 456.60546875,\n",
       "    'x1': 168.46421813964844,\n",
       "    'y1': 592.35546875,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=656x512>,\n",
       "    'image_type': '로고'}]},\n",
       " {'page': 5,\n",
       "  'text': '내성적 성격\\n31.3%\\n실수에 대한 압박감\\n25%\\n준비 부족\\n14.6%\\n무대 공포증\\n12.5%\\n질문의 대응이 어려워서\\n10.4%\\n시선에 대한 압박감\\n01. 개요\\n기획 배경\\n취업포털 커리어넷에서 직장인 384명을 대상으로 한 설문조사\\n타고난 내성적 성격 때문에\\n발표 중에 실수하는 것이 \\n두려워서\\n무대 공포증이 있어서\\n사람들과 시선을 마주치는\\n것이 싫어서\\n발표 전 불안감의 원인은 무엇일까?\\n',\n",
       "  'images': [{'x0': 35.82052230834961,\n",
       "    'y0': 409.8700866699219,\n",
       "    'x1': 85.32052612304688,\n",
       "    'y1': 455.6200866699219,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=648x598>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 418.395751953125,\n",
       "    'y0': 711.1583251953125,\n",
       "    'x1': 467.895751953125,\n",
       "    'y1': 756.9083251953125,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=648x598>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 579.948486328125,\n",
       "    'y0': 285.60986328125,\n",
       "    'x1': 629.448486328125,\n",
       "    'y1': 331.35986328125,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=648x598>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 295.4934387207031,\n",
       "    'y0': 203.15402221679688,\n",
       "    'x1': 344.9934387207031,\n",
       "    'y1': 248.90402221679688,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=648x598>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 6,\n",
       "  'text': '최초의 발표하는 인공지능 모델 : 오인용\\n01. 개요\\n프로젝트 소개\\n중요한 내용을 중심으로 발표용 대본 생성\\nAI 음성 합성을 활용한 자동 발표 기능\\n기능\\n기업, 연구자, 학생 등이 보다 효율적으로 정보 활용 가능\\n일괄된 발표 퀄리티\\n발표에 드는 시간 단축\\n기대 효과\\n',\n",
       "  'images': [{'x0': 41.02989959716797,\n",
       "    'y0': 229.45050048828125,\n",
       "    'x1': 551.0299072265625,\n",
       "    'y1': 750.7005004882812,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1119x1144>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 7, 'text': '프로젝트 기획\\n02\\n', 'images': []},\n",
       " {'page': 8,\n",
       "  'text': '사용할 기술스택\\nFast API\\nStreamlit\\nLang Chain\\nOllama\\nChroma DB\\n02. 기획\\nOpenAI\\nGitHub\\nHugging Face\\nLLM, Prompt, RAG 등의 AI Agent가 수행하는 과정을 하나의 Chain으로 묶는 데 사용\\nAPI 없이 로컬 환경에서 AI 모델을 직접 실행할 수 있어 보안과 성능을 최적화 가능\\n다양한 사전 학습된 모델을 검색하고 활용할 수 있는 플랫폼  \\nVector DB에 저장하기 위해 Embedding 모델로써 사용\\nAI 모델을 서빙하고 사용자 요청을 처리하는 역할로 사용.\\nVector DB로, 문서를 저장하고 빠르게 검색할 수 있도록 하기 위해 사용\\nAI 서비스를 사용자에게 웹 애플리케이션 형태로 제공하는 UI 프레임워크\\n코드 저장, 버전 관리 및 협업을 위해 사용.\\n자원 및 기술\\n',\n",
       "  'images': [{'x0': 81.0,\n",
       "    'y0': 471.44439697265625,\n",
       "    'x1': 124.90753936767578,\n",
       "    'y1': 515.3519287109375,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=75x75>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 607.7999877929688,\n",
       "    'x1': 124.5,\n",
       "    'y1': 651.2999877929688,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=75x75>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 185.80929565429688,\n",
       "    'x1': 129.75,\n",
       "    'y1': 234.55929565429688,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=192x192>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 258.9082946777344,\n",
       "    'x1': 121.5,\n",
       "    'y1': 299.4082946777344,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 538.8897705078125,\n",
       "    'x1': 126.0,\n",
       "    'y1': 583.8897705078125,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=120x120>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 398.8990173339844,\n",
       "    'x1': 129.75,\n",
       "    'y1': 447.6490173339844,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=205x205>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 675.2453002929688,\n",
       "    'x1': 129.75,\n",
       "    'y1': 723.9953002929688,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=205x205>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 398.8990173339844,\n",
       "    'x1': 129.75,\n",
       "    'y1': 447.6490173339844,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=205x205>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 675.2453002929688,\n",
       "    'x1': 129.75,\n",
       "    'y1': 723.9953002929688,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=205x205>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 326.3536376953125,\n",
       "    'x1': 129.75,\n",
       "    'y1': 375.1036376953125,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=205x205>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 9,\n",
       "  'text': '사용할 자원\\n랭체인과 자연어처리, 딥러닝에 관련된 위키독스를 크롤링하여 벡터 임베딩 후 VectorDB에 적재할 예정\\n02. 기획\\n자원 및 기술\\n',\n",
       "  'images': [{'x0': 43.007015228271484,\n",
       "    'y0': 237.18939208984375,\n",
       "    'x1': 422.50701904296875,\n",
       "    'y1': 729.1893920898438,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=256x332>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 531.282958984375,\n",
       "    'y0': 237.18939208984375,\n",
       "    'x1': 901.782958984375,\n",
       "    'y1': 729.189453125,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=98x130>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 1011.0809326171875,\n",
       "    'y0': 237.18939208984375,\n",
       "    'x1': 1389.8309326171875,\n",
       "    'y1': 729.1893920898438,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=281x365>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 10,\n",
       "  'text': '“저희 발표 안합니다!” 시스템 구조도\\n02. 기획\\n시스템 구조\\nUser\\n결 론\\n본 론\\n서  론\\nVector DB\\nLLM(오인용)\\nDocument\\n',\n",
       "  'images': [{'x0': 792.1921997070312,\n",
       "    'y0': 598.88623046875,\n",
       "    'x1': 916.6921997070312,\n",
       "    'y1': 725.63623046875,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=639x653>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 244.32577514648438,\n",
       "    'y0': 379.9923095703125,\n",
       "    'x1': 313.89910888671875,\n",
       "    'y1': 470.32965087890625,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=492x642>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 283.6929626464844,\n",
       "    'y0': 378.8963317871094,\n",
       "    'x1': 312.8040466308594,\n",
       "    'y1': 408.84912109375,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=213x215>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 971.4356689453125,\n",
       "    'y0': 378.076416015625,\n",
       "    'x1': 1055.4356689453125,\n",
       "    'y1': 477.076416015625,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1160x1371>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 11,\n",
       "  'text': '서비스 UI 구성\\n02. 기획\\n시스템 구조\\n발표 자료 업로드\\n처리완료된 자료 시각화\\n처리된 자료 다운로드\\n',\n",
       "  'images': [{'x0': 53.983116149902344,\n",
       "    'y0': 255.22137451171875,\n",
       "    'x1': 456.4029235839844,\n",
       "    'y1': 706.5646362304688,\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=726x814>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 519.0909423828125,\n",
       "    'y0': 268.42218017578125,\n",
       "    'x1': 921.5107421875,\n",
       "    'y1': 691.9461669921875,\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=758x798>,\n",
       "    'image_type': '그외'},\n",
       "   {'x0': 984.3355102539062,\n",
       "    'y0': 188.6280517578125,\n",
       "    'x1': 1394.0198974609375,\n",
       "    'y1': 773.1240844726562,\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=698x994>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 12,\n",
       "  'text': '서비스 UI 구성\\n02. 기획\\n시스템 구조\\n',\n",
       "  'images': [{'x0': 261.25177001953125,\n",
       "    'y0': 203.94683837890625,\n",
       "    'x1': 1178.56005859375,\n",
       "    'y1': 714.6538696289062,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1864x1038>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 13,\n",
       "  'text': '작업 흐름도\\n02. 기획\\nFast API\\nStreamlit\\nLang Chain\\nOllama\\nChroma DB\\nOpenAI\\nHugging Face\\nWork Flow\\n',\n",
       "  'images': [{'x0': 137.63365173339844,\n",
       "    'y0': -24.48468017578125,\n",
       "    'x1': 1032.3836669921875,\n",
       "    'y1': 870.2653198242188,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1421x1421>,\n",
       "    'image_type': '그래프/도표'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 656.7186279296875,\n",
       "    'x1': 1048.17822265625,\n",
       "    'y1': 691.1820068359375,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x60>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 701.2506103515625,\n",
       "    'x1': 1047.8583984375,\n",
       "    'y1': 735.3941040039062,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=60x60>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 376.7581787109375,\n",
       "    'x1': 1051.9791259765625,\n",
       "    'y1': 415.0224304199219,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 490.9000244140625,\n",
       "    'x1': 1045.503662109375,\n",
       "    'y1': 522.6887817382812,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 376.7581787109375,\n",
       "    'x1': 1051.9791259765625,\n",
       "    'y1': 415.0224304199219,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 490.9000244140625,\n",
       "    'x1': 1045.503662109375,\n",
       "    'y1': 522.6887817382812,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 304.0077209472656,\n",
       "    'x1': 1049.03564453125,\n",
       "    'y1': 339.3285827636719,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=120x120>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 206.010498046875,\n",
       "    'x1': 1051.9791259765625,\n",
       "    'y1': 244.27474975585938,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=205x205>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 1013.71484375,\n",
       "    'y0': 415.29638671875,\n",
       "    'x1': 1051.9791259765625,\n",
       "    'y1': 453.5606384277344,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=205x205>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 14, 'text': '프로젝트 방향성\\n03\\n', 'images': []},\n",
       " {'page': 15,\n",
       "  'text': 'TO DO LIST\\n실시간 상호작용\\n인간처럼 말하기\\n발표 스타일의 개인화\\n발표를 하는 디지털 아바타 생성\\n도메인 확장\\n03. 방향성\\n발전 방안\\n',\n",
       "  'images': [{'x0': 81.0,\n",
       "    'y0': 257.8437805175781,\n",
       "    'x1': 138.0,\n",
       "    'y1': 314.8437805175781,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=472x472>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 351.10174560546875,\n",
       "    'x1': 138.0,\n",
       "    'y1': 408.10174560546875,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=472x472>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 444.3597106933594,\n",
       "    'x1': 138.0,\n",
       "    'y1': 501.3597106933594,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=472x472>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 537.6176147460938,\n",
       "    'x1': 138.0,\n",
       "    'y1': 594.6176147460938,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=472x472>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 81.0,\n",
       "    'y0': 630.8755493164062,\n",
       "    'x1': 138.0,\n",
       "    'y1': 687.8755493164062,\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=472x472>,\n",
       "    'image_type': '로고'},\n",
       "   {'x0': 730.5584106445312,\n",
       "    'y0': 219.87545776367188,\n",
       "    'x1': 1369.653076171875,\n",
       "    'y1': 697.7031860351562,\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=396x296>,\n",
       "    'image_type': '그외'}]},\n",
       " {'page': 16, 'text': '저희 발표 안합니다\\n감사합니다.\\n', 'images': []}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for page in result:\n",
    "    print(f\"Page {page['page']}:\")\n",
    "    for i, img_data in enumerate(page['images']):\n",
    "        print(f\"  Image {i + 1} - Type: {img_data['image_type']}\")\n",
    "        display(img_data['image'])  # PIL.Image 객체 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PPT 전체 흐름 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def pil_image_to_base64(image: Image.Image) -> str:\n",
    "    \"\"\"PIL 이미지를 base64 PNG 데이터 URL로 변환\"\"\"\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "def build_summary_prompt_inputs(pdf_data: list) -> list:\n",
    "    \"\"\"\n",
    "    pdf_data를 LangChain message 포맷의 prompt 입력 형태로 변환\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        (\"system\", \"너는 전문가 발표 요약가야. 슬라이드 텍스트와 도표를 함께 보고 전체 발표 흐름을 요약해.\"),\n",
    "    ]\n",
    "\n",
    "    for page in pdf_data:\n",
    "        page_text = page.get(\"text\", \"\").strip()\n",
    "        blocks = []\n",
    "\n",
    "        if page_text:\n",
    "            blocks.append({\"type\": \"text\", \"text\": f\"[Page {page['page']}]\\n{page_text}\"})\n",
    "\n",
    "        for img_data in page[\"images\"]:\n",
    "            if img_data.get(\"image_type\") == \"그래프/도표\":\n",
    "                img_b64 = pil_image_to_base64(img_data[\"image\"])\n",
    "                blocks.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{img_b64}\"}\n",
    "                })\n",
    "\n",
    "        if blocks:\n",
    "            messages.append((\"human\", blocks))\n",
    "\n",
    "    messages.append((\"human\", \"위 발표 자료 전체의 흐름과 요지를 논리적으로 요약해 주세요.\"))\n",
    "    return messages\n",
    "\n",
    "def summarize_presentation_flow(pdf_data: list) -> str:\n",
    "    \"\"\"\n",
    "    LangChain 체인으로 발표 전체 흐름 요약 (텍스트 + 그래프 이미지 기반)\n",
    "    \"\"\"\n",
    "    # 모델 설정\n",
    "    llm = ChatOllama(model=\"gemma3:12b\", temperature=0)\n",
    "\n",
    "    # 프롬프트 메시지 구성\n",
    "    prompt_messages = build_summary_prompt_inputs(pdf_data)\n",
    "    prompt = ChatPromptTemplate.from_messages(prompt_messages)\n",
    "\n",
    "    # 체인 구성 및 실행\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    result = chain.invoke({})\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_presentation_flow(result)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores import Chroma\n",
    "\n",
    "# # 임베딩 생성\n",
    "# embedding_model_name = \"jhgan/ko-sbert-nli\"  # 임베딩 모델 선택\n",
    "# embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# # 벡터 스토어에 문서 추가\n",
    "# vector_store = Chroma.from_texts([page[\"text\"] for page in pages], embedding)\n",
    "\n",
    "# query = \"이 문서의 핵심 내용을 설명해\"\n",
    "# retrieved_docs = vector_store.similarity_search(query, k = 3)  # 상위 5개 문서 검색\n",
    "\n",
    "# # 검색된 문서의 내용을 하나로 합치기\n",
    "# retrieved_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.similarity_search('이 PDF의 서론은 몇 페이지부터 몇 페이지까지야?', k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain.schema import HumanMessage, SystemMessage\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# import time\n",
    "\n",
    "# ollama = ChatOllama(model='gemma3:12b')\n",
    "\n",
    "# # LLM에 검색된 내용만 전달\n",
    "# full_prompt = f\"\"\"\n",
    "# 이 문서의 주요 내용을 설명해줘. 관련된 내용:\n",
    "# {retrieved_text}\n",
    "# \"\"\"\n",
    "\n",
    "# response = ollama.invoke([\n",
    "#     SystemMessage(content=\"당신은 PDF 문서를 해석하는 AI입니다.\"),\n",
    "#     HumanMessage(content=full_prompt)\n",
    "# ])\n",
    "\n",
    "# full_explanation = response.content\n",
    "\n",
    "# print(full_explanation)  # 최종 결과 출력\n",
    "\n",
    "# for page in pages:\n",
    "#     text = page[\"text\"]\n",
    "#     prompt = f\"\"\"\n",
    "#     이 페이지의 주요 내용을 설명해줘. 텍스트 (일부만 제공됨):\n",
    "#     {text}\n",
    "    \n",
    "#     그리고 이미지 설명:\n",
    "#     {page['images']}\n",
    "#     \"\"\"\n",
    "\n",
    "#     response = ollama.invoke([\n",
    "#         SystemMessage(content=\"당신은 PDF 문서를 해석하는 AI입니다.\"),\n",
    "#         HumanMessage(content=prompt)\n",
    "#     ])\n",
    "\n",
    "#     page[\"generated_explanation\"] = response.content  # ollama 응답 저장\n",
    "#     print(page['generated_explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(full_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Page 1 설명:\n",
      "## 발표 대본 (Presentation Agent: 저희 발표 안합니다!)\n",
      "\n",
      "**[시작 - 밝고 유쾌한 분위기로 시작]**\n",
      "\n",
      "안녕하세요! 오늘 이렇게 뵙게 되어 반갑습니다. 저희는 정재식, 이진규입니다. 그리고… 저희는 오늘 발표하지 않습니다!\n",
      "\n",
      "**(잠시 멈추고 청중의 반응을 살핀다. 당황하거나 웃는 표정을 기대한다.)**\n",
      "\n",
      "네, 맞습니다. 저희는 발표를 하지 않습니다. \n",
      "\n",
      "**(청중의 궁금증을 자아내는 듯한 표정으로)**\n",
      "\n",
      "혹시 왜 발표를 안 하냐구요? 그건… 저희가 Presentation Agent이기 때문입니다!\n",
      "\n",
      "**(간단하게 Presentation Agent라는 이름의 의미를 설명한다. 예를 들어, \"저희는 발표를 대신해주는 존재입니다.\" 와 같이)**\n",
      "\n",
      "저희는 ㅈ소 기업에서 만들어졌습니다. (간단하게 회사에 대한 언급)\n",
      "\n",
      "**(감사 인사로 마무리)**\n",
      "\n",
      "오늘 이렇게 시간을 내주셔서 감사합니다!\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   이 대본은 제공된 정보가 매우 제한적이기 때문에, 상황에 맞게 내용을 추가하거나 수정해야 합니다.\n",
      "*   발표의 목적, 청중, 시간 등을 고려하여 대본을 조정해야 합니다.\n",
      "*   유머를 적절히 활용하여 청중의 흥미를 유발하는 것이 중요합니다.\n",
      "*   이미지 설명이 없으므로, 시각 자료를 활용할 계획이라면 이미지에 대한 언급을 추가해야 합니다.\n",
      "*   Presentation Agent의 역할과 기능에 대한 구체적인 설명이 필요하다면, 해당 내용을 추가해야 합니다.\n",
      "\n",
      "📄 Page 2 설명:\n",
      "## 발표 대본 (초안)\n",
      "\n",
      "**[시작 화면: 프로젝트 제목 및 발표자 정보]**\n",
      "\n",
      "안녕하세요, 오늘 [프로젝트 이름]에 대한 발표를 진행하게 된 [발표자 이름]입니다. 오늘 발표를 통해 이 프로젝트의 전반적인 내용과 앞으로의 방향성을 공유하고자 합니다.\n",
      "\n",
      "**[슬라이드 1: 프로젝트 개요]**\n",
      "\n",
      "먼저, 프로젝트 개요부터 말씀드리겠습니다. 이 프로젝트는 [프로젝트 목표 간략하게 설명]을 목표로 합니다. [프로젝트의 핵심 가치 또는 특징 1~2가지 언급].\n",
      "\n",
      "**[슬라이드 2: 기획 배경]**\n",
      "\n",
      "이 프로젝트를 기획하게 된 배경은 [문제 상황 또는 기회 요인 설명]입니다. 현재 [구체적인 상황 설명]으로 인해 [프로젝트를 통해 해결하고자 하는 문제 또는 달성하고자 하는 목표]가 필요하게 되었습니다.\n",
      "\n",
      "**[슬라이드 3: 프로젝트 소개]**\n",
      "\n",
      "[프로젝트 이름]은 [프로젝트의 핵심 기능 또는 서비스 간략하게 설명]을 제공하는 [프로젝트 유형 (예: 웹 서비스, 앱, 플랫폼 등)]입니다. [프로젝트의 주요 특징 또는 장점 1~2가지 언급].\n",
      "\n",
      "**[슬라이드 4: 프로젝트 기획]**\n",
      "\n",
      "프로젝트 기획 단계에서는 [기획 과정에서 중요하게 고려한 사항 1~2가지 언급]. 이를 바탕으로 [프로젝트의 핵심 기능 또는 서비스 상세 설명].\n",
      "\n",
      "**[슬라이드 5: 자원 및 기술]**\n",
      "\n",
      "프로젝트 진행에 필요한 자원으로는 [인력, 예산, 장비 등 구체적인 자원 언급]이 있으며, 기술적으로는 [사용하는 기술 스택 및 플랫폼 언급]을 활용할 예정입니다.\n",
      "\n",
      "**[슬라이드 6: 시스템 구조]**\n",
      "\n",
      "[시스템 구조 다이어그램 또는 간단한 설명]을 통해 프로젝트의 전체적인 구조를 보여드리겠습니다. [각 구성 요소의 역할과 상호 관계 설명].\n",
      "\n",
      "**[슬라이드 7: 작업 흐름]**\n",
      "\n",
      "프로젝트 진행 과정은 [단계별 작업 내용 및 일정 간략하게 설명]으로 구성됩니다. [각 단계별 주요 작업 내용 및 예상 소요 시간 언급].\n",
      "\n",
      "**[슬라이드 8: 프로젝트 방향성]**\n",
      "\n",
      "프로젝트의 방향성은 [핵심 목표 및 전략 간략하게 설명]으로 설정되었습니다. [향후 프로젝트의 발전 방향 및 목표 언급].\n",
      "\n",
      "**[슬라이드 9: 발전 방안]**\n",
      "\n",
      "향후 프로젝트 발전 방안으로는 [구체적인 발전 계획 및 목표 언급]을 고려하고 있습니다. [예상되는 효과 및 기대 결과 설명].\n",
      "\n",
      "**[마무리 화면: 질문 및 답변]**\n",
      "\n",
      "오늘 발표를 통해 [프로젝트 이름]에 대한 전반적인 내용을 공유했습니다. 혹시 질문 있으시면 편하게 질문해주세요. 경청해주셔서 감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만을 기반으로 작성되었으며, 실제 발표 내용에 맞게 수정 및 보완해야 합니다.\n",
      "*   각 슬라이드에 맞는 시각 자료 (이미지, 그래프, 다이어그램 등)를 활용하여 발표의 효과를 높일 수 있습니다.\n",
      "*   발표 시간과 청중의 수준을 고려하여 내용의 깊이와 범위를 조절해야 합니다.\n",
      "*   발표 자료에 포함된 내용을 간결하고 명확하게 전달하는 것이 중요합니다.\n",
      "*   발표 연습을 충분히 하여 자신감 있는 모습을 보여주는 것이 좋습니다.\n",
      "\n",
      "📄 Page 3 설명:\n",
      "## 발표 대본 (프로젝트 개요)\n",
      "\n",
      "**[시작 화면: 프로젝트 제목 및 로고 (이미지 설명이 없으므로, 발표 상황에 맞춰 적절한 이미지 사용)]**\n",
      "\n",
      "**발표자:** 안녕하세요, 오늘 저는 [프로젝트 이름]에 대한 개요를 발표하겠습니다.\n",
      "\n",
      "**1. 프로젝트 개요 (01)**\n",
      "\n",
      "*   **서론:** 오늘 발표에서는 [프로젝트 이름]의 핵심 내용을 간략하게 소개하고, 앞으로의 진행 방향에 대해 말씀드리겠습니다.\n",
      "*   **프로젝트 소개:** [프로젝트 이름]은 [프로젝트의 핵심 목표 및 간략한 설명]을 목표로 하는 프로젝트입니다. (예: 고객 만족도 향상을 위한 새로운 서비스 개발 프로젝트)\n",
      "*   **기획 배경:** 이 프로젝트는 [프로젝트가 시작된 배경 및 문제점]을 해결하기 위해 기획되었습니다. (예: 기존 서비스의 낮은 만족도, 시장 경쟁 심화 등)\n",
      "*   **주요 내용:** 오늘 발표에서는 프로젝트의 기획 배경, 방향성, 그리고 앞으로의 발전 방안에 대해 자세히 살펴보겠습니다.\n",
      "\n",
      "**2. 프로젝트 방향성 (03)**\n",
      "\n",
      "*   **핵심 목표:** [프로젝트의 핵심 목표를 구체적으로 설명] (예: 고객 만족도 20% 향상, 신규 고객 유치 10% 증가 등)\n",
      "*   **주요 전략:** [핵심 목표 달성을 위한 주요 전략 설명] (예: 사용자 중심 디자인 적용, 새로운 기술 도입 등)\n",
      "*   **기대 효과:** [프로젝트 성공 시 예상되는 효과 설명] (예: 기업 이미지 제고, 매출 증대 등)\n",
      "\n",
      "**3. 발전 방안 (03)**\n",
      "\n",
      "*   **향후 계획:** [프로젝트의 향후 진행 계획 간략하게 설명] (예: 1단계 시제품 개발, 2단계 사용자 테스트 진행 등)\n",
      "*   **기술적 고려 사항:** [프로젝트 진행 시 고려해야 할 기술적인 부분 설명] (예: 데이터 보안, 시스템 확장성 등)\n",
      "*   **자원 및 기술:** [프로젝트 진행에 필요한 자원 및 기술에 대한 간략한 언급]\n",
      "\n",
      "**4. 결론**\n",
      "\n",
      "*   **요약:** 오늘 발표에서는 [프로젝트 이름]의 개요를 살펴보았습니다.\n",
      "*   **질의응답:** 혹시 질문 있으시면 편하게 질문해주세요.\n",
      "\n",
      "**[마지막 화면: 프로젝트 관련 연락처 및 감사 인사]**\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만으로 작성되었으므로, 실제 발표 시에는 프로젝트의 구체적인 내용에 맞춰 수정해야 합니다.\n",
      "*   이미지 설명이 없으므로, 발표 상황에 맞춰 적절한 이미지 자료를 활용하여 발표의 시각적인 효과를 높이는 것이 좋습니다.\n",
      "*   발표 시간과 청중의 수준을 고려하여 내용의 깊이와 범위를 조절해야 합니다.\n",
      "*   발표 자료를 시각적으로 보기 좋게 구성하여 청중의 이해도를 높이는 것이 중요합니다.\n",
      "\n",
      "📄 Page 4 설명:\n",
      "## 발표 대본: AI 발표 모델, 오인용 소개\n",
      "\n",
      "**[시작 화면: 발표 제목과 로고 (오인용)]**\n",
      "\n",
      "안녕하세요, 오늘 저는 AI 발표 모델, 오인용을 소개하게 되어 기쁩니다.\n",
      "\n",
      "**[슬라이드 1: 개요 - 발표는 우리 삶에 얼마나 밀접해 있을까?]**\n",
      "\n",
      "우리는 일상생활에서 얼마나 자주 발표를 접하고 있을까요? 블로그, 뉴스, 카페, 지식인 등 다양한 곳에서 “발표 준비”라는 키워드를 검색해보면 알 수 있듯이, 발표는 우리 삶과 매우 밀접하게 관련되어 있습니다.\n",
      "\n",
      "**[슬라이드 2: 기획 배경]**\n",
      "\n",
      "이러한 배경에서 저희는 발표 준비에 드는 시간과 노력을 줄이고, 보다 효율적인 정보 활용을 돕기 위해 AI 발표 모델, 오인용을 개발하게 되었습니다.\n",
      "\n",
      "**[슬라이드 3: 프로젝트 소개 - 오인용]**\n",
      "\n",
      "오인용은 중요한 내용을 중심으로 발표용 대본을 생성하는 인공지능 모델입니다. 단순히 텍스트를 요약하는 것을 넘어, 발표의 흐름과 논리 구조를 고려하여 자연스러운 대본을 만들어냅니다.\n",
      "\n",
      "**[슬라이드 4: 핵심 기능 - AI 음성 합성 활용]**\n",
      "\n",
      "더 나아가, 오인용은 AI 음성 합성을 활용하여 자동 발표 기능을 제공합니다. 텍스트를 입력하면 AI가 자연스러운 목소리로 읽어주는 것이죠.\n",
      "\n",
      "**[슬라이드 5: 기대 효과 - 효율적인 정보 활용, 일관된 퀄리티, 시간 단축]**\n",
      "\n",
      "오인용은 다음과 같은 기대 효과를 가져다 줄 것입니다.\n",
      "\n",
      "*   **기업, 연구자, 학생 등**이 보다 효율적으로 정보를 활용할 수 있도록 돕습니다.\n",
      "*   **일관된 발표 퀄리티**를 유지할 수 있도록 지원합니다.\n",
      "*   **발표에 드는 시간**을 획기적으로 단축합니다.\n",
      "\n",
      "**[이미지 35, 36, 37 슬라이드에 삽입 - 시각적인 효과를 위한 이미지 활용]**\n",
      "\n",
      "**[마무리]**\n",
      "\n",
      "저희 오인용은 앞으로 발표의 새로운 지평을 열 것입니다. 많은 관심과 기대 부탁드립니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만을 기반으로 작성되었습니다. 실제 발표 시에는 추가적인 정보와 시각 자료를 활용하여 더욱 풍성한 발표를 진행하시기 바랍니다.\n",
      "*   이미지 설명에 제공된 좌표는 슬라이드에 이미지를 삽입할 때 참고 자료로 활용할 수 있습니다.\n",
      "*   발표 대상과 목적에 맞게 대본의 내용과 어조를 조절하는 것이 중요합니다.\n",
      "\n",
      "📄 Page 5 설명:\n",
      "## 발표 대본: 발표 전 불안감, 왜 우리는 불안할까?\n",
      "\n",
      "**1. 시작 (30초)**\n",
      "\n",
      "안녕하세요, 오늘 발표를 맡은 [이름]입니다. 혹시 발표라는 단어를 들으면 어떤 기분이 드나요? 긴장되고 불안한 분들이 많을 거라고 생각합니다. 실제로 많은 직장인들이 발표라는 상황 앞에서 어려움을 겪고 있습니다. 오늘 발표에서는 직장인들이 발표 전에 느끼는 불안감의 원인이 무엇인지, 그리고 그 원인에 대한 통계 결과를 함께 살펴보겠습니다.\n",
      "\n",
      "**2. 발표 배경 및 통계 결과 소개 (1분)**\n",
      "\n",
      "오늘 발표의 배경은 바로 ‘발표 준비’라는 키워드에 대한 고민에서 시작되었습니다. 취업포털 커리어넷에서 직장인 384명을 대상으로 한 설문조사와, 온라인 커뮤니티에서 ‘발표 준비’ 관련 내용을 수집하여 분석했습니다.\n",
      "\n",
      "그 결과, 발표 전 불안감을 느끼는 가장 큰 원인은 **내성적 성격**으로, 응답자의 **31.3%**를 차지했습니다. 그 다음으로는 **실수에 대한 압박감**이 **25%**로 나타났습니다. 이 외에도 **준비 부족(14.6%)**, **무대 공포증(12.5%)**, **질문의 대응이 어려움(10.4%)**, 그리고 **시선에 대한 압박감** 등이 불안감을 유발하는 요인으로 조사되었습니다. (슬라이드에 통계 자료 시각화된 이미지 삽입)\n",
      "\n",
      "**3. 불안감의 원인 심층 분석 (1분 30초)**\n",
      "\n",
      "*   **내성적 성격:** 타고난 성격 때문에 발표 상황 자체가 불편하게 느껴질 수 있습니다.\n",
      "*   **실수에 대한 압박감:** 완벽하게 발표해야 한다는 부담감은 불안감을 증폭시킵니다.\n",
      "*   **준비 부족:** 충분한 연습 없이 발표에 임하면 자신감 부족으로 이어집니다.\n",
      "*   **무대 공포증:** 사람들 앞에서 말하는 것에 대한 극심한 공포는 불안감을 유발합니다.\n",
      "*   **질문의 대응 어려움:** 예상치 못한 질문에 대한 답변이 두려워 불안감을 느낄 수 있습니다.\n",
      "*   **시선에 대한 압박감:** 청중의 시선이 부담스러워 발표에 집중하기 어려워집니다.\n",
      "\n",
      "**4. 결론 및 제언 (30초)**\n",
      "\n",
      "발표 전 불안감은 많은 직장인들이 겪는 보편적인 현상입니다. 하지만 이러한 불안감의 원인을 파악하고, 자신에게 맞는 해결 방안을 찾는다면 발표에 대한 부담을 줄이고 자신감을 높일 수 있습니다. 충분한 준비와 연습, 그리고 긍정적인 마음가짐이 중요합니다.\n",
      "\n",
      "오늘 발표가 여러분의 발표 불안감을 조금이나마 해소하는 데 도움이 되었기를 바랍니다. 경청해주셔서 감사합니다.\n",
      "\n",
      "**발표 팁:**\n",
      "\n",
      "*   통계 자료를 시각적으로 표현하여 청중의 이해도를 높입니다.\n",
      "*   자신의 경험을 예시로 들어 설명하면 더욱 공감대를 형성할 수 있습니다.\n",
      "*   청중과의 소통을 위해 질문을 던지거나, 간단한 퀴즈를 활용할 수 있습니다.\n",
      "*   자신감 있는 목소리와 표정으로 발표합니다.\n",
      "\n",
      "📄 Page 6 설명:\n",
      "## 발표 대본: 최초의 발표하는 인공지능 모델 - 오인용\n",
      "\n",
      "**[시작 화면: 오인용 로고 또는 프로젝트 관련 이미지]**\n",
      "\n",
      "안녕하세요, 오늘 저는 획기적인 인공지능 모델, '오인용'을 소개합니다. 이 모델은 단순한 정보 제공을 넘어, 실제 발표를 수행하는 데 특화되어 있습니다.\n",
      "\n",
      "**1. 개요**\n",
      "\n",
      "오인용은 발표용 대본을 자동으로 생성하고, AI 음성 합성을 활용하여 실제 발표를 수행하는 인공지능 모델입니다.  지금까지의 AI는 정보를 제공하는 데 집중해 왔지만, 오인용은 정보를 효과적으로 전달하는 '발표'라는 과정을 자동화하는 데 목표를 두고 개발되었습니다.\n",
      "\n",
      "**2. 주요 기능**\n",
      "\n",
      "오인용은 다음과 같은 주요 기능을 제공합니다.\n",
      "\n",
      "*   **자동 발표용 대본 생성:** 핵심 내용을 중심으로 발표용 대본을 자동으로 생성합니다.\n",
      "*   **AI 음성 합성:** 생성된 대본을 자연스러운 음성으로 합성하여 실제 발표를 수행합니다.\n",
      "\n",
      "**3. 기대 효과**\n",
      "\n",
      "오인용은 다양한 분야에서 긍정적인 영향을 미칠 것으로 기대됩니다.\n",
      "\n",
      "*   **기업:**  정보 전달의 효율성을 높이고, 일관된 퀄리티의 발표를 가능하게 합니다.\n",
      "*   **연구자:** 연구 결과를 효과적으로 공유하고, 발표 준비 시간을 단축합니다.\n",
      "*   **학생:**  발표 연습 부담을 줄이고, 학습 효과를 높입니다.\n",
      "\n",
      "**4. 향후 발전 방향**\n",
      "\n",
      "오인용은 현재 개발 단계에 있으며, 앞으로 다음과 같은 방향으로 발전할 계획입니다.\n",
      "\n",
      "*   **실시간 상호작용:** 청중의 반응에 맞춰 즉흥적으로 대응할 수 있도록 실시간 상호작용 기능을 추가합니다.\n",
      "*   **인간처럼 말하기:** 더욱 자연스럽고 인간적인 표현을 사용하도록 개선합니다.\n",
      "*   **발표 스타일 개인화:** 사용자의 선호도에 맞춰 발표 스타일을 개인화할 수 있도록 기능을 추가합니다.\n",
      "*   **디지털 아바타 생성:** 발표를 수행하는 디지털 아바타를 생성하여 시각적인 효과를 더합니다.\n",
      "*   **도메인 확장:** 다양한 분야에 적용할 수 있도록 도메인 확장을 추진합니다.\n",
      "\n",
      "**[마무리 화면: 오인용 로고 및 연락처 정보]**\n",
      "\n",
      "오인용은 앞으로 발표의 새로운 지평을 열 것입니다.  감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만을 기반으로 작성되었으며, 실제 발표 시에는 추가적인 정보와 자료를 활용하여 내용을 보완해야 합니다.\n",
      "*   발표 스타일, 어조, 속도 등을 조절하여 청중에게 더욱 효과적으로 전달할 수 있도록 연습하는 것이 중요합니다.\n",
      "*   이미지 설명에 제공된 좌표 정보는 이미지 삽입 시 참고 자료로 활용할 수 있습니다.\n",
      "\n",
      "📄 Page 7 설명:\n",
      "## 발표 대본 (초안) - 프로젝트 기획\n",
      "\n",
      "**[시작 화면: 프로젝트 제목 및 발표자 정보]**\n",
      "\n",
      "안녕하세요, 오늘 발표를 맡은 [발표자 이름]입니다. 오늘 발표에서는 프로젝트 기획에 대해 말씀드리겠습니다.\n",
      "\n",
      "**[슬라이드 1: 프로젝트 기획 제목]**\n",
      "\n",
      "오늘 발표의 주요 내용은 다음과 같습니다.\n",
      "\n",
      "*   **프로젝트 기획의 중요성**\n",
      "*   **프로젝트 방향성 설정**\n",
      "*   **[추가 내용 - 페이지 내용에 따라 추가]**\n",
      "\n",
      "**[슬라이드 2: 프로젝트 기획의 중요성]**\n",
      "\n",
      "프로젝트 기획은 성공적인 프로젝트의 **가장 중요한 첫걸음**입니다. 튼튼한 기획 없이는 아무리 뛰어난 아이디어나 기술도 제대로 구현될 수 없습니다. \n",
      "\n",
      "*   명확한 목표 설정\n",
      "*   자원 효율성 극대화\n",
      "*   리스크 관리 및 예측\n",
      "\n",
      "**[슬라이드 3: 프로젝트 방향성 설정]**\n",
      "\n",
      "다음으로, 프로젝트 방향성을 설정하는 과정입니다. 이는 프로젝트의 전체적인 흐름과 목표를 정의하는 핵심적인 단계입니다.\n",
      "\n",
      "*   **[구체적인 방향성 설정 방법 설명 - 페이지 내용에 따라 추가]**\n",
      "*   **[예시 또는 사례 제시 - 페이지 내용에 따라 추가]**\n",
      "\n",
      "**[슬라이드 4: 추가 내용 (페이지 내용에 따라 추가)]**\n",
      "\n",
      "[페이지 내용에 따라 추가될 내용들을 정리하여 설명합니다. 예를 들어, 목표 설정 방법, 일정 계획, 예산 관리, 팀 구성 등]\n",
      "\n",
      "**[마무리 화면: 질문 및 답변]**\n",
      "\n",
      "오늘 발표는 여기까지입니다. 경청해주셔서 감사합니다. 혹시 질문 있으신 분은 편하게 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만으로 작성된 초안입니다.\n",
      "*   실제 발표 시에는 페이지 내용, 이미지 설명, 발표 시간 등을 고려하여 내용을 수정하고 보완해야 합니다.\n",
      "*   발표 자료에 맞는 시각 자료 (이미지, 그래프, 표 등)를 활용하여 발표의 효과를 높이세요.\n",
      "*   발표 내용을 더욱 풍성하게 만들기 위해 관련 자료를 추가적으로 조사하고 내용을 보완하는 것이 좋습니다.\n",
      "*   발표 연습을 충분히 하여 자연스럽고 자신감 있는 발표를 할 수 있도록 준비하세요.\n",
      "\n",
      "📄 Page 8 설명:\n",
      "## 발표 대본 (기술 스택 및 기획)\n",
      "\n",
      "**시작 (30초)**\n",
      "\n",
      "안녕하세요, 오늘 발표에서는 [프로젝트/서비스 이름]의 기술 스택과 기획에 대해 말씀드리겠습니다. 저희는 [프로젝트/서비스의 간략한 소개]를 목표로 하고 있으며, 이를 위해 다양한 기술들을 활용하고 있습니다.\n",
      "\n",
      "**1. 기술 스택 소개 (2분)**\n",
      "\n",
      "저희 프로젝트의 핵심은 AI Agent를 활용하여 [프로젝트/서비스의 핵심 기능]을 수행하는 것입니다. 이를 위해 다음과 같은 기술 스택을 사용합니다.\n",
      "\n",
      "*   **FastAPI:** AI 모델을 서빙하고 사용자 요청을 처리하는 역할을 합니다. 빠른 성능과 효율적인 API 개발을 지원합니다.\n",
      "*   **Streamlit:** AI 서비스를 사용자에게 웹 애플리케이션 형태로 제공하는 UI 프레임워크입니다. 직관적인 인터페이스를 통해 사용자 경험을 향상시킵니다.\n",
      "*   **LangChain:** LLM, Prompt, RAG 등의 AI Agent가 수행하는 과정을 하나의 Chain으로 묶는 데 사용됩니다. 복잡한 AI 워크플로우를 쉽게 구축하고 관리할 수 있도록 돕습니다.\n",
      "*   **Ollama:** API 없이 로컬 환경에서 AI 모델을 직접 실행할 수 있도록 지원하여 보안과 성능을 최적화합니다.\n",
      "*   **Chroma DB:** Vector DB로, 문서를 저장하고 빠르게 검색할 수 있도록 합니다.\n",
      "*   **OpenAI, Hugging Face:** 다양한 사전 학습된 모델을 검색하고 활용할 수 있는 플랫폼으로, 프로젝트에 필요한 모델을 선택하고 적용하는 데 활용합니다.\n",
      "*   **GitHub:** 코드 저장, 버전 관리 및 협업을 위해 사용됩니다.\n",
      "\n",
      "**2. 기획 및 자원 (1분 30초)**\n",
      "\n",
      "저희는 랭체인과 자연어 처리, 딥러닝에 관련된 위키독스를 크롤링하여 벡터 임베딩 후 VectorDB에 적재할 예정입니다. 이를 통해 [프로젝트/서비스의 핵심 기능]을 위한 풍부한 지식 기반을 구축할 것입니다.\n",
      "\n",
      "**3. 기대 효과 및 마무리 (30초)**\n",
      "\n",
      "저희는 이러한 기술 스택과 기획을 통해 [프로젝트/서비스의 기대 효과]를 달성할 수 있을 것으로 기대합니다. 앞으로도 지속적인 기술 개발과 사용자 피드백을 통해 [프로젝트/서비스]를 발전시켜 나가겠습니다.\n",
      "\n",
      "경청해주셔서 감사합니다. 혹시 질문 있으신 분은 편하게 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만을 기반으로 작성되었으며, 실제 발표 내용에 맞게 수정해야 합니다.\n",
      "*   각 기술 스택에 대한 구체적인 활용 방안을 추가하면 더욱 풍성한 발표가 될 수 있습니다.\n",
      "*   이미지 설명을 활용하여 시각적인 자료를 함께 제시하면 청중의 이해도를 높일 수 있습니다.\n",
      "*   발표 시간과 청중의 수준을 고려하여 내용을 조절해야 합니다.\n",
      "*   발표 시 자신감 있는 태도와 명확한 발음으로 전달하는 것이 중요합니다.\n",
      "\n",
      "📄 Page 9 설명:\n",
      "## 발표 대본 (초안)\n",
      "\n",
      "**제목:** [발표 제목 - 예: 위키독스 기반 AI 지식 검색 시스템 구축]\n",
      "\n",
      "**1. 서론 (30초)**\n",
      "\n",
      "* 안녕하세요, [이름]입니다. 오늘 저는 [발표 제목]에 대해 발표하겠습니다.\n",
      "* [발표 주제에 대한 간략한 소개 및 중요성 언급 - 예: 빠르게 변화하는 AI 기술 트렌드를 따라잡기 위해, 위키독스 기반의 AI 지식 검색 시스템을 구축하여 정보 접근성을 높이고자 합니다.]\n",
      "* 오늘 발표에서는 시스템 구축에 사용될 자원과 기술 스택에 대해 자세히 설명드리겠습니다.\n",
      "\n",
      "**2. 본론: 사용 자원 및 기술 스택 (2분)**\n",
      "\n",
      "* **2.1. 사용 자원:**\n",
      "    * 핵심 자원은 랭체인(Lang Chain), 자연어 처리(NLP), 딥러닝 관련 위키독스입니다.\n",
      "    * 이 위키독스들을 크롤링하여 벡터 임베딩을 수행하고, VectorDB에 적재할 예정입니다. (간단히 설명: 위키독스 내용을 컴퓨터가 이해할 수 있는 벡터 형태로 변환하여 데이터베이스에 저장합니다.)\n",
      "\n",
      "* **2.2. 기술 스택:**\n",
      "    * **FastAPI:** AI 모델을 서빙하고 사용자 요청을 처리하는 역할을 담당합니다. (간단히 설명: 사용자 요청을 받아 AI 모델에 전달하고 결과를 사용자에게 전달하는 역할을 합니다.)\n",
      "    * **Streamlit:** AI 서비스를 웹 애플리케이션 형태로 제공하는 UI 프레임워크입니다. (간단히 설명: 사용자가 쉽게 사용할 수 있는 웹 인터페이스를 제공합니다.)\n",
      "    * **Lang Chain:** LLM, Prompt, RAG 등의 AI Agent가 수행하는 과정을 하나의 Chain으로 묶는 데 사용됩니다. (간단히 설명: 여러 AI 기능을 연결하여 복잡한 작업을 수행할 수 있도록 합니다.)\n",
      "    * **Ollama:** API 없이 로컬 환경에서 AI 모델을 직접 실행할 수 있어 보안과 성능을 최적화 가능합니다. (간단히 설명: 외부 API 의존성을 줄이고, 모델 실행 속도를 향상시킵니다.)\n",
      "    * **Chroma DB:** Vector DB로, 문서를 저장하고 빠르게 검색할 수 있도록 하기 위해 사용됩니다. (간단히 설명: 저장된 정보를 효율적으로 검색하여 사용자에게 필요한 정보를 제공합니다.)\n",
      "    * **OpenAI:** 다양한 사전 학습된 모델을 검색하고 활용할 수 있는 플랫폼입니다. (간단히 설명: 최신 AI 모델을 쉽게 활용할 수 있도록 지원합니다.)\n",
      "    * **GitHub:** 코드 저장, 버전 관리 및 협업을 위해 사용됩니다. (간단히 설명: 팀원들과 함께 코드를 관리하고 개발 과정을 추적합니다.)\n",
      "    * **Hugging Face:** Vector DB에 저장하기 위해 Embedding 모델로써 사용됩니다. (간단히 설명: 텍스트 데이터를 벡터 형태로 변환하는 데 사용됩니다.)\n",
      "\n",
      "**3. 결론 (30초)**\n",
      "\n",
      "* 지금까지 위키독스 기반 AI 지식 검색 시스템 구축에 사용될 자원과 기술 스택에 대해 설명드렸습니다.\n",
      "* 이 시스템을 통해 정보 접근성을 높이고, AI 기술 활용도를 향상시킬 수 있을 것으로 기대합니다.\n",
      "* 질문 있으시면 편하게 질문해주세요. 감사합니다.\n",
      "\n",
      "**참고 사항:**\n",
      "\n",
      "* 이미지 설명은 발표 자료에 이미지를 삽입할 때 참고하여 적절한 위치에 배치해주세요.\n",
      "* 발표 시간과 청중의 수준에 맞춰 내용을 조절해주세요.\n",
      "* 각 기술에 대한 더 자세한 설명이 필요하면 추가적인 자료를 준비해주세요.\n",
      "* 발표 자료에 시각적인 자료 (이미지, 그래프 등)를 적극 활용하여 청중의 이해도를 높여주세요.\n",
      "* 발표 연습을 충분히 하여 자연스럽게 발표할 수 있도록 준비해주세요.\n",
      "\n",
      "📄 Page 10 설명:\n",
      "## 발표 대본: 저희 발표 안합니다!\n",
      "\n",
      "**[서론]**\n",
      "\n",
      "안녕하십니까, 정재식과 이진규입니다. 오늘 저희는 다소 파격적인 주제로 여러분 앞에 섰습니다. 바로 \"저희 발표 안합니다!\" 입니다. 네, 그렇습니다. 여러분의 기대와 달리, 오늘 저희는 발표를 진행하지 않겠습니다. (잠시 웃음 유도)\n",
      "\n",
      "**[본론 - 시스템 구조 소개 (발표 대신 시각 자료 활용)]**\n",
      "\n",
      "저희가 발표를 하지 않는 이유는, 저희가 개발한 시스템의 핵심은 시각적으로 이해하는 것이 더 효과적이라고 판단했기 때문입니다. (화면 전환 - 시스템 구조도)\n",
      "\n",
      "보시는 것처럼 저희 시스템은 크게 User, Vector DB, LLM(오인용), Document의 네 가지 요소로 구성되어 있습니다. \n",
      "\n",
      "*   **User:** 사용자가 시스템과 상호작용하는 인터페이스입니다.\n",
      "*   **Vector DB:** 문서를 벡터 형태로 저장하고 검색하는 데이터베이스입니다.\n",
      "*   **LLM(오인용):** Large Language Model을 활용하여 문서 내용을 이해하고 답변을 생성합니다. (오인용이라는 점을 강조하며, 실제 사용 방식에 대한 추가 설명 가능)\n",
      "*   **Document:** 시스템이 처리하는 문서 데이터입니다.\n",
      "\n",
      "(각 요소 간의 연결 관계를 설명하며, 이미지 ID 70, 71, 72, 74에 해당하는 시각 자료를 활용하여 설명)\n",
      "\n",
      "**[본론 - 발표를 하지 않는 이유 설명]**\n",
      "\n",
      "저희는 이 시스템의 복잡한 상호작용을 글로 설명하는 것보다, 시각 자료를 통해 한눈에 이해시키는 것이 더 효과적이라고 생각했습니다. 발표라는 형식에 얽매여 핵심 내용을 제대로 전달하기 어렵다고 판단했습니다.\n",
      "\n",
      "**[결론]**\n",
      "\n",
      "저희는 \"저희 발표 안합니다!\"라는 파격적인 선택을 통해, 기존의 틀을 벗어나 더 효과적인 정보 전달 방식을 모색하고자 했습니다. 오늘 준비한 시각 자료를 통해 저희 시스템의 핵심을 이해해주셨기를 바랍니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만을 기반으로 작성되었으며, 실제 발표 내용과 다를 수 있습니다.\n",
      "*   발표 시에는 시각 자료를 적극적으로 활용하여 청중의 이해를 돕는 것이 중요합니다.\n",
      "*   \"LLM(오인용)\" 부분은 실제 사용 방식에 대한 추가 설명을 통해 오해를 방지해야 합니다.\n",
      "*   청중의 반응을 살피면서 유연하게 대본을 조절하는 것이 좋습니다.\n",
      "*   \"저희 발표 안합니다!\"라는 주제를 활용하여 재미있고 기억에 남는 발표를 만들 수 있습니다.\n",
      "\n",
      "📄 Page 11 설명:\n",
      "## 발표 대본 (초안)\n",
      "\n",
      "**제목:** 서비스 기능 소개\n",
      "\n",
      "**발표자:** (이름)\n",
      "\n",
      "---\n",
      "\n",
      "**1. 시작 (30초)**\n",
      "\n",
      "* 안녕하세요, (이름)입니다. 오늘 저는 저희 서비스의 주요 기능들을 간략하게 소개해 드리겠습니다. 이 서비스는 (서비스의 간단한 설명 - 예를 들어, 데이터 분석을 돕는 서비스)를 목표로 합니다.\n",
      "\n",
      "**2. 주요 기능 소개 (각 기능별 1분 ~ 1분 30초)**\n",
      "\n",
      "* **서비스 UI 구성:** (화면 공유하며) 먼저 서비스의 사용자 인터페이스(UI)를 살펴보겠습니다. 직관적인 디자인으로 사용자가 쉽게 기능을 이용할 수 있도록 구성했습니다. (UI의 주요 특징 설명 - 예를 들어, 메뉴 구조, 검색 기능 등)\n",
      "* **02. 기획:** (간단하게 기획 의도 설명 - 예를 들어, 사용자 편의성을 최우선으로 고려하여 기획했습니다.)\n",
      "* **시스템 구조:** (시스템 구조에 대한 간략한 설명 - 예를 들어, 백엔드와 프론트엔드의 역할 분담, 데이터베이스 구조 등. 너무 기술적인 내용은 피하고 핵심만 전달)\n",
      "* **발표 자료 업로드:** (화면 공유하며) 사용자는 이 기능을 통해 발표 자료를 쉽게 업로드할 수 있습니다. (업로드 방식 설명 - 예를 들어, 파일 선택, 드래그 앤 드롭 등)\n",
      "* **처리완료된 자료 시각화:** (화면 공유하며) 업로드된 자료는 자동으로 처리되어 시각화된 형태로 제공됩니다. (시각화 방식 설명 - 예를 들어, 그래프, 차트 등) 이를 통해 사용자는 데이터를 보다 직관적으로 이해할 수 있습니다.\n",
      "* **처리된 자료 다운로드:** (화면 공유하며) 처리된 자료는 사용자가 필요에 따라 다운로드하여 활용할 수 있습니다. (다운로드 형식 설명 - 예를 들어, CSV, Excel 등)\n",
      "\n",
      "**3. 마무리 (30초)**\n",
      "\n",
      "* 지금까지 저희 서비스의 주요 기능들을 살펴보았습니다. 저희 서비스는 (서비스의 핵심 가치 - 예를 들어, 데이터 분석 효율성 향상, 의사 결정 지원 등)을 통해 사용자에게 실질적인 도움을 제공할 수 있도록 노력하겠습니다. 질문 있으시면 언제든지 편하게 질문해주세요. 감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고 사항:**\n",
      "\n",
      "* 위 대본은 초안이며, 실제 발표 상황에 맞춰 내용을 수정하고 보완해야 합니다.\n",
      "* 각 기능별로 화면 공유를 통해 시각적인 자료를 함께 제시하면 더욱 효과적인 발표가 될 수 있습니다.\n",
      "* 발표 시간과 청중의 수준을 고려하여 내용의 깊이와 난이도를 조절해야 합니다.\n",
      "* 이미지 설명에 있는 image_id는 실제 이미지와 연결되어야 합니다.\n",
      "* 발표 자료 업로드, 처리완료된 자료 시각화, 처리된 자료 다운로드 기능에 대한 구체적인 사용 방법을 예시를 들어 설명하면 청중의 이해도를 높일 수 있습니다.\n",
      "* \"02. 기획\"은 내용이 추상적이므로, 구체적인 기획 의도를 설명하는 것이 좋습니다. 예를 들어, \"사용자 편의성을 최우선으로 고려하여, 데이터 분석 과정을 최대한 간소화하기 위해 기획했습니다.\" 와 같이 설명할 수 있습니다.\n",
      "\n",
      "\n",
      "📄 Page 12 설명:\n",
      "## 발표 대본 (초안)\n",
      "\n",
      "**제목:** 서비스 개발 주요 내용 발표\n",
      "\n",
      "**발표자:** (이름)\n",
      "\n",
      "---\n",
      "\n",
      "**1. 시작 (30초)**\n",
      "\n",
      "* 안녕하세요, (이름)입니다. 오늘 저는 저희 서비스 개발 과정에서 중요한 부분을 다룬 내용을 발표하고자 합니다.\n",
      "* 오늘 발표에서는 서비스 UI 구성, 기획, 그리고 시스템 구조에 대해 간략하게 설명드리겠습니다.\n",
      "\n",
      "**2. 서비스 UI 구성 (1분)**\n",
      "\n",
      "* 먼저 서비스 UI 구성에 대해 말씀드리겠습니다. (이미지 84를 보여주며) 이 이미지는 UI 구성의 핵심적인 부분을 보여줍니다.\n",
      "* (UI 구성에 대한 구체적인 설명 - 예를 들어, 주요 화면 구성, 사용자 경험 개선 노력 등)\n",
      "* 사용자 편의성을 최우선으로 고려하여 UI를 설계했습니다.\n",
      "\n",
      "**3. 기획 (1분)**\n",
      "\n",
      "* 다음으로 서비스 기획 단계에 대해 말씀드리겠습니다.\n",
      "* (기획 단계에서 중요하게 고려한 사항 설명 - 예를 들어, 사용자 요구사항 분석, 기능 정의, 목표 설정 등)\n",
      "* 사용자 중심의 서비스를 만들기 위해 다양한 의견을 수렴하고 반영했습니다.\n",
      "\n",
      "**4. 시스템 구조 (1분)**\n",
      "\n",
      "* 마지막으로 시스템 구조에 대해 설명드리겠습니다.\n",
      "* (시스템 구조에 대한 간략한 설명 - 예를 들어, 아키텍처 개요, 주요 컴포넌트, 데이터 흐름 등)\n",
      "* 안정적이고 확장 가능한 시스템 구축을 목표로 설계되었습니다.\n",
      "\n",
      "**5. 마무리 (30초)**\n",
      "\n",
      "* 오늘 발표에서는 서비스 UI 구성, 기획, 그리고 시스템 구조에 대해 간략하게 살펴보았습니다.\n",
      "* 앞으로도 사용자에게 더 나은 서비스를 제공하기 위해 지속적으로 노력하겠습니다.\n",
      "* 질문 있으시면 편하게 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "* 위 대본은 초안이며, 실제 발표 내용에 맞춰 수정해야 합니다.\n",
      "* 각 항목별 설명 시간을 조절하여 전체 발표 시간을 맞추세요.\n",
      "* 이미지 84를 활용하여 시각적인 효과를 더하세요.\n",
      "* 발표 자료 업로드, 처리완료된 자료 시각화, 처리된 자료 다운로드 기능에 대한 언급은 관련 페이지 내용이 더 필요할 경우 추가할 수 있습니다.\n",
      "* 발표 대상에 맞춰 전문 용어 사용 정도를 조절하세요.\n",
      "* 자신감 있는 목소리와 표정으로 발표하세요.\n",
      "\n",
      "📄 Page 13 설명:\n",
      "## 발표 대본 (초안)\n",
      "\n",
      "**제목:** [프로젝트명 - 핵심 기술 및 작업 흐름 소개]\n",
      "\n",
      "**대상:** [청중 명시 - 예: 팀원, 투자자, 발표회 심사위원 등]\n",
      "\n",
      "---\n",
      "\n",
      "**1. 시작 (30초)**\n",
      "\n",
      "*   **인사:** 안녕하세요, [이름]입니다. 오늘 [프로젝트명]에 대한 발표를 진행하게 되어 기쁩니다.\n",
      "*   **간략한 소개:** 저희는 [프로젝트 목표]를 달성하기 위해 노력하고 있습니다. 오늘 발표에서는 프로젝트의 핵심 기술과 작업 흐름을 중심으로 설명드리겠습니다.\n",
      "\n",
      "**2. 프로젝트 개요 (1분)**\n",
      "\n",
      "*   **기획 배경:** [프로젝트가 시작된 배경, 문제점, 해결하고자 하는 목표 등을 간략하게 설명합니다. 관련 이미지를 활용하면 좋습니다.]\n",
      "*   **프로젝트 소개:** [프로젝트의 핵심 기능, 주요 특징, 기대 효과 등을 설명합니다. 청중이 쉽게 이해할 수 있도록 비유나 예시를 활용하는 것이 좋습니다.]\n",
      "*   **프로젝트 방향성:** [프로젝트의 장기적인 목표와 발전 방향을 제시합니다.]\n",
      "\n",
      "**3. 핵심 기술 및 자원 (2분)**\n",
      "\n",
      "*   **기술 스택:** 저희 프로젝트는 다음과 같은 기술 스택을 활용합니다.\n",
      "    *   **Fast API:** [Fast API의 역할과 장점을 간략하게 설명합니다.]\n",
      "    *   **Streamlit:** [Streamlit의 역할과 장점을 간략하게 설명합니다.]\n",
      "    *   **Lang Chain:** [Lang Chain의 역할과 장점을 간략하게 설명합니다.]\n",
      "    *   **Ollama:** [Ollama의 역할과 장점을 간략하게 설명합니다.]\n",
      "    *   **Chroma DB:** [Chroma DB의 역할과 장점을 간략하게 설명합니다.]\n",
      "    *   **OpenAI:** [OpenAI의 역할과 장점을 간략하게 설명합니다.]\n",
      "    *   **Hugging Face:** [Hugging Face의 역할과 장점을 간략하게 설명합니다.]\n",
      "*   **자원:** [프로젝트에 투입된 인력, 예산, 데이터 등 자원을 간략하게 소개합니다.]\n",
      "\n",
      "**4. 작업 흐름 (2분)**\n",
      "\n",
      "*   **작업 흐름도 소개:** [작업 흐름도를 화면에 띄우고, 각 단계별 주요 활동을 설명합니다. 각 단계가 어떻게 기술 스택과 연결되는지 보여주는 것이 중요합니다.]\n",
      "    *   [예시: 02. 기획 단계에서는 Fast API를 활용하여…]\n",
      "    *   [예시: Work Flow 단계에서는 Lang Chain을 사용하여…]\n",
      "*   **각 단계별 중요 포인트:** [각 단계에서 발생할 수 있는 문제점과 해결 방안을 간략하게 언급합니다.]\n",
      "\n",
      "**5. 발전 방안 (1분)**\n",
      "\n",
      "*   **향후 계획:** [프로젝트의 향후 발전 방향과 계획을 제시합니다. 새로운 기능 추가, 성능 개선, 시장 확대 등 구체적인 내용을 포함하는 것이 좋습니다.]\n",
      "*   **기대 효과:** [프로젝트의 성공적인 완료를 통해 얻을 수 있는 기대 효과를 강조합니다.]\n",
      "\n",
      "**6. 마무리 (30초)**\n",
      "\n",
      "*   **요약:** 오늘 발표 내용을 간략하게 요약합니다.\n",
      "*   **감사 인사:** 경청해주셔서 감사합니다.\n",
      "*   **질의응답:** 질문 있으시면 편하게 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고 사항:**\n",
      "\n",
      "*   위 대본은 초안이며, 실제 발표 내용에 맞춰 수정해야 합니다.\n",
      "*   각 기술에 대한 자세한 설명은 청중의 수준에 맞춰 조절해야 합니다.\n",
      "*   이미지를 적극적으로 활용하여 시각적인 효과를 높이는 것이 좋습니다.\n",
      "*   발표 시간과 내용을 고려하여 각 섹션의 분량을 조절해야 합니다.\n",
      "*   발표 연습을 충분히 하여 자연스럽게 전달하는 것이 중요합니다.\n",
      "*   청중과의 소통을 위해 질문을 유도하고 적극적으로 답변하는 것이 좋습니다.\n",
      "\n",
      "📄 Page 14 설명:\n",
      "## 발표 대본 (프로젝트 방향성)\n",
      "\n",
      "**[시작 화면: 프로젝트 제목 및 발표자 정보]**\n",
      "\n",
      "안녕하세요, [발표자 이름]입니다. 오늘 저는 [프로젝트 이름]의 **프로젝트 방향성**에 대해 발표하겠습니다.\n",
      "\n",
      "**[슬라이드 전환: 프로젝트 방향성 제목 슬라이드]**\n",
      "\n",
      "우리가 이 프로젝트를 시작하게 된 배경은 [간단하게 프로젝트 시작 배경 설명 - 페이지 텍스트에 언급되어 있지 않으므로 추론하여 작성].  이러한 배경을 바탕으로, 우리는 [프로젝트 이름]을 통해 [프로젝트의 궁극적인 목표]를 달성하고자 합니다.\n",
      "\n",
      "**[슬라이드 전환: 프로젝트 방향성 상세 내용 슬라이드 - 페이지 텍스트에 내용이 없어 추론하여 작성]**\n",
      "\n",
      "프로젝트 방향성을 명확히 하기 위해, 우리는 다음과 같은 핵심 가치를 기준으로 프로젝트를 진행할 것입니다.\n",
      "\n",
      "*   **[핵심 가치 1]:** [핵심 가치 1에 대한 구체적인 설명 및 예시]\n",
      "*   **[핵심 가치 2]:** [핵심 가치 2에 대한 구체적인 설명 및 예시]\n",
      "*   **[핵심 가치 3]:** [핵심 가치 3에 대한 구체적인 설명 및 예시]\n",
      "\n",
      "이러한 핵심 가치를 바탕으로, 우리는 [프로젝트의 주요 목표 1], [프로젝트의 주요 목표 2], 그리고 [프로젝트의 주요 목표 3]을 달성하는 데 집중할 것입니다.\n",
      "\n",
      "**[슬라이드 전환: 이미지 슬라이드 - 이미지 설명이 없음]**\n",
      "\n",
      "[이미지가 있다면 이미지에 대한 간단한 설명. 이미지가 없다면, \"이 슬라이드는 프로젝트 방향성을 시각적으로 보여주기 위한 슬라이드입니다.\"]\n",
      "\n",
      "**[슬라이드 전환: 결론 슬라이드]**\n",
      "\n",
      "오늘 발표를 통해 [프로젝트 이름]의 방향성을 명확히 공유했습니다.  우리는 [프로젝트 이름]을 통해 [프로젝트의 궁극적인 목표]를 달성하고, [기대되는 긍정적인 결과]를 가져올 수 있도록 최선을 다하겠습니다.\n",
      "\n",
      "경청해주셔서 감사합니다. 혹시 질문 있으신 분은 편하게 질문해주세요.\n",
      "\n",
      "**[마무리 화면: 발표자 정보 및 감사 인사]**\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보가 매우 제한적이므로, 추론을 통해 작성되었습니다. 실제 발표 시에는 페이지 텍스트를 기반으로 내용을 보충하고 수정해야 합니다.\n",
      "*   각 슬라이드에 맞는 시각 자료 (이미지, 그래프, 차트 등)를 활용하여 발표의 효과를 높일 수 있습니다.\n",
      "*   발표 시간과 청중의 특성을 고려하여 대본의 내용을 조절해야 합니다.\n",
      "*   발표 연습을 충분히 하여 자연스럽고 자신감 있는 모습을 보여주는 것이 중요합니다.\n",
      "*   **[ ]** 안의 내용은 실제 프로젝트에 맞게 채워 넣으세요.\n",
      "\n",
      "📄 Page 15 설명:\n",
      "## 발표 대본 (초안)\n",
      "\n",
      "**제목:** 발표하는 인공지능 모델: 오인용\n",
      "\n",
      "**1. 시작 (30초)**\n",
      "\n",
      "* **(밝고 자신감 있는 목소리로)** 안녕하세요, 오늘 저는 발표하는 인공지능 모델, '오인용'에 대해 소개해 드리겠습니다.\n",
      "* **(간단한 질문으로 청중의 흥미 유도)** 혹시 발표 준비에 어려움을 느껴보신 적 있으신가요? 시간과 노력이 많이 필요하고, 일관된 퀄리티를 유지하기 어려울 때도 있죠.\n",
      "* **(문제 해결 제시)** '오인용'은 이러한 어려움을 해결하고, 보다 효율적인 정보 활용을 가능하게 하는 혁신적인 솔루션입니다.\n",
      "\n",
      "**2. 오인용 소개 (1분)**\n",
      "\n",
      "* **(핵심 기능 소개)** '오인용'은 발표용 대본 생성, AI 음성 합성, 디지털 아바타 생성 등 다양한 기능을 제공합니다.\n",
      "* **(구체적인 기능 설명)**\n",
      "    * **발표용 대본 생성:** 중요한 내용을 중심으로 발표용 대본을 자동으로 생성합니다.\n",
      "    * **AI 음성 합성:** 자연스러운 음성으로 발표를 자동화합니다.\n",
      "    * **디지털 아바타 생성:** 발표를 하는 디지털 아바타를 생성하여 더욱 몰입감 있는 경험을 제공합니다.\n",
      "* **(목표 청중 언급)** 기업, 연구자, 학생 등 다양한 분야의 사용자들이 '오인용'을 통해 효율적인 정보 활용이 가능합니다.\n",
      "\n",
      "**3. 기대 효과 (1분)**\n",
      "\n",
      "* **(핵심적인 이점 강조)** '오인용'은 다음과 같은 기대 효과를 제공합니다.\n",
      "    * **일괄된 발표 퀄리티:** 모든 발표의 퀄리티를 균일하게 유지합니다.\n",
      "    * **발표 시간 단축:** 발표 준비에 소요되는 시간을 획기적으로 줄여줍니다.\n",
      "* **(구체적인 예시)** 예를 들어, 연구자들은 복잡한 연구 결과를 쉽게 발표할 수 있고, 학생들은 발표 불안감을 줄이고 자신감을 얻을 수 있습니다.\n",
      "\n",
      "**4. 발전 방향 (30초)**\n",
      "\n",
      "* **(향후 계획 제시)** 앞으로 '오인용'은 다음과 같은 방향으로 발전할 것입니다.\n",
      "    * **실시간 상호작용:** 청중과의 실시간 상호작용 기능을 추가하여 더욱 생동감 있는 발표를 가능하게 합니다.\n",
      "    * **인간처럼 말하기:** 더욱 자연스럽고 인간적인 음성 표현을 구현합니다.\n",
      "    * **발표 스타일의 개인화:** 사용자의 취향에 맞는 다양한 발표 스타일을 제공합니다.\n",
      "    * **도메인 확장:** 다양한 분야에 적용될 수 있도록 기능을 확장합니다.\n",
      "\n",
      "**5. 마무리 (30초)**\n",
      "\n",
      "* **(요약 및 강조)** '오인용'은 발표의 새로운 지평을 열고, 정보 활용의 효율성을 극대화하는 강력한 도구가 될 것입니다.\n",
      "* **(감사 인사 및 질문 유도)** 경청해주셔서 감사합니다. 혹시 질문 있으신 분은 편하게 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "* 위 대본은 초안이며, 실제 발표 상황에 맞춰 수정 및 보완해야 합니다.\n",
      "* 이미지 설명에 따른 이미지 삽입을 고려하여 시각적인 효과를 높일 수 있습니다.\n",
      "* 발표 속도와 목소리 톤을 조절하여 청중의 집중도를 높이는 것이 중요합니다.\n",
      "* 실제 발표 시에는 자신감 있는 태도와 밝은 표정을 유지하는 것이 좋습니다.\n",
      "\n",
      "📄 Page 16 설명:\n",
      "## 발표 대본 (간결 버전)\n",
      "\n",
      "**(시작)**\n",
      "\n",
      "안녕하세요.\n",
      "\n",
      "저희는 발표를 진행하지 않겠습니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "**(종료)**\n",
      "\n",
      "---\n",
      "\n",
      "## 발표 대본 (조금 더 자세한 버전 - 상황에 따라 활용)\n",
      "\n",
      "**(시작)**\n",
      "\n",
      "안녕하세요. 오늘 귀한 시간 내어 주셔서 감사합니다.\n",
      "\n",
      "저희는 오늘 예정되었던 발표를 진행하지 않기로 결정했습니다.\n",
      "\n",
      "저희의 결정으로 인해 불편을 드린 점 양해 부탁드립니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "**(종료)**\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보가 매우 제한적이기 때문에, 상황에 맞게 내용을 추가하거나 수정해야 합니다.\n",
      "*   발표의 목적, 청중, 분위기 등을 고려하여 적절한 어조와 표현을 사용하세요.\n",
      "*   \"ㅈ소 기업\"이라는 정보는 발표 내용에 따라 활용 여부를 결정하세요. (예: 유머러스한 분위기 조성 등)\n",
      "*   이미지 설명이 비어있으므로, 이미지 활용 계획이 있다면 대본에 반영하세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain.schema import HumanMessage, SystemMessage\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain_chroma import Chroma\n",
    "\n",
    "# pdf_path = '../../data/pdf/presentation_agent.pdf'\n",
    "# doc = fitz.open(pdf_path)\n",
    "# page_data = []\n",
    "\n",
    "\n",
    "# for page_num in range(len(doc)):\n",
    "#     page = doc[page_num]\n",
    "    \n",
    "#     text = page.get_text(\"text\")  \n",
    "#     images = page.get_images(full=True)  \n",
    "\n",
    "#     image_data = []\n",
    "#     for img in images:\n",
    "#         xref = img[0]\n",
    "#         img_rects = page.get_image_rects(xref)\n",
    "#         if img_rects:\n",
    "#             x0, y0, x1, y1 = img_rects[0]\n",
    "#             image_data.append({\"image_id\": xref, \"x\": x0, \"y\": y0})\n",
    "\n",
    "#     page_data.append({\"page\": page_num + 1, \"text\": text, \"images\": image_data})\n",
    "\n",
    "# # 1. 각 페이지를 개별적으로 벡터 스토어에 저장\n",
    "# embedding_model_name = \"jhgan/ko-sbert-nli\"  # 한국어 SBERT 사용\n",
    "# embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# vector_store = Chroma.from_texts([page[\"text\"] for page in page_data], embedding)\n",
    "\n",
    "# # 2. 페이지별로 설명 생성 (RAG 활용)\n",
    "# ollama = ChatOllama(model='gemma3:12b')\n",
    "\n",
    "# for page in page_data:\n",
    "#     page_text = page[\"text\"]\n",
    "    \n",
    "#     retrieved_docs = vector_store.similarity_search(page_text, k=3)\n",
    "#     retrieved_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "#     prompt = f\"\"\"\n",
    "#     이 페이지의 주요 내용을 기반으로 발표대본 만들어줘.\n",
    "\n",
    "#     **현재 페이지 텍스트 (일부만 제공됨)**:\n",
    "#     {page_text}\n",
    "    \n",
    "#     **관련 페이지 내용 (유사한 내용 검색됨)**:\n",
    "#     {retrieved_text}\n",
    "    \n",
    "#     **이미지 설명**:\n",
    "#     {page['images']}\n",
    "#     \"\"\"\n",
    "\n",
    "#     response = ollama.invoke([\n",
    "#         SystemMessage(content=\"당신은 발표 대본을 생성하는 AI입니다.\"),\n",
    "#         HumanMessage(content=prompt)\n",
    "#     ])\n",
    "\n",
    "#     page[\"generated_explanation\"] = response.content  # 생성된 설명 저장\n",
    "#     print(f\"📄 Page {page['page']} 설명:\\n{page['generated_explanation']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "# import chromadb\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.llms import Ollama\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# # 1. PDF 처리 함수 (서론, 본론, 결론 분류 + 텍스트 및 이미지 추출)\n",
    "# def extract_page(pdf_path, image_threshold=0.5):\n",
    "#     doc = fitz.open(pdf_path)\n",
    "#     total_pages = len(doc)\n",
    "#     pages = []\n",
    "\n",
    "#     def classify_page(page_num, total_pages):\n",
    "#         if page_num < 2:\n",
    "#             return \"intro\"\n",
    "#         elif page_num >= total_pages - 2:\n",
    "#             return \"conclusion\"\n",
    "#         else:\n",
    "#             return \"body\"\n",
    "\n",
    "#     def get_image_area_ratio(page, img_rect):\n",
    "#         \"\"\" 개별 이미지의 크기를 전체 페이지 면적 대비 비율로 반환 \"\"\"\n",
    "#         page_width, page_height = page.rect.width, page.rect.height\n",
    "#         page_area = page_width * page_height\n",
    "\n",
    "#         x0, y0, x1, y1 = img_rect\n",
    "#         img_width = x1 - x0\n",
    "#         img_height = y1 - y0\n",
    "#         img_area = img_width * img_height\n",
    "\n",
    "#         return img_area / page_area\n",
    "\n",
    "#     def get_total_image_area_ratio(page, images):\n",
    "#         \"\"\" 페이지에서 감지된 모든 이미지의 총 면적 비율을 계산 \"\"\"\n",
    "#         total_ratio = sum(get_image_area_ratio(page, img_rect) for img_rect in images)\n",
    "#         return total_ratio\n",
    "\n",
    "#     for page_num in range(total_pages):\n",
    "#         page = doc[page_num]\n",
    "#         text = page.get_text(\"text\")\n",
    "#         section = classify_page(page_num, total_pages)\n",
    "\n",
    "#         # 이미지 정보 추가\n",
    "#         images = []\n",
    "#         img_rects = []\n",
    "#         for img in page.get_images(full=True):\n",
    "#             xref = img[0]\n",
    "#             img_rects_page = page.get_image_rects(xref)\n",
    "#             if img_rects_page:\n",
    "#                 img_rects.append(img_rects_page[0])  # 이미지 위치 저장\n",
    "\n",
    "#         # 페이지 내 이미지 총 면적 계산\n",
    "#         total_img_ratio = get_total_image_area_ratio(page, img_rects)\n",
    "#         process_images = total_img_ratio >= image_threshold  # 40% 이상일 경우만 처리\n",
    "\n",
    "#         image_data = []\n",
    "#         for img_rect in img_rects:\n",
    "#             x0, y0, x1, y1 = img_rect\n",
    "#             image_entry = {\"x\": x0, \"y\": y0, \"width\": x1 - x0, \"height\": y1 - y0}\n",
    "#             image_entry[\"processed\"] = process_images  # 이미지 사용 여부 설정\n",
    "#             image_data.append(image_entry)\n",
    "\n",
    "#         pages.append({\n",
    "#             \"page\": page_num + 1,\n",
    "#             \"text\": text,\n",
    "#             \"section\": section,\n",
    "#             \"images\": image_data if process_images else [],\n",
    "#             \"image_analysis\": process_images\n",
    "#         })\n",
    "\n",
    "#     return pages\n",
    "\n",
    "# # 2. LangChain LLM 설정\n",
    "# llm = Ollama(model=\"gemma3:12b\")\n",
    "\n",
    "# # 3. 프롬프트 템플릿 (각 페이지별 대본 생성)\n",
    "# def create_prompt_template():\n",
    "#     return PromptTemplate(\n",
    "#         input_variables=[\"page_text\", \"retrieved_text\", \"page_images\"],\n",
    "#         template=\"\"\"\n",
    "#         이 페이지의 주요 내용을 기반으로 발표대본을 만들어줘.\n",
    "        \n",
    "#         인사는 page = 1일떄만 해.\n",
    "\n",
    "#         **현재 페이지 텍스트 (일부만 제공됨)**:\n",
    "#         {page_text}\n",
    "        \n",
    "#         **관련 페이지 내용 (유사한 내용 검색됨)**:\n",
    "#         {retrieved_text}\n",
    "        \n",
    "#         **이미지 설명**:\n",
    "#         {page_images}\n",
    "#         \"\"\"\n",
    "#     )\n",
    "\n",
    "# # 4. LangChain 체인 생성 (서론 / 본론 / 결론)\n",
    "# intro_chain = LLMChain(llm=llm, prompt=create_prompt_template())\n",
    "# body_chain = LLMChain(llm=llm, prompt=create_prompt_template())\n",
    "# conclusion_chain = LLMChain(llm=llm, prompt=create_prompt_template())\n",
    "\n",
    "# # 5. 전체 PDF 처리 및 발표 대본 생성 함수\n",
    "# def process_pdf(pdf_path):\n",
    "#     pages = extract_page(pdf_path)\n",
    "\n",
    "#     vector_store = Chroma.from_texts([page[\"text\"] for page in pages], HuggingFaceEmbeddings(model_name=\"jhgan/ko-sbert-nli\"))\n",
    "\n",
    "#     def retrieve_context(query):\n",
    "#         retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "#         return \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "#     scripts = []\n",
    "#     for i, page in enumerate(pages):\n",
    "#         page_text = page[\"text\"]\n",
    "#         retrieved_text = retrieve_context(page_text)\n",
    "        \n",
    "#         # **이미지 포함 여부 결정 (이미지 비율이 40% 이상인 경우만 설명)**\n",
    "#         if page[\"image_analysis\"]:\n",
    "#             page_images = str(page[\"images\"])\n",
    "#         else:\n",
    "#             page_images = \"해당 페이지에는 이미지가 없습니다.\"\n",
    "\n",
    "#         if page[\"section\"] == \"intro\":\n",
    "#             script = intro_chain.run(page_text=page_text, retrieved_text=retrieved_text, page_images=page_images)\n",
    "#         elif page[\"section\"] == \"body\":\n",
    "#             script = body_chain.run(page_text=page_text, retrieved_text=retrieved_text, page_images=page_images)\n",
    "#         else:\n",
    "#             script = conclusion_chain.run(page_text=page_text, retrieved_text=retrieved_text, page_images=page_images)\n",
    "\n",
    "#         scripts.append({\"page\": page[\"page\"], \"script\": script})\n",
    "\n",
    "#     return scripts\n",
    "\n",
    "# # 실행 예시\n",
    "# pdf_file_path = \"../../data/pdf/presentation_agent.pdf\"\n",
    "# result = process_pdf(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "**(페이지 1일 때만 아래 인사말을 합니다)**\n",
      "\n",
      "안녕하세요, 오늘 이 자리에서 [발표 주제]에 대한 발표를 진행하게 된 [발표자 이름]입니다. 오늘 발표에서는 프로젝트 개요에 대해 자세히 말씀드리겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "**(페이지 1 이후, 인사말은 생략합니다)**\n",
      "\n",
      "오늘 발표에서는 프로젝트 개요에 대해 말씀드리겠습니다.\n",
      "\n",
      "(페이지 내용이 매우 짧고 반복적인 내용만 제공되었으므로, 발표 대본은 일반적인 프로젝트 개요 발표에 맞춰 작성되었습니다. 실제 발표 시에는 프로젝트의 구체적인 내용에 맞춰 내용을 수정해야 합니다.)\n",
      "\n",
      "**1. 프로젝트 배경 및 필요성**\n",
      "\n",
      "*   (프로젝트가 시작하게 된 배경 설명)\n",
      "*   (이 프로젝트가 왜 필요한지, 어떤 문제를 해결하는지 설명)\n",
      "*   (기존 방식의 한계점 또는 문제점 제시)\n",
      "\n",
      "**2. 프로젝트 목표**\n",
      "\n",
      "*   (프로젝트를 통해 달성하고자 하는 구체적인 목표 제시)\n",
      "*   (측정 가능한 목표 설정 - 예: 효율성 향상, 비용 절감, 고객 만족도 증가 등)\n",
      "*   (목표 달성을 통해 기대되는 효과 설명)\n",
      "\n",
      "**3. 프로젝트 범위**\n",
      "\n",
      "*   (프로젝트에 포함되는 작업 및 기능 명확히 정의)\n",
      "*   (프로젝트에서 제외되는 부분 명시 - 범위 관리의 중요성 강조)\n",
      "\n",
      "**4. 주요 내용 및 특징**\n",
      "\n",
      "*   (프로젝트의 핵심 내용 간략하게 소개)\n",
      "*   (다른 프로젝트와 차별화되는 특징 강조)\n",
      "*   (주요 기술 또는 방법론 소개)\n",
      "\n",
      "**5. 기대 효과**\n",
      "\n",
      "*   (프로젝트 성공 시 예상되는 긍정적인 결과 제시)\n",
      "*   (기업 또는 조직에 미치는 영향 설명)\n",
      "*   (궁극적으로 달성하고자 하는 비전 제시)\n",
      "\n",
      "**마무리**\n",
      "\n",
      "오늘 발표를 통해 프로젝트 개요에 대한 이해를 높이셨기를 바랍니다. 앞으로 진행될 프로젝트를 통해 [기대되는 결과]를 달성할 수 있도록 최선을 다하겠습니다. 질문 있으시면 편하게 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 일반적인 프로젝트 개요 발표에 맞춰 작성되었으며, 실제 발표 시에는 프로젝트의 구체적인 내용에 맞춰 내용을 수정해야 합니다.\n",
      "*   발표 자료 (PPT 등)를 활용하여 시각적인 효과를 높이는 것이 좋습니다.\n",
      "*   청중과의 소통을 위해 질문을 유도하고, 적극적으로 답변하는 것이 중요합니다.\n",
      "*   발표 시간과 청중의 수준을 고려하여 내용을 조절해야 합니다.\n",
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "**[인사]**\n",
      "\n",
      "안녕하십니까! 오늘 발표를 맡게 된 [이름]입니다.\n",
      "\n",
      "**[본론]**\n",
      "\n",
      "오늘 발표는 \"발표 준비\"라는 키워드를 중심으로 진행됩니다. 혹시 여러분은 발표라는 단어를 들으면 어떤 생각이 드나요? 긴장되나요? 아니면 자신감이 느껴지나요? 발표는 우리 삶과 얼마나 밀접하게 관련되어 있을까요?\n",
      "\n",
      "**[기획 배경 설명]**\n",
      "\n",
      "이 질문에 대한 답을 찾기 위해, 저희는 \"발표 준비\"라는 키워드로 블로그, 뉴스, 카페, 지식인 등 다양한 온라인 플랫폼에서 관련 자료를 수집했습니다.  발표에 대한 사람들의 생각과 경험을 파악하고, 발표가 우리 삶에 어떤 의미를 가지는지 알아보고자 했습니다.\n",
      "\n",
      "**[다음 내용 예고]**\n",
      "\n",
      "지금부터 수집된 자료를 바탕으로, 발표에 대한 다양한 시각과 함께 흥미로운 사실들을 함께 살펴보겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "**[참고]**\n",
      "\n",
      "*   이 대본은 제공된 텍스트를 기반으로 작성되었으며, 실제 발표 내용에 맞게 수정 및 보완해야 합니다.\n",
      "*   이미지 설명은 발표 자료에 시각적인 요소를 추가하는 데 활용할 수 있습니다.\n",
      "*   발표 자료에 워드클라우드와 네트워크 그래프를 활용하여 발표 내용을 더욱 풍성하게 만들 수 있습니다.\n",
      "## 발표 대본\n",
      "\n",
      "**[Page 1]**\n",
      "\n",
      "안녕하십니까, 오늘 발표를 맡게 된 [이름]입니다. 오늘 발표는 직장인들의 발표 전 불안감의 원인에 대한 조사 결과를 바탕으로 진행하겠습니다.\n",
      "\n",
      "**[Page 1 이후]**\n",
      "\n",
      "오늘 발표는 취업포털 커리어넷에서 직장인 384명을 대상으로 한 설문조사 결과를 토대로, 발표 전 불안감을 느끼는 원인이 무엇인지 분석하고 공유하는 내용을 담고 있습니다.\n",
      "\n",
      "조사 결과, 가장 큰 비중을 차지하는 원인은 **내성적 성격**으로, 응답자의 31.3%를 차지했습니다.  다음으로 **실수에 대한 압박감**이 25%로 나타났습니다.\n",
      "\n",
      "그 외에도 **준비 부족** (14.6%), **무대 공포증** (12.5%), **질문의 대응이 어려워서** (10.4%), 그리고 **시선에 대한 압박감** 등이 불안감의 원인으로 지목되었습니다.\n",
      "\n",
      "(슬라이드에 그래프 또는 표를 보여주며)\n",
      "\n",
      "이처럼 많은 직장인들이 발표 전 불안감을 느끼는 이유는 다양하며, 개인의 성격적 특성, 준비 정도, 그리고 발표 상황에 대한 두려움 등이 복합적으로 작용하는 것으로 보입니다.\n",
      "\n",
      "이 결과를 바탕으로, 앞으로 발표 불안감을 줄이기 위한 다양한 방법들을 고민하고 실천해 나간다면, 보다 효과적인 의사소통 능력을 갖추는 데 도움이 될 것입니다.\n",
      "\n",
      "감사합니다. 질문 있으시면 편하게 질문해주세요.\n",
      "\n",
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "**[페이지 1]**\n",
      "\n",
      "안녕하십니까, 오인용입니다. 오늘 저는 저희가 개발한, 최초의 발표하는 인공지능 모델에 대한 발표를 진행하고자 합니다. 이 모델은 발표 자료를 기반으로 발표용 대본을 생성하고, AI 음성 합성을 활용하여 자동 발표 기능을 제공합니다. 오늘 발표를 통해 이 모델이 가진 기능과 기대 효과에 대해 자세히 설명드리겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 발표 대본 (페이지 2 이후)\n",
      "\n",
      "**[페이지 2 이후 - 내용 반복]**\n",
      "\n",
      "오늘 제가 소개해드릴 인공지능 모델은 발표 자료를 기반으로 발표용 대본을 생성하고, AI 음성 합성을 활용하여 자동 발표 기능을 제공합니다.\n",
      "\n",
      "이 모델은 기업, 연구자, 학생 등 다양한 사용자들이 정보를 보다 효율적으로 활용할 수 있도록 설계되었습니다.  발표 자료를 입력하면, 모델이 핵심 내용을 중심으로 발표용 대본을 자동으로 생성해줍니다.  \n",
      "\n",
      "이 모델을 통해 얻을 수 있는 기대 효과는 다음과 같습니다.\n",
      "\n",
      "*   **일괄된 발표 퀄리티:** 모델이 생성하는 대본은 일관된 품질을 유지하여 발표의 완성도를 높입니다.\n",
      "*   **발표 시간 단축:**  대본 작성에 소요되는 시간을 크게 줄여줍니다.\n",
      "\n",
      "이러한 기능들을 통해 사용자들은 시간과 노력을 절약하고, 더욱 효과적인 발표를 진행할 수 있을 것입니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 텍스트를 기반으로 작성되었으며, 실제 발표 내용에 맞게 수정 및 보완이 필요합니다.\n",
      "*   페이지 1의 인사말은 페이지 1에서만 사용하도록 설정되었습니다.\n",
      "*   페이지 2 이후의 내용은 제공된 텍스트가 반복되었기 때문에, 실제 발표 내용에 맞게 수정해야 합니다.\n",
      "*   발표 시 시각 자료 (이미지, 그래프 등)를 활용하면 더욱 효과적인 발표를 할 수 있습니다.\n",
      "## 발표 대본 (페이지 2: 프로젝트 기획)\n",
      "\n",
      "**(페이지 1일 경우)**\n",
      "\n",
      "안녕하십니까, 오늘 발표를 맡은 [이름]입니다. 오늘 발표 주제는 프로젝트 기획에 대해 말씀드리겠습니다.\n",
      "\n",
      "**(페이지 2: 프로젝트 기획)**\n",
      "\n",
      "오늘 발표에서는 프로젝트 기획에 대해 집중적으로 다루겠습니다. 현재 페이지는 '프로젝트 기획 02'를 나타내고 있습니다.\n",
      "\n",
      "(페이지 내용이 매우 짧고 반복적인 내용만 제공되었으므로, 발표 내용 구성이 어렵습니다. 아래는 일반적인 프로젝트 기획 발표에 포함될 수 있는 내용을 바탕으로 작성되었습니다. 실제 발표 시에는 페이지 내용에 맞춰 내용을 수정하고 보완해야 합니다.)\n",
      "\n",
      "**1. 프로젝트 기획의 중요성**\n",
      "\n",
      "프로젝트는 목표 달성을 위해 일시적으로 구성되는 조직입니다. 성공적인 프로젝트를 위해서는 탄탄한 기획이 필수적입니다. 프로젝트 기획은 프로젝트의 방향을 설정하고, 자원 배분 계획을 수립하며, 잠재적인 위험을 예측하고 대비하는 중요한 과정입니다.\n",
      "\n",
      "**2. 프로젝트 기획의 주요 단계 (예시)**\n",
      "\n",
      "*   **아이디어 발상 및 정의:** 프로젝트의 시작점은 명확한 목표와 아이디어에서 시작됩니다.\n",
      "*   **범위 정의:** 프로젝트의 범위는 무엇을 포함하고 무엇을 제외할 것인지 명확하게 정의해야 합니다.\n",
      "*   **일정 계획:** 프로젝트 완료에 필요한 기간과 각 단계별 일정을 계획합니다.\n",
      "*   **자원 계획:** 필요한 인력, 예산, 장비 등 자원을 확보하고 배분 계획을 수립합니다.\n",
      "*   **위험 관리 계획:** 프로젝트 진행 중 발생할 수 있는 위험을 예측하고, 이에 대한 대비책을 마련합니다.\n",
      "\n",
      "**3. 프로젝트 기획 시 고려 사항 (예시)**\n",
      "\n",
      "*   **목표의 구체성:** SMART (Specific, Measurable, Achievable, Relevant, Time-bound) 원칙에 따라 목표를 구체적으로 설정해야 합니다.\n",
      "*   **이해관계자 관리:** 프로젝트에 관련된 모든 이해관계자의 요구사항을 파악하고, 적극적으로 소통해야 합니다.\n",
      "*   **유연성 확보:** 예상치 못한 상황 발생에 대비하여 계획에 유연성을 확보해야 합니다.\n",
      "\n",
      "**4. 결론**\n",
      "\n",
      "프로젝트 기획은 프로젝트 성공의 핵심적인 요소입니다. 체계적인 기획을 통해 프로젝트의 목표를 달성하고, 효율적인 자원 활용과 위험 관리가 가능합니다.\n",
      "\n",
      "(질문 있으시면 질문해주세요.)\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   페이지 내용이 매우 짧기 때문에, 위 대본은 일반적인 프로젝트 기획 발표 내용을 바탕으로 작성되었습니다.\n",
      "*   실제 발표 시에는 페이지 내용에 맞춰 내용을 수정하고 보완해야 합니다.\n",
      "*   발표 자료에 시각적인 자료 (차트, 그래프, 이미지 등)를 추가하면 더욱 효과적인 발표가 될 수 있습니다.\n",
      "*   발표 시간과 청중의 수준을 고려하여 내용을 조절해야 합니다.\n",
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "**[페이지 1 시작]**\n",
      "\n",
      "안녕하십니까, [이름]입니다. 오늘 저희는 [프로젝트/서비스 이름]의 기술 스택 및 기획에 대해 발표하겠습니다.  저희 프로젝트는 [프로젝트/서비스에 대한 간략한 소개 - 1~2 문장]를 목표로 합니다.  오늘 발표를 통해 여러분께 저희가 어떤 기술들을 활용하고, 어떤 방식으로 프로젝트를 진행해 나갈 것인지 상세히 설명드리겠습니다.\n",
      "\n",
      "**[페이지 1 종료]**\n",
      "\n",
      "## 발표 대본 (페이지 2 이후)\n",
      "\n",
      "저희 프로젝트의 핵심은 다양한 AI 기술을 활용하여 [프로젝트/서비스의 핵심 기능 요약]를 제공하는 것입니다. 이를 위해 다음과 같은 기술 스택을 사용합니다.\n",
      "\n",
      "*   **FastAPI:** AI 모델을 서빙하고 사용자 요청을 처리하는 역할을 담당합니다.\n",
      "*   **Streamlit:** AI 서비스를 사용자에게 웹 애플리케이션 형태로 제공하는 UI 프레임워크로 사용합니다.\n",
      "*   **Lang Chain:** LLM, Prompt, RAG 등의 AI Agent가 수행하는 과정을 하나의 Chain으로 묶는 데 사용됩니다.\n",
      "*   **Ollama:** API 없이 로컬 환경에서 AI 모델을 직접 실행하여 보안과 성능을 최적화합니다.\n",
      "*   **Chroma DB:** Vector DB로, 문서를 저장하고 빠르게 검색할 수 있도록 사용됩니다.\n",
      "*   **OpenAI:** LLM을 활용하기 위한 기반 모델로 사용됩니다.\n",
      "*   **GitHub:** 코드 저장, 버전 관리 및 협업을 위해 사용됩니다.\n",
      "*   **Hugging Face:** 다양한 사전 학습된 모델을 검색하고 활용할 수 있는 플랫폼으로 사용됩니다.\n",
      "\n",
      "특히, 저희는 Ollama를 활용하여 로컬 환경에서 AI 모델을 실행함으로써 보안과 성능을 극대화하고, Hugging Face를 통해 다양한 모델을 활용할 수 있는 유연성을 확보했습니다. 또한, Lang Chain을 통해 복잡한 AI Agent의 과정을 효율적으로 관리하고, Chroma DB를 통해 문서 검색 속도를 향상시켰습니다.\n",
      "\n",
      "이러한 기술 스택을 기반으로, 저희는 [프로젝트/서비스의 주요 기능 및 특징을 구체적으로 설명 - 2~3 문장]를 제공할 수 있을 것으로 기대합니다.\n",
      "\n",
      "질문 있으시면 언제든지 편하게 질문해주세요. 감사합니다.\n",
      "\n",
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "**[페이지 1: 인사]**\n",
      "\n",
      "안녕하십니까, 발표를 맡은 [이름]입니다. 오늘 저는 [발표 주제]에 대해 말씀드리겠습니다. 간단하게 발표 내용을 요약하면, 랭체인, 자연어 처리, 딥러닝 관련 위키독스를 활용하여 지식 기반을 구축하는 방법에 대해 설명드릴 예정입니다.\n",
      "\n",
      "## 발표 대본 (페이지 2 이후)\n",
      "\n",
      "**[페이지 2: 사용할 자원]**\n",
      "\n",
      "본 프로젝트에서 사용할 주요 자원은 다음과 같습니다.\n",
      "\n",
      "*   **데이터:** 랭체인, 자연어 처리, 딥러닝과 관련된 위키독스 데이터를 크롤링하여 활용할 예정입니다.\n",
      "*   **기술:** 크롤링, 벡터 임베딩, VectorDB 적재 기술을 활용하여 지식 기반을 구축합니다.\n",
      "\n",
      "이러한 자원과 기술을 바탕으로, [발표 주제]에 대한 심도 있는 분석과 해결책 제시를 목표로 하고 있습니다.\n",
      "\n",
      "**[추가 설명]**\n",
      "\n",
      "*   발표 내용에 따라 위키독스 크롤링의 구체적인 방법, 벡터 임베딩 모델, VectorDB 종류 등을 추가 설명할 수 있습니다.\n",
      "*   청중의 이해를 돕기 위해 관련 기술 용어를 간략하게 설명하는 것이 좋습니다.\n",
      "*   발표 시간과 청중의 수준에 맞춰 내용을 조절하십시오.\n",
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "**(페이지 1)**\n",
      "\n",
      "안녕하십니까, 저희는 \"저희 발표 안합니다!\" 프로젝트 팀입니다. 오늘 이 자리에서 저희가 준비한 내용을 간략하게 공유하고자 합니다. 발표 제목은 \"저희 발표 안합니다!\" 입니다. (웃음)\n",
      "\n",
      "오늘 발표는 저희 프로젝트의 핵심 시스템 구조에 대한 간략한 소개를 중심으로 진행될 예정입니다.  저희의 목표는... (이 부분은 페이지 내용이 없어 생략)\n",
      "\n",
      "그럼 본격적으로 발표를 시작하도록 하겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 발표 대본 (페이지 2 이후)\n",
      "\n",
      "**(페이지 2 이후 - 내용 반복)**\n",
      "\n",
      "오늘 저희는 \"저희 발표 안합니다!\" 프로젝트의 시스템 구조에 대해 말씀드리겠습니다.\n",
      "\n",
      "저희의 시스템은 크게 다음과 같은 요소들로 구성되어 있습니다.\n",
      "\n",
      "*   **User:** 사용자는 시스템과 상호작용하는 주체입니다.\n",
      "*   **Document:** 시스템이 처리하는 문서 데이터입니다.\n",
      "*   **Vector DB:** 문서를 벡터 형태로 저장하고 검색하는 데이터베이스입니다.\n",
      "*   **LLM(오인용):**  (이 부분은 페이지 내용에 '오인용'이라고 명시되어 있어, 자세한 설명은 생략하고) LLM을 활용한 부분입니다.\n",
      "\n",
      "이러한 요소들이 유기적으로 연결되어 시스템이 작동합니다. (시스템 구조도에 대한 추가 설명이 필요하지만, 이미지가 없으므로 생략)\n",
      "\n",
      "저희는 이 시스템을 통해... (이 부분은 페이지 내용이 없어 생략)\n",
      "\n",
      "결론적으로, 저희 프로젝트는... (이 부분은 페이지 내용이 없어 생략)\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 제한적인 페이지 내용만을 기반으로 작성되었습니다.\n",
      "*   실제 발표 시에는 페이지 내용에 따라 내용을 추가하거나 수정해야 합니다.\n",
      "*   이미지가 제공되었다면, 이미지에 대한 설명도 추가해야 합니다.\n",
      "*   \"LLM(오인용)\" 부분은 실제 내용에 따라 수정해야 합니다.\n",
      "## 발표 대본\n",
      "\n",
      "**(Page 1)**\n",
      "\n",
      "안녕하십니까, 오늘 발표를 맡은 [이름]입니다. 오늘 발표에서는 [발표 주제]에 대해 말씀드리겠습니다.\n",
      "\n",
      "**(Page 1 이후 페이지)**\n",
      "\n",
      "오늘 발표에서는 크게 6가지 주요 내용을 다룰 예정입니다.\n",
      "\n",
      "1.  **서비스 UI 구성:** 서비스의 사용자 인터페이스 구성에 대해 설명드리겠습니다.\n",
      "2.  **기획:** 서비스 기획 단계에서 고려했던 사항들을 공유하겠습니다.\n",
      "3.  **시스템 구조:** 서비스의 전체적인 시스템 구조를 간략하게 설명드리겠습니다.\n",
      "4.  **발표 자료 업로드:** 발표 자료 업로드 기능에 대한 내용입니다.\n",
      "5.  **처리완료된 자료 시각화:** 처리된 자료를 시각적으로 표현하는 방법에 대해 말씀드리겠습니다.\n",
      "6.  **처리된 자료 다운로드:** 처리된 자료를 다운로드하는 기능에 대해 설명드리겠습니다.\n",
      "\n",
      "각 항목에 대해 자세히 설명드리겠습니다. (각 항목에 대한 자세한 설명은 페이지 내용에 따라 추가)\n",
      "\n",
      "감사합니다.\n",
      "## 발표 대본 (페이지 1일 때 인사 포함)\n",
      "\n",
      "**(페이지 1일 때만)** 안녕하세요, 발표를 시작합니다. 오늘 저는 [발표 주제]에 대해 말씀드리겠습니다.\n",
      "\n",
      "오늘 발표에서는 서비스 UI 구성, 기획, 그리고 시스템 구조에 대해 간략하게 설명드리겠습니다.\n",
      "\n",
      "**서비스 UI 구성**\n",
      "\n",
      "*   [구체적인 내용 설명 - 페이지 내용에 따라 채워 넣어야 함. 예를 들어, UI 디자인 원칙, 주요 화면 구성, 사용자 경험 고려 사항 등을 설명할 수 있습니다.]\n",
      "\n",
      "**기획**\n",
      "\n",
      "*   [구체적인 내용 설명 - 페이지 내용에 따라 채워 넣어야 함. 예를 들어, 서비스 기획 배경, 목표, 주요 기능 등을 설명할 수 있습니다.]\n",
      "\n",
      "**시스템 구조**\n",
      "\n",
      "*   [구체적인 내용 설명 - 페이지 내용에 따라 채워 넣어야 함. 예를 들어, 시스템 아키텍처 개요, 주요 컴포넌트, 데이터 흐름 등을 설명할 수 있습니다.]\n",
      "\n",
      "이것으로 발표를 마치겠습니다. 질문 있으시면 편하게 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 정보만으로 작성되었으며, 실제 발표 내용에 맞게 수정해야 합니다.\n",
      "*   각 항목별로 구체적인 내용과 예시를 추가하여 발표를 풍성하게 만들 수 있습니다.\n",
      "*   발표 자료에 맞는 시각 자료 (이미지, 다이어그램 등)를 활용하면 더욱 효과적인 발표가 될 수 있습니다.\n",
      "*   발표 시간과 청중의 수준을 고려하여 내용을 조절해야 합니다.\n",
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "안녕하십니까, 오늘 발표를 맡은 [이름]입니다. 오늘 저희는 [발표 주제]에 대한 내용을 공유하고자 합니다.  오늘 발표를 통해 [발표 목표]를 달성할 수 있기를 바랍니다.\n",
      "\n",
      "## 발표 대본 (페이지 1 이후)\n",
      "\n",
      "오늘 발표에서는 작업 흐름도와 관련된 내용을 다룰 예정입니다. 핵심은 다음과 같은 기술 스택을 활용하여 [프로젝트/시스템/솔루션]을 구축한다는 것입니다.\n",
      "\n",
      "*   **Fast API:** [Fast API에 대한 간략한 설명 및 역할]\n",
      "*   **Streamlit:** [Streamlit에 대한 간략한 설명 및 역할]\n",
      "*   **Lang Chain:** [Lang Chain에 대한 간략한 설명 및 역할]\n",
      "*   **Ollama:** [Ollama에 대한 간략한 설명 및 역할]\n",
      "*   **Chroma DB:** [Chroma DB에 대한 간략한 설명 및 역할]\n",
      "*   **OpenAI:** [OpenAI에 대한 간략한 설명 및 역할]\n",
      "*   **Hugging Face:** [Hugging Face에 대한 간략한 설명 및 역할]\n",
      "\n",
      "(이미지 슬라이드 삽입 - 작업 흐름도 이미지)\n",
      "\n",
      "이 이미지에서 보시는 것처럼, 각 기술들은 [프로젝트/시스템/솔루션]의 [구체적인 부분]을 담당하며, 유기적으로 연결되어 [전체적인 목표]를 달성합니다.\n",
      "\n",
      "(각 기술 스택에 대한 추가 설명 및 예시를 덧붙여 설명)\n",
      "\n",
      "이러한 기술 스택을 통해 [프로젝트/시스템/솔루션]은 [기대 효과]를 얻을 수 있습니다.\n",
      "\n",
      "감사합니다. 질문 있으시면 편하게 질문해주세요.\n",
      "\n",
      "## 발표 대본 (페이지 3: 프로젝트 방향성)\n",
      "\n",
      "**(페이지 1일 경우)**\n",
      "\n",
      "안녕하세요, 오늘 발표를 맡은 [발표자 이름]입니다. 오늘 발표에서는 [발표 주제]에 대해 말씀드리겠습니다.\n",
      "\n",
      "**(페이지 3: 프로젝트 방향성)**\n",
      "\n",
      "자, 그럼 본격적으로 오늘 발표의 핵심인 프로젝트 방향성에 대해 이야기해 보겠습니다.\n",
      "\n",
      "(잠시 멈춰서 청중에게 시선을 맞추며)\n",
      "\n",
      "지금까지 저희는 [이전 페이지 내용 요약 - 예를 들어, 문제 정의, 목표 설정 등]을 통해 프로젝트의 기반을 다져왔습니다. 이제 이 기반 위에서 프로젝트를 어떻게 진행해 나갈 것인지, 즉, **프로젝트 방향성**에 대해 명확히 정의하고 공유하고자 합니다.\n",
      "\n",
      "(페이지 내용이 반복적으로 \"프로젝트 방향성 03\"으로만 되어있으므로, 구체적인 방향성을 제시해야 함. 아래는 예시이며, 실제 프로젝트 방향성에 맞춰 수정해야 함)\n",
      "\n",
      "저희 프로젝트의 방향성은 크게 세 가지로 요약할 수 있습니다.\n",
      "\n",
      "1.  **[방향성 1]:** [방향성 1에 대한 구체적인 설명 및 중요성 강조]. 예를 들어, \"사용자 중심의 디자인을 최우선으로 하여, 사용 편의성을 극대화하는 방향으로 진행하겠습니다.\"\n",
      "2.  **[방향성 2]:** [방향성 2에 대한 구체적인 설명 및 중요성 강조]. 예를 들어, \"최신 기술 트렌드를 반영하여, 혁신적인 솔루션을 제공하는 것을 목표로 합니다.\"\n",
      "3.  **[방향성 3]:** [방향성 3에 대한 구체적인 설명 및 중요성 강조]. 예를 들어, \"지속 가능한 성장을 위해, 확장 가능하고 유지 보수가 용이한 시스템을 구축하겠습니다.\"\n",
      "\n",
      "(각 방향성에 대한 예시를 들어 설명)\n",
      "\n",
      "이러한 방향성을 바탕으로, 저희는 [구체적인 계획 또는 단계 설명]. 예를 들어, \"1단계에서는 사용자 인터페이스 디자인을 완료하고, 2단계에서는 핵심 기능 개발을 진행할 예정입니다.\"\n",
      "\n",
      "(결론 및 강조)\n",
      "\n",
      "저희는 이 방향성을 명확히 설정하고, 모든 팀원들이 이를 공유하며 프로젝트를 진행할 것입니다. 이를 통해 [프로젝트 성공에 대한 기대 효과 언급].\n",
      "\n",
      "(질문 유도)\n",
      "\n",
      "혹시 프로젝트 방향성에 대해 궁금한 점이 있으신 분은 질문해주세요.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 페이지 내용이 매우 제한적이므로, 실제 프로젝트 방향성에 맞춰 내용을 수정해야 합니다.\n",
      "*   각 방향성에 대한 구체적인 설명과 예시를 추가하여 청중의 이해도를 높이는 것이 중요합니다.\n",
      "*   발표 시 시각 자료 (슬라이드, 차트 등)를 활용하면 더욱 효과적인 발표가 가능합니다.\n",
      "*   페이지 내용이 반복되는 이유를 파악하고, 실제 프로젝트 방향성을 명확히 제시해야 합니다.\n",
      "## 발표 대본 (페이지 1)\n",
      "\n",
      "**[페이지 1]**\n",
      "\n",
      "안녕하십니까, 여러분. 오늘 저는 [발표 주제 - 페이지 내용 기반으로 채워주세요. 예: 디지털 아바타 기반 발표 시스템 개발 현황 및 발전 방향]에 대해 발표할 예정입니다.  이 발표를 통해 여러분과 함께 [발표 목표 - 페이지 내용 기반으로 채워주세요. 예: 디지털 아바타 기반 발표 시스템의 가능성을 탐색하고, 미래 발전 방향에 대한 인사이트를 공유]하고자 합니다.\n",
      "\n",
      "## 발표 대본 (페이지 1 이후)\n",
      "\n",
      "**[페이지 1 이후 - 내용 반복]**\n",
      "\n",
      "오늘 발표에서는 다음과 같은 주요 내용을 다룰 예정입니다.\n",
      "\n",
      "*   **TO DO LIST:** 현재 진행 중인 작업 목록을 확인하고, 앞으로 해결해야 할 과제를 공유합니다.\n",
      "*   **실시간 상호작용:** 발표 시스템에 실시간 상호작용 기능을 어떻게 구현할 수 있을지 논의합니다.\n",
      "*   **인간처럼 말하기:** 디지털 아바타가 더욱 자연스럽고 인간적인 표현을 할 수 있도록 하는 방법에 대해 알아봅니다.\n",
      "*   **발표 스타일의 개인화:** 발표 스타일을 개인화하여 더욱 효과적인 발표를 할 수 있도록 지원하는 방안을 모색합니다.\n",
      "*   **발표를 하는 디지털 아바타 생성:** 디지털 아바타 생성 기술의 발전 현황과 적용 가능성을 살펴봅니다.\n",
      "*   **도메인 확장:** 시스템의 적용 범위를 넓히기 위한 도메인 확장 전략을 제시합니다.\n",
      "*   **03. 방향성 & 발전 방안:**  전체적인 방향성을 설정하고, 시스템 발전 방안에 대한 심도 있는 논의를 진행합니다.\n",
      "\n",
      "이러한 내용을 바탕으로, 디지털 아바타 기반 발표 시스템의 미래를 함께 그려보고자 합니다. 경청해주셔서 감사합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**참고:**\n",
      "\n",
      "*   위 대본은 제공된 텍스트를 기반으로 작성되었으며, 실제 발표 내용에 맞게 수정해야 합니다.\n",
      "*   발표 주제, 목표, 그리고 각 항목에 대한 구체적인 내용 (예: 실시간 상호작용 구현 방법, 인간처럼 말하기를 위한 기술 등)을 추가하여 더욱 풍성한 발표를 만들 수 있습니다.\n",
      "*   이미지가 없으므로, 시각 자료를 활용하여 발표의 이해도를 높이는 것을 고려해 보세요.\n",
      "*   발표 시간과 청중의 수준에 맞춰 내용을 조절하는 것이 중요합니다.\n"
     ]
    }
   ],
   "source": [
    "for script in result :\n",
    "    print(script['script'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## 발표 서론 (예시)\\n\\n**안녕하세요, 발표를 시작합니다.**\\n\\n저희는 DeepPrint 팀, D.P. 팀입니다. 김지민, 박형빈, 정재식으로 구성되어 있으며, Wanted PotenUp 프로젝트의 3차 프로젝트로 딥러닝 기반 아동 미술 심리 진단 시스템 개발에 도전했습니다.\\n\\n아동 미술은 아이의 내면세계와 감정을 표현하는 중요한 도구입니다. 하지만 기존의 미술 심리 진단은 전문가의 주관적인 해석에 의존하며, 시간과 비용이 많이 소요되는 어려움이 있었습니다.\\n\\n저희 팀은 이러한 어려움을 해결하고, 보다 객관적이고 효율적인 아동 미술 심리 진단 시스템을 구축하기 위해 딥러닝 기술을 활용했습니다. 오늘 발표에서는 저희 팀이 개발한 딥러닝 기반 아동 미술 심리 진단 시스템의 개발 과정과 결과를 공유하고, 앞으로의 발전 방향에 대해 이야기하고자 합니다.\\n\\n**발표를 시작하겠습니다.**\\n\\n---\\n\\n**참고:**\\n\\n*   발표 대상과 내용에 따라 서론의 어조와 내용을 조절해주세요.\\n*   서론에 발표 내용의 핵심 키워드를 포함하여 청중의 관심을 유도하는 것이 좋습니다.\\n*   발표 자료의 첫 페이지에 팀 정보와 프로젝트 정보를 명확하게 표시하는 것이 좋습니다.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro = result['intro_script']\n",
    "intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## 발표 본론: HTP 검사를 통한 심리 상태 이해\\n\\n**존경하는 청중 여러분,**\\n\\n앞서 HTP 검사의 간략한 소개와 함께, 이 검사가 개인의 심리 상태를 파악하는 데 유용한 도구임을 말씀드렸습니다. 이제부터는 HTP 검사가 어떻게 진행되며, 어떤 점을 통해 개인의 심리 상태를 이해할 수 있는지 좀 더 자세히 살펴보겠습니다.\\n\\n**1. HTP 검사 진행 방식: 그림을 통한 무의식 탐색**\\n\\nHTP 검사는 피검자에게 집(House), 나무(Tree), 사람(Person)의 세 가지 주제에 대해 그림을 그리도록 요청하는 방식으로 진행됩니다. 특별한 제한 없이 자유롭게 그림을 그리도록 하며, 그림을 그리는 과정에서 피검자의 무의식적인 감정, 생각, 그리고 대인 관계 패턴이 드러나도록 유도합니다.\\n\\n*   **집(House):** 집은 피검자의 자아, 가족 관계, 그리고 안전에 대한 욕구를 상징합니다. 집의 크기, 형태, 창문, 문, 지붕 등의 묘사는 피검자의 자존감, 가족과의 관계, 그리고 세상에 대한 인식 등을 반영합니다.\\n*   **나무(Tree):** 나무는 성장, 발달, 그리고 삶의 의미를 상징합니다. 나무의 종류, 크기, 가지, 잎 등의 묘사는 피검자의 성장 과정, 목표 의식, 그리고 삶에 대한 태도를 보여줍니다.\\n*   **사람(Person):** 사람은 피검자의 대인 관계, 사회성, 그리고 타인과의 상호 작용 방식을 나타냅니다. 사람의 크기, 옷차림, 표정, 그리고 주변 인물과의 관계 묘사는 피검자의 사회적 관계, 정서적 안정, 그리고 타인에 대한 인식 등을 보여줍니다.\\n\\n**2. HTP 검사 분석: 그림 속에 숨겨진 메시지 해석**\\n\\n그림이 완성되면, 숙련된 전문가가 그림의 내용, 표현 방식, 그리고 그림의 전체적인 조화를 종합적으로 분석하여 피검자의 심리 상태를 파악합니다. 분석 과정에서는 다음과 같은 요소들을 고려합니다.\\n\\n*   **그림의 내용:** 그림에 묘사된 세부적인 요소들의 의미를 해석합니다. 예를 들어, 집의 크기가 작다면 자존감 저하를, 나무의 가지가 꺾여 있다면 좌절감을, 사람의 얼굴이 찡그려 있다면 불행감을 나타낼 수 있습니다.\\n*   **그림의 표현 방식:** 그림의 색상, 선의 굵기, 그리고 그림의 배치 등을 분석합니다. 예를 들어, 어두운 색상을 많이 사용했다면 우울감을, 굵은 선을 사용했다면 공격성을, 그림의 배치가 불안정하다면 정서적 불안정을 나타낼 수 있습니다.\\n*   **그림의 전체적인 조화:** 그림의 세 요소들이 서로 어떻게 연결되어 있는지, 그리고 그림 전체가 어떤 분위기를 나타내는지 파악합니다. 그림의 조화는 피검자의 심리적 안정감과 통합 정도를 보여줍니다.\\n\\n**3. HTP 검사의 활용: 다양한 분야에서의 적용**\\n\\nHTP 검사는 다양한 분야에서 활용될 수 있습니다.\\n\\n*   **아동 및 청소년 심리 평가:** 학교 부적응, 또래 관계 문제, 학습 장애 등 아동 및 청소년의 심리적인 어려움을 파악하고 적절한 지원을 제공하는 데 활용됩니다.\\n*   **성인 심리 상담:** 스트레스, 불안, 우울, 대인 관계 문제 등 성인의 심리적인 어려움을 이해하고 해결하는 데 도움을 줍니다.\\n*   **인사 선발 및 조직 심리:** 지원자의 성격, 대인 관계 능력, 그리고 스트레스 관리 능력을 평가하여 적합한 직무를 부여하고 조직 적응력을 높이는 데 활용됩니다.\\n\\n**결론적으로,** HTP 검사는 그림이라는 친숙한 도구를 통해 개인의 무의식적인 심리 상태를 탐색하고 이해하는 데 유용한 검사입니다. 이 검사를 통해 얻은 정보는 개인의 심리적인 어려움을 해결하고, 더 나아가 건강하고 행복한 삶을 살아가는 데 도움을 줄 수 있습니다.\\n\\n**감사합니다.**'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = result['body_script']\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## 발표 결론: 4월에 다시 만나요!\\n\\n오늘 발표는 짧게 마무리하겠습니다. 반복되는 질문처럼, \"다음 발표는 언제였지?\"라는 궁금증을 자아내는 메시지를 전달하고자 했습니다. \\n\\n이것은 마치 기다림의 연속처럼 느껴질 수 있다는 것을 의미합니다. 하지만 걱정 마세요! **4월에 다시 만날 예정입니다.** \\n\\n그때까지, 여러분의 많은 관심과 참여 부탁드리며, 4월에 더 알찬 내용으로 찾아뵙겠습니다. 감사합니다!\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conclusion = result['conclusion_script']\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## 발표 서론 (예시)\\n\\n**안녕하세요, 발표를 시작합니다.**\\n\\n저희는 DeepPrint 팀, D.P. 팀입니다. 김지민, 박형빈, 정재식으로 구성되어 있으며, Wanted PotenUp 프로젝트의 3번째 과제로 딥러닝 기반 아동 미술 심리 진단 시스템 개발에 도전했습니다.\\n\\n아동 미술은 아이의 내면세계와 감정을 표현하는 중요한 도구입니다. 하지만 기존의 미술 심리 진단은 전문가의 주관적인 해석에 의존하여 시간과 비용이 많이 소요되고, 객관적인 신뢰성을 확보하기 어려웠습니다.\\n\\n이에 저희는 딥러닝 기술을 활용하여 아동 미술 작품을 분석하고, 보다 객관적이고 효율적인 심리 진단 시스템을 구축하고자 했습니다. 오늘 발표에서는 저희 팀이 개발한 딥러닝 기반 아동 미술 심리 진단 시스템의 개발 과정과 주요 기능, 그리고 앞으로의 발전 방향에 대해 자세히 말씀드리겠습니다.\\n\\n**발표를 시작하겠습니다.**\\n\\n---\\n\\n**참고:**\\n\\n*   발표 대상과 내용에 따라 서론의 어조와 내용을 조절해주세요.\\n*   서론에 개발 배경, 문제점, 해결 방안 등을 간략하게 언급하여 발표에 대한 흥미를 유발할 수 있습니다.\\n*   발표 내용을 요약하는 슬라이드를 함께 사용하여 청중의 이해를 돕는 것도 좋은 방법입니다.## 발표 본론: HTP 검사를 통한 심리 상태 이해\\n\\n**존경하는 청중 여러분,**\\n\\n앞서 HTP 검사의 간략한 소개와 함께, 이 검사가 개인의 심리 상태를 파악하는 데 유용한 도구임을 말씀드렸습니다. 이제부터는 HTP 검사가 어떻게 진행되며, 어떤 점을 통해 개인의 심리 상태를 이해할 수 있는지 좀 더 자세히 살펴보겠습니다.\\n\\n**1. HTP 검사 진행 방식: 그림을 통한 무의식 탐색**\\n\\nHTP 검사는 피검자에게 집(House), 나무(Tree), 사람(Person)의 세 가지 주제에 대해 그림을 그리도록 요청하는 방식으로 진행됩니다. 특별한 제한 없이 자유롭게 그림을 그리도록 하며, 그림을 그리는 과정에서 피검자의 무의식적인 감정, 생각, 그리고 대인 관계 패턴이 드러나도록 유도합니다.\\n\\n*   **집(House):** 집은 피검자의 자아, 가족 관계, 그리고 안전에 대한 욕구를 상징합니다. 집의 크기, 형태, 창문, 문, 지붕 등의 묘사는 피검자의 자존감, 가족과의 관계, 그리고 세상에 대한 인식 등을 반영합니다.\\n*   **나무(Tree):** 나무는 성장, 발달, 그리고 삶의 의미를 상징합니다. 나무의 종류, 크기, 가지, 잎 등의 묘사는 피검자의 성장 과정, 목표 의식, 그리고 삶에 대한 태도를 보여줍니다.\\n*   **사람(Person):** 사람은 피검자의 대인 관계, 사회성, 그리고 타인과의 상호 작용 방식을 나타냅니다. 사람의 크기, 옷차림, 표정, 그리고 주변 인물과의 관계 묘사는 피검자의 사회적 관계, 정서적 안정, 그리고 타인에 대한 인식 등을 보여줍니다.\\n\\n**2. HTP 검사 분석: 그림 속에 숨겨진 메시지 해석**\\n\\n그림이 완성되면, 숙련된 전문가가 그림의 내용, 표현 방식, 그리고 그림의 전체적인 조화를 종합적으로 분석하여 피검자의 심리 상태를 파악합니다. 분석 과정에서는 다음과 같은 요소들을 고려합니다.\\n\\n*   **그림의 내용:** 그림에 묘사된 세부적인 요소들의 의미를 해석합니다. 예를 들어, 집의 크기가 작다면 자존감 저하를, 나무의 가지가 꺾여 있다면 좌절감을, 사람의 얼굴이 찡그려 있다면 불행감을 나타낼 수 있습니다.\\n*   **그림의 표현 방식:** 그림의 색상, 선의 굵기, 그리고 그림의 배치 등을 분석합니다. 예를 들어, 어두운 색상을 많이 사용했다면 우울감을, 굵은 선을 사용했다면 공격성을, 그림의 배치가 불안정하다면 정서적 불안정을 나타낼 수 있습니다.\\n*   **그림의 전체적인 조화:** 그림의 세 요소들이 서로 어떻게 연결되어 있는지, 그리고 그림 전체가 어떤 분위기를 나타내는지 파악합니다. 그림의 조화는 피검자의 심리적 안정감과 통합 정도를 보여줍니다.\\n\\n**3. HTP 검사의 활용: 다양한 분야에서의 적용**\\n\\nHTP 검사는 다양한 분야에서 활용될 수 있습니다.\\n\\n*   **아동 및 청소년 심리 평가:** 학교 부적응, 또래 관계 문제, 학습 장애 등 아동 및 청소년의 심리적인 어려움을 파악하고 적절한 지원을 제공하는 데 활용됩니다.\\n*   **성인 심리 상담:** 스트레스, 불안, 우울, 대인 관계 문제 등 성인의 심리적인 어려움을 이해하고 해결하는 데 도움을 줍니다.\\n*   **인사 선발 및 조직 심리:** 지원자의 성격, 대인 관계 능력, 그리고 스트레스 관리 능력을 평가하여 적합한 직무를 부여하고 조직 적응력을 높이는 데 활용됩니다.\\n\\n**결론적으로,** HTP 검사는 그림이라는 친숙한 도구를 통해 개인의 무의식적인 심리 상태를 탐색하고 이해하는 데 유용한 검사입니다. 이 검사를 통해 얻은 정보는 개인의 심리적인 어려움을 해결하고, 더 나아가 건강하고 행복한 삶을 살아가는 데 도움을 줄 수 있습니다.\\n\\n**감사합니다.**## 발표 결론: 4월에 다시 만나요!\\n\\n오늘 발표는 짧게 마무리하겠습니다. 반복되는 질문처럼, \"다음 발표는 언제였지?\"라는 궁금증을 자아내는 메시지를 전달하고자 했습니다. \\n\\n이것은 마치 기다림의 연속처럼 느껴질 수 있다는 것을 의미합니다. 하지만 걱정 마세요! **4월에 다시 만날 예정입니다.** \\n\\n그때까지, 여러분의 많은 관심과 참여 부탁드리며, 4월에 더 알찬 내용으로 찾아뵙겠습니다. 감사합니다!\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script = intro + body + conclusion\n",
    "script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdfplumber\n",
    "# import easyocr\n",
    "# import torch\n",
    "# import os\n",
    "# import io\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from PIL import Image\n",
    "\n",
    "# # ✅ PDF 경로\n",
    "# pdf_path = \"../../data/pdf/presentation_agent.pdf\"\n",
    "\n",
    "# # ✅ OCR 모델 (EasyOCR)\n",
    "# ocr_reader = easyocr.Reader([\"en\", \"ko\"])  # 한국어 + 영어 지원\n",
    "\n",
    "# # ✅ BLIP-2 모델 (이미지 설명 AI)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 1번 GPU만 사용\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "# model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)\n",
    "\n",
    "# # ✅ OpenCV를 활용하여 PIL 이미지를 NumPy 배열로 변환\n",
    "# def image_to_numpy(image_pil):\n",
    "#     \"\"\"PIL 이미지를 NumPy 배열로 변환 (EasyOCR 입력용)\"\"\"\n",
    "#     image_cv = np.array(image_pil.convert(\"RGB\"))  # RGB 변환\n",
    "#     image_gray = cv2.cvtColor(image_cv, cv2.COLOR_RGB2GRAY)  # ✅ 흑백 변환 (OCR 성능 향상)\n",
    "#     return image_gray  # ✅ EasyOCR는 grayscale을 선호함\n",
    "\n",
    "# # ✅ PDF 분석 및 페이지 분류 + 이미지 처리\n",
    "# def extract_page(pdf_path):\n",
    "#     loader = PDFPlumberLoader(pdf_path)\n",
    "#     documents = loader.load()\n",
    "\n",
    "#     pages = []\n",
    "#     total_pages = len(documents)\n",
    "\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page_num, doc_page in enumerate(documents):\n",
    "#             page = pdf.pages[page_num]\n",
    "#             text = doc_page.page_content.strip() if doc_page.page_content else \"\"\n",
    "\n",
    "#             # ✅ 이미지 처리\n",
    "#             images = []\n",
    "#             for img in page.images:\n",
    "#                 x0, y0, x1, y1 = img[\"x0\"], img[\"top\"], img[\"x1\"], img[\"bottom\"]\n",
    "                \n",
    "#                 # ✅ 이미지 크롭 후 OCR 적용\n",
    "#                 page_image = page.to_image()\n",
    "#                 full_img = page_image.annotated\n",
    "#                 img_crop = full_img.crop((x0, y0, x1, y1))\n",
    "\n",
    "#                 img_bytes = io.BytesIO()\n",
    "#                 img_crop.save(img_bytes, format=\"PNG\")\n",
    "#                 img_pil = Image.open(img_bytes)\n",
    "\n",
    "#                 # ✅ OCR 적용 (EasyOCR)\n",
    "#                 ocr_input = image_to_numpy(img_pil)  # OpenCV 변환 후 OCR 실행\n",
    "#                 ocr_text = ocr_reader.readtext(ocr_input, detail=0)\n",
    "#                 ocr_result = \" \".join(ocr_text) if ocr_text else \"No OCR text found.\"\n",
    "\n",
    "#                 # ✅ 이미지 설명 (BLIP-2)\n",
    "#                 img_pil = img_pil.convert(\"RGB\")  # BLIP-2에서 RGB 변환 필수\n",
    "#                 inputs = processor(img_pil, return_tensors=\"pt\").to(device)\n",
    "#                 with torch.no_grad():\n",
    "#                     caption = model.generate(**inputs)\n",
    "#                     blip_caption = processor.decode(caption[0], skip_special_tokens=True)\n",
    "\n",
    "#                 images.append({\n",
    "#                     \"image_id\": len(images) + 1,\n",
    "#                     \"ocr_text\": ocr_result,\n",
    "#                     \"blip_caption\": blip_caption\n",
    "#                 })\n",
    "\n",
    "#             pages.append({\n",
    "#                 \"page\": page_num + 1,\n",
    "#                 \"text\": text,\n",
    "#                 \"images\": images\n",
    "#             })\n",
    "\n",
    "#     return pages\n",
    "\n",
    "# # ✅ 벡터 스토어 생성 (페이지 단위 저장)\n",
    "# embedding_model_name = \"jhgan/ko-sbert-nli\"\n",
    "# embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# def create_vector_store(pages):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "#     texts = [f\"Page {p['page']}: {p['text']}\" for p in pages]  \n",
    "#     docs = text_splitter.create_documents(texts)\n",
    "\n",
    "#     vector_store = Chroma.from_documents(docs, embedding)\n",
    "#     retriever = vector_store.as_retriever()\n",
    "\n",
    "#     return retriever\n",
    "\n",
    "# # ✅ 발표 대본 생성 함수 (불필요한 설명 제거)\n",
    "# def generate_script(pdf_path):\n",
    "#     pages = extract_page(pdf_path)\n",
    "#     retriever = create_vector_store(pages)\n",
    "#     ollama = ChatOllama(model=\"gemma3:12b\", temperature=0)\n",
    "\n",
    "#     prev_script = \"\"  # 이전 페이지의 대본 저장\n",
    "\n",
    "#     for i, page in enumerate(pages):\n",
    "#         page_text = page[\"text\"]\n",
    "\n",
    "#         # 🔹 현재 페이지 + 이전 페이지 + 다음 페이지 활용\n",
    "#         current_page = page_text\n",
    "#         previous_page = pages[i - 1][\"text\"] if i > 0 else \"\"\n",
    "#         next_page = pages[i + 1][\"text\"] if i < len(pages) - 1 else \"\"\n",
    "\n",
    "#         query_text = f\"{previous_page}\\n{current_page}\\n{next_page}\".strip()\n",
    "#         retrieved_docs = retriever.get_relevant_documents(query_text)  # ✅ 최신 버전 적용\n",
    "#         retrieved_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "#         # ✅ 이미지 설명 데이터 중요도 평가\n",
    "#         important_images = []\n",
    "#         for img in page[\"images\"]:\n",
    "#             prompt_for_image = f\"\"\"\n",
    "#             다음은 PDF에서 추출된 이미지 설명입니다.\n",
    "#             이 이미지가 발표 대본에서 중요한지 평가해주세요.\n",
    "            \n",
    "#             **OCR 결과:** {img[\"ocr_text\"]}\n",
    "#             **BLIP 이미지 설명:** {img[\"blip_caption\"]}\n",
    "\n",
    "#             발표 내용에서 반드시 포함해야 할까요? (예/아니오)\n",
    "#             \"\"\"\n",
    "#             response = ollama.invoke([\n",
    "#                 SystemMessage(content=\"당신은 발표 자료를 분석하는 AI입니다.\"),\n",
    "#                 HumanMessage(content=prompt_for_image)\n",
    "#             ])\n",
    "\n",
    "#             if \"예\" in response.content:\n",
    "#                 important_images.append(f\"OCR 인식 텍스트: {img['ocr_text']}\\nAI 이미지 설명: {img['blip_caption']}\")\n",
    "\n",
    "#         image_text = \"\\n\".join(important_images) if important_images else \"해당 페이지에는 분석할 이미지가 없습니다.\"\n",
    "\n",
    "#         # ✅ LLM 프롬프트 (불필요한 설명 제외)\n",
    "#         prompt = f\"\"\"\n",
    "#         [중요] 정확한 발표 대본만 작성해 주세요. 추가적인 설명, 제안 사항은 포함하지 마세요.\n",
    "\n",
    "#         **이전 페이지 요약:**\n",
    "#         {previous_page}\n",
    "\n",
    "#         **현재 페이지의 주요 내용:**\n",
    "#         {current_page}\n",
    "\n",
    "#         **다음 페이지 개요:**\n",
    "#         {next_page}\n",
    "\n",
    "#         **관련 문서 내용 (RAG 검색 결과):**\n",
    "#         {retrieved_text}\n",
    "\n",
    "#         **필요한 이미지 설명만 포함:**\n",
    "#         {image_text}\n",
    "\n",
    "#         [중요] 불필요한 부가 설명 없이 정확한 발표 대본만 작성해 주세요.\n",
    "#         \"\"\"\n",
    "\n",
    "#         response = ollama.invoke([\n",
    "#             SystemMessage(content=\"당신은 발표 대본을 생성하는 AI입니다. 문서의 흐름을 유지하며 발표 대본만 작성하세요.\"),\n",
    "#             HumanMessage(content=prompt)\n",
    "#         ])\n",
    "\n",
    "#         # ✅ 불필요한 내용 필터링\n",
    "#         generated_script = response.content.strip()\n",
    "\n",
    "#         prev_script = generated_script\n",
    "#         page[\"generated_script\"] = generated_script  \n",
    "\n",
    "#     return pages\n",
    "\n",
    "# # ✅ 실행 예시\n",
    "# result = generate_script(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanted-1/miniconda3/envs/LLM_team2_py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_3149231/3907768069.py:84: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
      "/tmp/ipykernel_3149231/3907768069.py:100: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "# import pdfplumber\n",
    "# import easyocr\n",
    "# import torch\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "# from langchain.document_loaders import PDFPlumberLoader\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.schema import HumanMessage, SystemMessage\n",
    "# from langchain_community.chat_models import ChatOpenAI\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain.vectorstores import Chroma as ChromaVectorDB\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from PIL import Image\n",
    "# import io\n",
    "\n",
    "# # ✅ 환경 변수 로드 (.env 파일에서 API 키 불러오기)\n",
    "# load_dotenv()\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# # PDF 경로\n",
    "# pdf_path = \"../../data/pdf/presentation_agent.pdf\"\n",
    "\n",
    "# # OCR 모델 (EasyOCR)\n",
    "# ocr_reader = easyocr.Reader([\"en\", \"ko\"])  # 한국어 + 영어 지원\n",
    "\n",
    "# # BLIP-2 모델 (이미지 설명 AI)\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "# model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)\n",
    "\n",
    "# # 1. PDF 분석 및 페이지 분류 + 이미지 처리\n",
    "# def extract_page(pdf_path):\n",
    "#     loader = PDFPlumberLoader(pdf_path)\n",
    "#     documents = loader.load()\n",
    "\n",
    "#     pages = []\n",
    "#     total_pages = len(documents)\n",
    "\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page_num, doc_page in enumerate(documents):\n",
    "#             page = pdf.pages[page_num]\n",
    "#             text = doc_page.page_content.strip() if doc_page.page_content else \"\"\n",
    "\n",
    "#             # 이미지 처리\n",
    "#             images = []\n",
    "#             for img in page.images:\n",
    "#                 x0, y0, x1, y1 = img[\"x0\"], img[\"top\"], img[\"x1\"], img[\"bottom\"]\n",
    "                \n",
    "#                 page_image = page.to_image()\n",
    "#                 full_img = page_image.annotated\n",
    "#                 img_crop = full_img.crop((x0, y0, x1, y1))\n",
    "\n",
    "#                 img_bytes = io.BytesIO()\n",
    "#                 img_crop.save(img_bytes, format=\"PNG\")\n",
    "#                 img_pil = Image.open(img_bytes)\n",
    "\n",
    "#                 # 1️⃣ OCR 적용 (EasyOCR)\n",
    "#                 ocr_text = ocr_reader.readtext(img_bytes.getvalue(), detail=0)\n",
    "#                 ocr_result = \" \".join(ocr_text) if ocr_text else \"No OCR text found.\"\n",
    "\n",
    "#                 # 2️⃣ 이미지 설명 (BLIP-2)\n",
    "#                 inputs = processor(img_pil, return_tensors=\"pt\").to(device)\n",
    "#                 with torch.no_grad():\n",
    "#                     caption = model.generate(**inputs)\n",
    "#                     blip_caption = processor.decode(caption[0], skip_special_tokens=True)\n",
    "\n",
    "#                 images.append({\n",
    "#                     \"image_id\": len(images) + 1,\n",
    "#                     \"ocr_text\": ocr_result,\n",
    "#                     \"blip_caption\": blip_caption\n",
    "#                 })\n",
    "\n",
    "#             pages.append({\n",
    "#                 \"page\": page_num + 1,\n",
    "#                 \"text\": text,\n",
    "#                 \"images\": images\n",
    "#             })\n",
    "\n",
    "#     return pages\n",
    "\n",
    "# # 2. 벡터 스토어 생성 (페이지 단위로 저장)\n",
    "# embedding_model_name = \"jhgan/ko-sbert-nli\"\n",
    "# embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# def create_vector_store(pages):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "#     texts = [f\"Page {p['page']}: {p['text']}\" for p in pages]  \n",
    "#     docs = text_splitter.create_documents(texts)\n",
    "\n",
    "#     vector_store = ChromaVectorDB.from_documents(docs, embedding)\n",
    "#     return vector_store\n",
    "\n",
    "# # 3. 발표 대본 생성 함수 (한 흐름으로 진행)\n",
    "# def generate_script(pdf_path):\n",
    "#     pages = extract_page(pdf_path)\n",
    "#     vector_store = create_vector_store(pages)\n",
    "\n",
    "#     # ✅ LangChain을 사용한 GPT-4 모델 불러오기\n",
    "#     llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "#     prev_script = \"\"  # 이전 페이지의 대본을 저장\n",
    "\n",
    "#     for i, page in enumerate(pages):\n",
    "#         page_text = page[\"text\"]\n",
    "\n",
    "#         # 🔹 현재 페이지 + 이전 페이지 + 다음 페이지 활용\n",
    "#         current_page = page_text\n",
    "#         previous_page = pages[i - 1][\"text\"] if i > 0 else \"\"\n",
    "#         next_page = pages[i + 1][\"text\"] if i < len(pages) - 1 else \"\"\n",
    "\n",
    "#         query_text = f\"{previous_page}\\n{current_page}\\n{next_page}\".strip()\n",
    "#         retrieved_docs = vector_store.similarity_search(query_text, k=5)\n",
    "#         retrieved_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "#         # 이미지 설명 데이터 중요도 평가\n",
    "#         important_images = []\n",
    "#         for img in page[\"images\"]:\n",
    "#             prompt_for_image = f\"\"\"\n",
    "#             다음은 PDF에서 추출된 이미지 설명입니다.\n",
    "#             이 이미지가 발표 대본에서 중요한지 평가해주세요.\n",
    "            \n",
    "#             **OCR 결과:** {img[\"ocr_text\"]}\n",
    "#             **BLIP 이미지 설명:** {img[\"blip_caption\"]}\n",
    "\n",
    "#             발표 내용에서 반드시 포함해야 할까요? (예/아니오)\n",
    "#             \"\"\"\n",
    "#             response = llm.invoke([\n",
    "#                 SystemMessage(content=\"당신은 발표 자료를 분석하는 AI입니다.\"),\n",
    "#                 HumanMessage(content=prompt_for_image)\n",
    "#             ])\n",
    "\n",
    "#             if \"예\" in response.content:\n",
    "#                 important_images.append(f\"OCR 인식 텍스트: {img['ocr_text']}\\nAI 이미지 설명: {img['blip_caption']}\")\n",
    "\n",
    "#         image_text = \"\\n\".join(important_images) if important_images else \"해당 페이지에는 분석할 이미지가 없습니다.\"\n",
    "\n",
    "#         # LLM 프롬프트 (전체 대본 흐름 유지)\n",
    "#         prompt = f\"\"\"\n",
    "#         [중요] 정확한 발표 대본만 작성해 주세요. 추가적인 설명, 제안 사항은 포함하지 마세요. 인삿말은 넣지 마세요.\n",
    "\n",
    "#         **이전 내용 (연결을 위한 참고용):**\n",
    "#         {previous_page}\n",
    "\n",
    "#         **현재 페이지 주요 내용:**\n",
    "#         {current_page}\n",
    "\n",
    "#         **다음 내용 (연결을 위한 참고용):**\n",
    "#         {next_page}\n",
    "\n",
    "#         **관련 문서 내용 (RAG 검색 결과):**\n",
    "#         {retrieved_text}\n",
    "\n",
    "#         **필요한 이미지 설명만 포함:**\n",
    "#         {image_text}\n",
    "\n",
    "#         [중요] 발표 대본의 흐름을 자연스럽게 이어가며 정확한 대본만 작성해 주세요.\n",
    "#         \"\"\"\n",
    "\n",
    "#         response = llm.invoke([\n",
    "#             SystemMessage(content=\"당신은 발표 대본을 생성하는 AI입니다. 문서의 흐름을 유지하며 발표 대본만 작성하세요.\"),\n",
    "#             HumanMessage(content=prompt)\n",
    "#         ])\n",
    "\n",
    "#         # 불필요한 내용 필터링\n",
    "#         generated_script = response.content.strip()\n",
    "\n",
    "#         prev_script = generated_script\n",
    "#         page[\"generated_script\"] = generated_script  \n",
    "\n",
    "#     return pages\n",
    "\n",
    "# # 실행 예시\n",
    "# result = generate_script(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# import io\n",
    "# import os\n",
    "# import pdfplumber\n",
    "# from dotenv import load_dotenv\n",
    "# from PIL import Image\n",
    "\n",
    "# # LangChain 관련 임포트\n",
    "# from langchain.document_loaders import PDFPlumberLoader\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.schema import HumanMessage, SystemMessage\n",
    "# from langchain_community.chat_models import ChatOpenAI\n",
    "# from langchain.vectorstores import Chroma as ChromaVectorDB\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain, MapReduceDocumentsChain, RetrievalQA\n",
    "# from langchain.docstore.document import Document\n",
    "# from langchain.chains.combine_documents.reduce import ReduceDocumentsChain\n",
    "# from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "\n",
    "# # 환경 변수 로드 및 PDF 경로 설정\n",
    "# load_dotenv()\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# pdf_path = \"../../data/pdf/DeePrint.pdf\"\n",
    "\n",
    "# #############################################\n",
    "# # 1. 기본 전처리: PDF 추출, 이미지 분석, 벡터 스토어 생성\n",
    "# #############################################\n",
    "\n",
    "# def cvt2base64(pil_image):\n",
    "#     buffer = io.BytesIO()\n",
    "#     pil_image.save(buffer, format=\"JPEG\")\n",
    "#     img_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "#     return img_str\n",
    "\n",
    "# def extract_page(pdf_path):\n",
    "#     loader = PDFPlumberLoader(pdf_path)\n",
    "#     documents = loader.load()\n",
    "#     pages = []\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page_num, doc_page in enumerate(documents):\n",
    "#             page = pdf.pages[page_num]\n",
    "#             text = doc_page.page_content.strip() if doc_page.page_content else \"\"\n",
    "#             images = []\n",
    "#             for img in page.images:\n",
    "#                 x0, y0, x1, y1 = img[\"x0\"], img[\"top\"], img[\"x1\"], img[\"bottom\"]\n",
    "#                 page_image = page.to_image()\n",
    "#                 full_img = page_image.annotated\n",
    "#                 img_crop = full_img.crop((x0, y0, x1, y1))\n",
    "#                 img_base64 = cvt2base64(img_crop)\n",
    "#                 images.append({\n",
    "#                     \"image_id\": len(images) + 1,\n",
    "#                     \"base64\": img_base64\n",
    "#                 })\n",
    "#             pages.append({\n",
    "#                 \"page\": page_num + 1,\n",
    "#                 \"text\": text,\n",
    "#                 \"images\": images\n",
    "#             })\n",
    "#     return pages\n",
    "\n",
    "# def analyze_page_images(pages, llm):\n",
    "#     for page in pages:\n",
    "#         necessary_image_analysis = []\n",
    "#         for img in page[\"images\"]:\n",
    "#             # 먼저 이미지가 대본 작성에 꼭 필요한지 판단\n",
    "#             prompt_necessity = f\"\"\"\n",
    "#             다음은 PDF에서 추출된 이미지의 base64 인코딩 문자열입니다.\n",
    "#             이 이미지가 발표 대본 작성에 꼭 필요한 시각 정보(도표, 그래프 등)를 담고 있다고 생각하시나요?\n",
    "#             반드시 포함해야 한다면 '예', 그렇지 않다면 '아니오'로 대답해 주세요.\n",
    "            \n",
    "#             이미지 데이터: data:image/jpeg;base64,{img[\"base64\"]}\n",
    "#             \"\"\"\n",
    "#             response_necessity = llm.invoke([\n",
    "#                 SystemMessage(content=\"당신은 발표 자료를 분석하는 AI입니다.\"),\n",
    "#                 HumanMessage(content=prompt_necessity)\n",
    "#             ])\n",
    "#             if \"예\" in response_necessity.content:\n",
    "#                 prompt_for_analysis = f\"\"\"\n",
    "#                 해당 이미지를 해석하여, 발표 대본에 포함할 핵심 시각 정보를 텍스트로 요약해 주세요.\n",
    "#                 이미지 데이터: data:image/jpeg;base64,{img[\"base64\"]}\n",
    "#                 \"\"\"\n",
    "#                 response_analysis = llm.invoke([\n",
    "#                     SystemMessage(content=\"당신은 발표 자료를 분석하는 AI입니다.\"),\n",
    "#                     HumanMessage(content=prompt_for_analysis)\n",
    "#                 ])\n",
    "#                 analysis = response_analysis.content.strip()\n",
    "#                 necessary_image_analysis.append(analysis)\n",
    "#         page[\"image_analysis\"] = \"\\n\".join(necessary_image_analysis) if necessary_image_analysis else \"\"\n",
    "#     return pages\n",
    "\n",
    "# # 벡터 스토어 생성: 페이지 텍스트와 이미지 분석 결과를 함께 저장\n",
    "# embedding_model_name = \"jhgan/ko-sbert-nli\"\n",
    "# embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# def create_vector_store(pages):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "#     texts = [\n",
    "#         f\"Page {p['page']}:\\nText: {p['text']}\\nImage Analysis: {p.get('image_analysis', '없음')}\"\n",
    "#         for p in pages\n",
    "#     ]\n",
    "#     docs = text_splitter.create_documents(texts)\n",
    "#     vector_store = ChromaVectorDB.from_documents(docs, embedding)\n",
    "#     return vector_store\n",
    "\n",
    "# #############################################\n",
    "# # 2. 페이지별 요약 및 초안 생성 \n",
    "# #############################################\n",
    "\n",
    "# # LLM 인스턴스 생성\n",
    "# # llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "# llm = ChatOllama(model=\"gemma3:12b\", temperature=0)\n",
    "\n",
    "# # 2-1. 각 페이지의 원문을 간략하게 요약하는 체인 (일관성 향상을 위해)\n",
    "# summary_prompt = PromptTemplate(\n",
    "#     input_variables=[\"page_text\"],\n",
    "#     template=\"\"\"\n",
    "#     아래 페이지 내용을 2~3문장으로 간략하게 요약해 주세요.\n",
    "#     내용: {page_text}\n",
    "#     \"\"\"\n",
    "# )\n",
    "# summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "# # 페이지 전처리: 페이지별 요약 생성\n",
    "# pages = extract_page(pdf_path)\n",
    "# pages = analyze_page_images(pages, llm)\n",
    "# vector_store = create_vector_store(pages)\n",
    "# for page in pages:\n",
    "#     page[\"summary\"] = summary_chain.run({\"page_text\": page[\"text\"]})\n",
    "\n",
    "# # 2-2. 각 페이지별 초안 생성: 이전, 현재, 다음 요약과 관련 정보(RAG)를 활용하여 구조화된 초안(JSON 형식: 도입, 본론, 결론)\n",
    "# page_draft_prompt = PromptTemplate(\n",
    "#     input_variables=[\"previous\", \"current\", \"next\", \"retrieved\"],\n",
    "#     template=\"\"\"\n",
    "#     다음 페이지 요약 정보를 참고하여, 도입, 본론, 결론의 구조로 발표 대본 초안을 작성해 주세요.\n",
    "#     이전 요약: {previous}\n",
    "#     현재 요약: {current}\n",
    "#     다음 요약: {next}\n",
    "    \n",
    "#     관련 정보: {retrieved}\n",
    "    \n",
    "#     출력은 JSON 형식으로, 예:\n",
    "#     {{\"introduction\": \"도입 내용\", \"body\": \"본론 내용\", \"conclusion\": \"결론 내용\"}}\n",
    "#     로 작성해 주세요.\n",
    "#     \"\"\"\n",
    "# )\n",
    "# page_draft_chain = LLMChain(llm=llm, prompt=page_draft_prompt)\n",
    "\n",
    "# # 각 페이지 초안 생성\n",
    "# for i, page in enumerate(pages):\n",
    "#     previous_summary = pages[i-1][\"summary\"] if i > 0 else \"\"\n",
    "#     current_summary = page[\"summary\"]\n",
    "#     next_summary = pages[i+1][\"summary\"] if i < len(pages)-1 else \"\"\n",
    "#     # RAG: 이전+현재+다음 요약을 바탕으로 관련 정보를 벡터 스토어에서 검색\n",
    "#     query_text = f\"{previous_summary}\\n{current_summary}\\n{next_summary}\".strip()\n",
    "#     retrieved_docs = vector_store.similarity_search(query_text, k=5)\n",
    "#     retrieved_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "#     page[\"draft\"] = page_draft_chain.run({\n",
    "#         \"previous\": previous_summary,\n",
    "#         \"current\": current_summary,\n",
    "#         \"next\": next_summary,\n",
    "#         \"retrieved\": retrieved_text\n",
    "#     })\n",
    "\n",
    "# #############################################\n",
    "# # 3. 중복 제거 및 전체 대본 통합 \n",
    "# #############################################\n",
    "\n",
    "# # Map 단계 프롬프트: 각 페이지 초안을 구조화된 요약으로 변환하는 프롬프트\n",
    "# map_prompt = PromptTemplate(\n",
    "#     input_variables=[\"page_draft\"],\n",
    "#     template=\"\"\"\n",
    "#     아래의 페이지 대본 초안을 도입, 본론, 결론 구조로 요약해 주세요.\n",
    "#     초안: {page_draft}\n",
    "    \n",
    "#     출력은 JSON 형식으로 작성해 주세요.\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # Reduce 단계 프롬프트: 여러 초안 목록을 하나의 일관된 발표 대본으로 통합 (중복 및 반복 제거)\n",
    "# reduce_prompt = PromptTemplate(\n",
    "#     input_variables=[\"drafts\"],\n",
    "#     template=\"\"\"\n",
    "#     아래는 여러 페이지에서 생성된 대본 초안 목록입니다.\n",
    "#     중복되는 내용은 제거하고, 전체 흐름이 자연스럽도록 하나의 최종 발표 대본으로 통합해 주세요.\n",
    "    \n",
    "#     초안 목록:\n",
    "#     {drafts}\n",
    "    \n",
    "#     최종 발표 대본을 출력해 주세요.\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # 🔹 Map 단계: 각 페이지 초안을 구조화된 요약으로 변환하는 LLMChain\n",
    "# map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "# # 🔹 Reduce 단계: 여러 초안을 하나의 일관된 발표 대본으로 통합하는 LLMChain\n",
    "# reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# # 🔹 StuffDocumentsChain을 사용하여 개별 문서(페이지)를 하나로 결합하는 체인 설정\n",
    "# stuff_chain = StuffDocumentsChain(\n",
    "#     llm_chain=reduce_chain,\n",
    "#     document_variable_name=\"drafts\"\n",
    "# )\n",
    "\n",
    "# # 🔹 ReduceDocumentsChain을 사용하여 최종 대본을 생성하는 체인 설정\n",
    "# reduce_documents_chain = ReduceDocumentsChain(\n",
    "#     combine_documents_chain=stuff_chain\n",
    "# )\n",
    "\n",
    "# # 🔹 MapReduceDocumentsChain을 생성\n",
    "# map_reduce_chain = MapReduceDocumentsChain(\n",
    "#     llm_chain=map_chain,\n",
    "#     reduce_documents_chain=reduce_documents_chain\n",
    "# )\n",
    "\n",
    "# # 🔹 페이지별 초안을 문서 객체로 변환\n",
    "# documents = [Document(page_content=page[\"draft\"]) for page in pages]\n",
    "\n",
    "# # 🔹 MapReduceDocumentsChain 실행\n",
    "# combined_draft = map_reduce_chain.run(documents)\n",
    "\n",
    "# #############################################\n",
    "# # 4. 정보 통합 및 최종 대본 보완 \n",
    "# #############################################\n",
    "\n",
    "# # RetrievalQA 체인을 사용해 벡터 스토어에서 추가 핵심 정보를 선택적으로 가져옴\n",
    "# retrieval_qa = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=vector_store.as_retriever()\n",
    "# )\n",
    "# additional_info = retrieval_qa.run(\"발표 대본 생성을 위한 핵심 정보 요약\")\n",
    "\n",
    "# # RefineChain: 기존 통합 초안과 추가 정보를 바탕으로 최종 대본 재구성\n",
    "# refine_prompt = PromptTemplate(\n",
    "#     input_variables=[\"existing_script\", \"additional_info\"],\n",
    "#     template=\"\"\"\n",
    "#     기존 발표 대본 초안:\n",
    "#     {existing_script}\n",
    "    \n",
    "#     추가 정보:\n",
    "#     {additional_info}\n",
    "    \n",
    "#     위 정보를 바탕으로 중복을 제거하고 전체 흐름이 자연스러운 최종 발표 대본을 작성해 주세요.\n",
    "#     \"\"\"\n",
    "# )\n",
    "# refine_chain = LLMChain(llm=llm, prompt=refine_prompt)\n",
    "# final_script = refine_chain.run({\n",
    "#     \"existing_script\": combined_draft,\n",
    "#     \"additional_info\": additional_info\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 발표 대본:\n",
      " 안녕하세요. 오늘 저희 발표의 주제는 '발표 준비'와 이를 지원하는 혁신적인 인공지능 모델인 '오인용'입니다. 발표는 크게 세 부분으로 나누어 진행될 예정입니다. 첫 번째로 프로젝트의 개요를 살펴보고, 두 번째로 기획 배경과 시스템 구조를 설명한 후, 마지막으로 프로젝트의 방향성과 발전 방안에 대해 논의하겠습니다.\n",
      "\n",
      "이 프로젝트는 최초의 발표하는 인공지능 모델인 '오인용'을 중심으로 구성되어 있습니다. 이 모델은 중요한 내용을 중심으로 발표용 대본을 생성하는 기능을 가지고 있으며, AI 음성 합성을 활용하여 자동으로 발표를 진행할 수 있습니다. 이러한 기능은 기업, 연구자, 학생들이 정보를 보다 효율적으로 활용할 수 있도록 도와주며, 일관된 발표 퀄리티를 유지하고 발표에 소요되는 시간을 단축하는 데 기여할 것입니다.\n",
      "\n",
      "발표는 우리 삶에 얼마나 밀접하게 연결되어 있는지를 탐구하는 과정으로, '발표 준비'라는 키워드를 중심으로 블로그, 뉴스, 카페, 지식인 등에서 수집한 정보를 바탕으로 발표의 방향성과 목표를 이해하는 데 도움을 줄 것입니다. 발표 준비와 관련된 정보를 수집하기 위해 다양한 온라인 플랫폼에서 데이터를 크롤링하였으며, 이 과정에서 수집된 데이터는 Wordcloud와 Networkx를 활용하여 시각화될 예정입니다. 이를 통해 발표 준비의 중요성과 관련된 키워드를 시각적으로 표현하고, 발표에 대한 불안감을 유발하는 요인들을 분석할 것입니다.\n",
      "\n",
      "최근 설문조사에 따르면, 많은 직장인들이 발표 전 불안감을 느끼고 있으며, 그 주요 원인은 내성적 성격(31.3%)과 실수에 대한 압박감(25%)으로 나타났습니다. 또한, 무대 공포증(12.5%)과 질문에 대한 대응 어려움(10.4%)도 불안감을 유발하는 주요 요인으로 지적되었습니다. 이러한 결과는 발표에 대한 두려움과 준비 부족이 직장인들에게 큰 영향을 미친다는 것을 보여줍니다.\n",
      "\n",
      "결론적으로, 발표 준비는 단순한 정보 전달을 넘어, 개인의 자신감과 직무 수행 능력에 큰 영향을 미칩니다. 발표에 대한 불안감을 줄이기 위해서는 충분한 준비와 연습이 필요하며, 이를 통해 발표의 질을 높이고, 발표자 자신도 더 나은 경험을 할 수 있습니다. 저희 프로젝트는 발표의 효율성을 높이고, 다양한 사용자들이 정보를 효과적으로 활용할 수 있도록 돕는 것을 목표로 하고 있습니다. 앞으로도 이러한 기술들이 발전하여 더 많은 사람들이 발표의 기회를 가질 수 있기를 기대합니다.\n",
      "\n",
      "이제 저희 AI 프로젝트의 기획 단계와 기술 스택, 시스템 구조, 그리고 서비스 사용자 인터페이스(UI) 구성에 대해 말씀드리겠습니다. 본 프로젝트는 발표용 대본을 자동으로 생성하는 인공지능 모델을 개발하는 것을 목표로 하고 있으며, 이를 위해 OpenAI, ChromaDB, LangChain, Hugging Face, Ollama, FastAPI, Streamlit 등 다양한 기술을 활용할 예정입니다.\n",
      "\n",
      "먼저, 사용될 기술 스택에 대해 설명하겠습니다. LangChain은 AI 에이전트가 수행하는 과정을 하나의 체인으로 묶는 데 사용되며, Ollama는 로컬 환경에서 AI 모델을 실행하여 보안과 성능을 최적화합니다. Hugging Face는 다양한 사전 학습된 모델을 검색하고 활용할 수 있는 플랫폼으로, FastAPI는 AI 모델을 서빙하고 사용자 요청을 처리하는 역할을 합니다. ChromaDB는 문서를 저장하고 빠르게 검색할 수 있도록 돕는 Vector DB이며, Streamlit은 사용자에게 웹 애플리케이션 형태로 서비스를 제공하는 UI 프레임워크로 사용됩니다.\n",
      "\n",
      "이 프로젝트의 기획 단계에서는 랭체인과 자연어 처리, 딥러닝 관련 위키독스를 크롤링하여 벡터 임베딩을 수행한 후, 이를 VectorDB에 적재할 계획입니다. 이러한 데이터는 AI 모델의 학습과 성능 향상에 중요한 역할을 할 것입니다. 시스템 구조는 Vector DB와 LLM을 포함하여 구성되며, 사용자와의 상호작용을 위해 다양한 기능을 제공합니다. 주요 기능으로는 발표 자료의 업로드, 처리 완료된 자료의 시각화, 그리고 처리된 자료의 다운로드가 포함됩니다.\n",
      "\n",
      "저희의 발전 방안은 크게 다섯 가지로 나눌 수 있습니다. 첫째, 실시간 상호작용 기능을 통해 발표자가 청중과 즉각적으로 소통할 수 있도록 합니다. 둘째, 인간처럼 말하는 기능을 통해 발표의 자연스러움을 높입니다. 셋째, 발표 스타일의 개인화를 통해 각 발표자의 특성에 맞춘 맞춤형 발표를 지원합니다. 넷째, 발표를 하는 디지털 아바타를 생성하여, 발표자가 아닌 AI가 발표를 진행할 수 있는 가능성을 열어줍니다. 마지막으로, 도메인 확장을 통해 다양한 분야에서 활용될 수 있도록 합니다. 이러한 기술들은 LangChain, Ollama, Hugging Face, FastAPI, ChromaDB, Streamlit 등 다양한 자원과 기술을 활용하여 구현됩니다.\n",
      "\n",
      "결론적으로, 저희의 발표하는 인공지능 모델은 기업, 연구자, 학생 등 다양한 사용자들이 보다 효율적으로 정보를 활용할 수 있도록 도와줄 것입니다. 발표에 드는 시간을 단축시키고, 일관된 발표 퀄리티를 유지할 수 있는 이 모델은 발표에 대한 불안감을 줄이고, 더 나아가 발표의 접근성을 높이는 데 기여할 것입니다. 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"최종 발표 대본:\\n\", final_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m script \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m :\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(script[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_script\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "for script in result :\n",
    "    print(script['generated_script'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
