{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Optional\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def load_txt(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def extract_chapter_meta(chapter_num: str, chapter_title: str) -> dict:\n",
    "    \"\"\"\n",
    "    chapter_num이 '01' → level 1, parent 없음\n",
    "    chapter_num이 '01-02' → level 2, parent '01'\n",
    "    \"\"\"\n",
    "    if \"-\" in chapter_num:\n",
    "        parent = chapter_num.split(\"-\")[0]\n",
    "        level = 2\n",
    "    else:\n",
    "        parent = None\n",
    "        level = 1\n",
    "    return {\n",
    "        \"chapter\": chapter_num,\n",
    "        \"title\": chapter_title,\n",
    "        \"level\": level,\n",
    "        \"parent\": parent\n",
    "    }\n",
    "\n",
    "def split_by_chapter(text: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Wikidocs 형식 텍스트를 챕터별로 나누고 계층 정보를 포함한 Document로 변환\n",
    "    \"\"\"\n",
    "    pattern = r\"(?=^---\\s+(\\d{2}(?:-\\d{2})?)\\.\\s+(.*?)\\s+---)\"\n",
    "    matches = list(re.finditer(pattern, text, flags=re.MULTILINE))\n",
    "\n",
    "    documents = []\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.start()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "\n",
    "        chapter_num = match.group(1)\n",
    "        chapter_title = match.group(2).strip()\n",
    "        chapter_text = text[start:end].strip()\n",
    "\n",
    "        metadata = extract_chapter_meta(chapter_num, chapter_title)\n",
    "\n",
    "        doc = Document(page_content=chapter_text, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents\n",
    "\n",
    "def load_and_split_wikidocs(path: str) -> List[Document]:\n",
    "    text = load_txt(path)\n",
    "    return split_by_chapter(text)\n",
    "\n",
    "def filter_chapters(\n",
    "    documents: List[Document],\n",
    "    level: Optional[int] = None,\n",
    "    parent: Optional[str] = None,\n",
    "    contains_title: Optional[str] = None\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    챕터 리스트에서 조건에 맞는 챕터만 필터링\n",
    "    - level: 1 (대챕터), 2 (소챕터)\n",
    "    - parent: '01' 등 상위 챕터 번호\n",
    "    - contains_title: 제목 키워드 포함 여부\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    for doc in documents:\n",
    "        meta = doc.metadata\n",
    "        if level and meta[\"level\"] != level:\n",
    "            continue\n",
    "        if parent and meta[\"parent\"] != parent:\n",
    "            continue\n",
    "        if contains_title and contains_title not in meta[\"title\"]:\n",
    "            continue\n",
    "        filtered.append(doc)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 총 문서 수: 165\n",
      "🔹 소챕터 수: 0\n",
      "🔹 02번 챕터 하위 수: 0\n",
      "🔹 '설치' 포함 제목 수: 1\n"
     ]
    }
   ],
   "source": [
    "first_docs = load_and_split_wikidocs(\"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_01.txt\")\n",
    "\n",
    "# 소챕터만 추출 (level 2)\n",
    "subchapters = filter_chapters(first_docs, level=2)\n",
    "\n",
    "# 대챕터 02의 모든 소챕터 추출\n",
    "chap02_children = filter_chapters(first_docs, parent=\"02\")\n",
    "\n",
    "# \"설치\"라는 단어를 포함하는 챕터만 추출\n",
    "install_sections = filter_chapters(first_docs, contains_title=\"설치\")\n",
    "\n",
    "print(f\"📌 총 문서 수: {len(first_docs)}\")\n",
    "print(f\"🔹 소챕터 수: {len(subchapters)}\")\n",
    "print(f\"🔹 02번 챕터 하위 수: {len(chap02_children)}\")\n",
    "print(f\"🔹 '설치' 포함 제목 수: {len(install_sections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 총 문서 수: 27\n",
      "🔹 소챕터 수: 0\n",
      "🔹 02번 챕터 하위 수: 0\n",
      "🔹 '설치' 포함 제목 수: 0\n"
     ]
    }
   ],
   "source": [
    "second_docs = load_and_split_wikidocs(\"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_02.txt\")\n",
    "\n",
    "# 소챕터만 추출 (level 2)\n",
    "subchapters = filter_chapters(second_docs, level=2)\n",
    "\n",
    "# 대챕터 02의 모든 소챕터 추출\n",
    "chap02_children = filter_chapters(second_docs, parent=\"02\")\n",
    "\n",
    "# \"설치\"라는 단어를 포함하는 챕터만 추출\n",
    "install_sections = filter_chapters(second_docs, contains_title=\"설치\")\n",
    "\n",
    "print(f\"📌 총 문서 수: {len(second_docs)}\")\n",
    "print(f\"🔹 소챕터 수: {len(subchapters)}\")\n",
    "print(f\"🔹 02번 챕터 하위 수: {len(chap02_children)}\")\n",
    "print(f\"🔹 '설치' 포함 제목 수: {len(install_sections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 총 문서 수: 33\n",
      "🔹 소챕터 수: 4\n",
      "🔹 02번 챕터 하위 수: 0\n",
      "🔹 '설치' 포함 제목 수: 0\n"
     ]
    }
   ],
   "source": [
    "third_docs = load_and_split_wikidocs(\"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_03.txt\")\n",
    "\n",
    "# 소챕터만 추출 (level 2)\n",
    "subchapters = filter_chapters(third_docs, level=2)\n",
    "\n",
    "# 대챕터 02의 모든 소챕터 추출\n",
    "chap02_children = filter_chapters(third_docs, parent=\"02\")\n",
    "\n",
    "# \"설치\"라는 단어를 포함하는 챕터만 추출\n",
    "install_sections = filter_chapters(third_docs, contains_title=\"설치\")\n",
    "\n",
    "print(f\"📌 총 문서 수: {len(third_docs)}\")\n",
    "print(f\"🔹 소챕터 수: {len(subchapters)}\")\n",
    "print(f\"🔹 02번 챕터 하위 수: {len(chap02_children)}\")\n",
    "print(f\"🔹 '설치' 포함 제목 수: {len(install_sections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "27\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(first_docs))\n",
    "print(len(second_docs))\n",
    "print(len(third_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서 청크 수: 4746\n",
      "두 번째 문서 청크 수: 1983\n",
      "세 번째 문서 청크 수: 2964\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 분할기 초기화 (하나의 스플리터만 사용)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 청크 크기\n",
    "    chunk_overlap=50,  # 청크 간 중복\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 분할 기준\n",
    ")\n",
    "\n",
    "first_splits = []\n",
    "second_splits = []\n",
    "third_splits = []\n",
    "\n",
    "for doc in first_docs:\n",
    "    splits = splitter.split_text(doc.page_content)\n",
    "    first_splits.extend(splits)\n",
    "    # print(first_splits)\n",
    "\n",
    "for doc in second_docs:\n",
    "    splits = splitter.split_text(doc.page_content)\n",
    "    second_splits.extend(splits)\n",
    "    # print(second_splits)\n",
    "\n",
    "for doc in third_docs:\n",
    "    splits = splitter.split_text(doc.page_content)\n",
    "    third_splits.extend(splits)\n",
    "    # print(third_splits)\n",
    "\n",
    "print(f\"첫 번째 문서 청크 수: {len(first_splits)}\")\n",
    "print(f\"두 번째 문서 청크 수: {len(second_splits)}\")\n",
    "print(f\"세 번째 문서 청크 수: {len(third_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4640\\1310670779.py:30: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  first_db.persist()\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수에서 API 키 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings()  # OpenAI 임베딩 모델 지정\n",
    "\n",
    "# DB 디렉토리 존재 여부 확인 및 삭제\n",
    "if os.path.exists(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\first_db\"):\n",
    "    shutil.rmtree(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\first_db\")\n",
    "if os.path.exists(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\second_db\"):\n",
    "    shutil.rmtree(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\second_db\")\n",
    "if os.path.exists(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\third_db\"):\n",
    "    shutil.rmtree(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\third_db\")\n",
    "\n",
    "# 첫 번째 문서 DB 생성\n",
    "first_db = Chroma.from_texts(\n",
    "    texts=first_splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\first_db\"\n",
    ")\n",
    "first_db.persist()\n",
    "\n",
    "# # 두 번째 문서 DB 생성\n",
    "# second_db = Chroma.from_texts(\n",
    "#     texts=second_splits,\n",
    "#     embedding=embeddings,\n",
    "#     persist_directory=r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\second_db\"\n",
    "# )\n",
    "# second_db.persist()\n",
    "\n",
    "# # 세 번째 문서 DB 생성\n",
    "# third_db = Chroma.from_texts(\n",
    "#     texts=third_splits,\n",
    "#     embedding=embeddings,\n",
    "#     persist_directory=r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\third_db\"\n",
    "# )\n",
    "# third_db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='# 원하는 Pandas DataFrame을 정의합니다.\\ndf = pd.read_csv(\"./data/titanic.csv\")\\ndf.head()'),\n",
       " Document(metadata={}, page_content='PassengerId\\nSurvived\\nPclass\\nName\\nSex\\nAge\\nSibSp\\nParch\\nTicket\\nFare\\nCabin\\nEmbarked\\n1\\n0\\n3\\nBraund, Mr. Owen Harris\\nmale\\n22\\n1\\n0\\nA/5 21171\\n7.25\\nS\\n2\\n1\\n1\\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\\nfemale\\n38\\n1\\n0\\nPC 17599\\n71.2833\\nC85\\nC\\n3\\n1\\n3\\nHeikkinen, Miss. Laina\\nfemale\\nDataFrameLoader\\nPandas는 Python 프로그래밍 언어를 위한 오픈 소스 데이터 분석 및 조작 도구입니다. 이 라이브러리는 데이터 과학, 머신러닝, 그리고 다양한 분야의 데이터 작업에 널리 사용되고 있습니다.\\nimport pandas as pd\\n# CSV 파일 읽기\\ndf = pd.read_csv(\"./data/titanic.csv\")\\n첫 5개 행을 조회합니다.'),\n",
       " Document(metadata={}, page_content=\"연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n판다스 (Pandas)\\nMetadata: {'source': './data/appendix-keywords.txt', 'id': 10, 'relevance_score': 0.9997084}\"),\n",
       " Document(metadata={}, page_content='# !pip install -qU langchain-teddynote\\nfrom langchain_teddynote import logging\\n# 프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH15-Agent-Toolkits\")\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\nCH15-Agent-Toolkits\\nimport pandas as pd\\ndf = pd.read_csv(\"./data/titanic.csv\")  # CSV 파일을 읽습니다.\\n# df = pd.read_excel(\"./data/titanic.xlsx\") # 엑셀 파일도 읽을 수 있습니다.\\ndf.head()\\n[이미지: ]\\nfrom langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\\nfrom langchain.agents.agent_types import AgentType'),\n",
       " Document(metadata={}, page_content=\"[이미지: ]\\n[도구 호출]\\nTool: python_repl_ast\\nquery: import pandas as pd\\nimport matplotlib.pyplot as plt\\n# 남자와 여자 승객의 생존율 계산\\nsurvival_rate = df.groupby('Sex')['Survived'].mean()\\n# barplot 시각화\\nsurvival_rate.plot(kind='bar', color=['blue', 'pink'])\\nplt.title('Survival Rate by Gender')\\nplt.xlabel('Gender')\\nplt.ylabel('Survival Rate')\\nplt.xticks(rotation=0)\\nplt.show()\\nLog:\"),\n",
       " Document(metadata={}, page_content='# !pip install -qU langchain-teddynote\\nfrom langchain_teddynote import logging\\n# 프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH16-Evaluations\")\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\nCH16-Evaluations\\n저장한 CSV 파일로부터 로드\\ndata/ragas_synthetic_dataset.csv 파일을 로드합니다.\\nimport pandas as pd\\ndf = pd.read_csv(\"data/ragas_synthetic_dataset.csv\")\\ndf.head()\\n[이미지: ]\\nfrom datasets import Dataset\\ntest_dataset = Dataset.from_pandas(df)\\ntest_dataset'),\n",
       " Document(metadata={}, page_content='아래 코드는 업로드한 HuggingFace Dataset 을 활용하는 예시입니다.\\n(참고) 아래의 주석을 풀고 실행하여 datasets 라이브러리를 업데이트 후 진행해 주세요.\\n# !pip install -qU datasets\\nimport pandas as pd\\nfrom datasets import load_dataset, Dataset\\nimport os\\n# huggingface Dataset에서 repo_id로 데이터셋 다운로드\\ndataset = load_dataset(\\n\"teddylee777/rag-synthetic-dataset\",  # 데이터셋 이름\\ntoken=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],  # private 데이터인 경우 필요합니다.\\n)\\n# 데이터셋에서 split 기준으로 조회\\nhuggingface_df = dataset[\"korean_v1\"].to_pandas()\\nhuggingface_df.head()\\n[이미지: ]'),\n",
       " Document(metadata={}, page_content='----------------------------------------------------------------------------------------------------\\nDocument 6:\\n판다스 (Pandas)\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\\nGPT (Generative Pretrained Transformer)\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.'),\n",
       " Document(metadata={}, page_content='```\\n22.19937\\n```PandasDataFrameOutputParser\\nPandas DataFrame은 Python 프로그래밍 언어에서 널리 사용되는 데이터 구조로, 데이터 조작 및 분석을 위해 흔히 사용됩니다. 구조화된 데이터를 다루기 위한 포괄적인 도구 세트를 제공하여, 데이터 정제, 변환 및 분석과 같은 작업에 다양하게 활용될 수 있습니다.\\n이 출력 파서는 사용자가 임의의 Pandas DataFrame을 지정하고 해당 DataFrame에서 데이터를 추출하여 형식화된 사전 형태로 데이터를 조회할 수 있는 LLM을 요청할 수 있게 해줍니다.\\nfrom dotenv import load_dotenv\\nload_dotenv()\\nTrue\\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\\n# !pip install langchain-teddynote\\nfrom langchain_teddynote import logging'),\n",
       " Document(metadata={}, page_content='Document 7:\\n판다스 (Pandas)\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\\nGPT (Generative Pretrained Transformer)\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\nInstructGPT')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10}).invoke('import pandas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from typing import List\n",
    "# from langchain_core.documents import Document\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# def load_txt(path: str) -> str:\n",
    "#     \"\"\"\n",
    "#     텍스트 파일을 UTF-8로 로드\n",
    "#     \"\"\"\n",
    "#     with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         return f.read()\n",
    "\n",
    "# def extract_chapter_meta(chapter_num: str, chapter_title: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     개선된 버전: 제목 내 [카테고리] → parent\n",
    "#     \"\"\"\n",
    "#     # [카테고리]가 존재하면 parent로 추정\n",
    "#     category_match = re.match(r\"\\[(.*?)\\]\", chapter_title)\n",
    "#     if category_match:\n",
    "#         parent = category_match.group(1)\n",
    "#     else:\n",
    "#         parent = None\n",
    "\n",
    "#     return {\n",
    "#         \"chapter\": chapter_num,\n",
    "#         \"title\": chapter_title,\n",
    "#         \"level\": 1,  # 실제 파일에는 대챕터만 존재\n",
    "#         \"parent\": parent\n",
    "#     }\n",
    "\n",
    "# def protect_code_blocks(text: str) -> str:\n",
    "#     \"\"\"\n",
    "#     ```로 감싸진 코드 블록을 <CODE_BLOCK>으로 감싸 보존\n",
    "#     \"\"\"\n",
    "#     code_pattern = re.compile(r\"```.*?\\n.*?```\", re.DOTALL)\n",
    "#     protected = []\n",
    "#     last_end = 0\n",
    "\n",
    "#     for match in code_pattern.finditer(text):\n",
    "#         start, end = match.span()\n",
    "#         protected.append(text[last_end:start])\n",
    "#         code = match.group()\n",
    "#         protected.append(f\"\\n<CODE_BLOCK>\\n{code}\\n</CODE_BLOCK>\\n\")\n",
    "#         last_end = end\n",
    "\n",
    "#     protected.append(text[last_end:])\n",
    "#     return \"\".join(protected)\n",
    "\n",
    "# def split_by_chapter_with_code(text: str) -> List[Document]:\n",
    "#     \"\"\"\n",
    "#     챕터 헤더(--- 01. 제목 ---) 기준으로 분할하되, 각 챕터 내 코드블록 보존\n",
    "#     \"\"\"\n",
    "#     pattern = r\"(?=^---\\s+(\\d{2}(?:-\\d{2})?)\\.\\s+(.*?)\\s+---)\"\n",
    "#     matches = list(re.finditer(pattern, text, flags=re.MULTILINE))\n",
    "\n",
    "#     documents = []\n",
    "#     for i, match in enumerate(matches):\n",
    "#         start = match.start()\n",
    "#         end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "\n",
    "#         chapter_num = match.group(1)\n",
    "#         chapter_title = match.group(2).strip()\n",
    "#         chapter_text = text[start:end].strip()\n",
    "\n",
    "#         protected_text = protect_code_blocks(chapter_text)\n",
    "#         metadata = extract_chapter_meta(chapter_num, chapter_title)\n",
    "\n",
    "#         documents.append(Document(page_content=protected_text, metadata=metadata))\n",
    "\n",
    "#     return documents\n",
    "\n",
    "# def process_wikidocs_files(paths: List[str]) -> List[Document]:\n",
    "#     \"\"\"\n",
    "#     여러 Wikidocs 형식의 텍스트 파일을 처리하여 Document 리스트로 반환\n",
    "#     \"\"\"\n",
    "#     all_docs = []\n",
    "#     for path in paths:\n",
    "#         text = load_txt(path)\n",
    "#         docs = split_by_chapter_with_code(text)\n",
    "#         all_docs.extend(docs)\n",
    "#     return all_docs\n",
    "\n",
    "# def extract_and_replace_code_blocks(text: str):\n",
    "#     \"\"\"\n",
    "#     <CODE_BLOCK>...</CODE_BLOCK> 구간을 [[CODE:0]], [[CODE:1]], ...로 치환\n",
    "#     \"\"\"\n",
    "#     code_blocks = []\n",
    "#     pattern = re.compile(r\"<CODE_BLOCK>\\s*```.*?\\n.*?```\\s*</CODE_BLOCK>\", re.DOTALL)\n",
    "\n",
    "#     def replacer(match):\n",
    "#         code_blocks.append(match.group())\n",
    "#         return f\"[[CODE:{len(code_blocks) - 1}]]\"\n",
    "\n",
    "#     modified_text = pattern.sub(replacer, text)\n",
    "#     return modified_text, code_blocks\n",
    "\n",
    "# def split_protected_chunks(docs: List[Document], chunk_size=1000, chunk_overlap=200) -> List[Document]:\n",
    "#     \"\"\"\n",
    "#     코드 블록이 잘리지 않도록 보호한 상태로 chunk 분할\n",
    "#     \"\"\"\n",
    "#     splitter = RecursiveCharacterTextSplitter(\n",
    "#         chunk_size=chunk_size,\n",
    "#         chunk_overlap=chunk_overlap\n",
    "#     )\n",
    "\n",
    "#     chunked_docs = []\n",
    "#     for doc in docs:\n",
    "#         # 코드 블록을 임시 토큰으로 치환\n",
    "#         mod_text, code_blocks = extract_and_replace_code_blocks(doc.page_content)\n",
    "#         temp_doc = Document(page_content=mod_text, metadata=doc.metadata)\n",
    "\n",
    "#         # 분할\n",
    "#         split_docs = splitter.split_documents([temp_doc])\n",
    "\n",
    "#         # 코드 블록 복원\n",
    "#         for d in split_docs:\n",
    "#             restored_text = d.page_content\n",
    "#             for i, block in enumerate(code_blocks):\n",
    "#                 restored_text = restored_text.replace(f\"[[CODE:{i}]]\", block)\n",
    "#             d.page_content = restored_text\n",
    "#             chunked_docs.append(d)\n",
    "\n",
    "#     return chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_txt(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def protect_code_blocks(text: str) -> str:\n",
    "    code_pattern = re.compile(r\"```.*?\\n.*?```\", re.DOTALL)\n",
    "    protected = []\n",
    "    last_end = 0\n",
    "    for match in code_pattern.finditer(text):\n",
    "        start, end = match.span()\n",
    "        protected.append(text[last_end:start])\n",
    "        code = match.group()\n",
    "        protected.append(f\"\\n<CODE_BLOCK>\\n{code}\\n</CODE_BLOCK>\\n\")\n",
    "        last_end = end\n",
    "    protected.append(text[last_end:])\n",
    "    return \"\".join(protected)\n",
    "\n",
    "def split_by_structure_with_code(text: str) -> List[Document]:\n",
    "    lines = text.splitlines()\n",
    "    documents = []\n",
    "    buffer = []\n",
    "\n",
    "    current_chapter_num = None\n",
    "    current_chapter_title = None\n",
    "    current_section_num = None\n",
    "    current_section_title = None\n",
    "\n",
    "    chapter_pattern = re.compile(r\"^---\\s+CH(\\d+)\\s+(.*?)\\s+---$\")\n",
    "    section_pattern = re.compile(r\"^---\\s+(\\d{2})\\.\\s+(.*?)\\s+---$\")\n",
    "    title_only_pattern = re.compile(r\"^(---|===).*?(---|===)$\")\n",
    "\n",
    "    for line in lines:\n",
    "        chapter_match = chapter_pattern.match(line)\n",
    "        section_match = section_pattern.match(line)\n",
    "\n",
    "        if chapter_match:\n",
    "            # flush 이전 buffer\n",
    "            if buffer:\n",
    "                chunk = \"\\n\".join(buffer).strip()\n",
    "                # 제목만 있는 문서인지 확인\n",
    "                if not is_title_only_document(chunk):\n",
    "                    protected = protect_code_blocks(chunk)\n",
    "                    documents.append(Document(\n",
    "                        page_content=protected,\n",
    "                        metadata={\n",
    "                            \"chapter_info\": f\"CH{current_chapter_num} {current_chapter_title}\" if current_chapter_num else None,\n",
    "                            \"section_info\": f\"{current_section_num}. {current_section_title}\" if current_section_num else None,\n",
    "                        }\n",
    "                    ))\n",
    "                buffer = []\n",
    "\n",
    "            current_chapter_num = chapter_match.group(1)\n",
    "            current_chapter_title = chapter_match.group(2).strip()\n",
    "            current_section_num, current_section_title = None, None\n",
    "\n",
    "        elif section_match:\n",
    "            if buffer:\n",
    "                chunk = \"\\n\".join(buffer).strip()\n",
    "                # 제목만 있는 문서인지 확인\n",
    "                if not is_title_only_document(chunk):\n",
    "                    protected = protect_code_blocks(chunk)\n",
    "                    documents.append(Document(\n",
    "                        page_content=protected,\n",
    "                        metadata={\n",
    "                            \"chapter_info\": f\"CH{current_chapter_num} {current_chapter_title}\" if current_chapter_num else None,\n",
    "                            \"section_info\": f\"{current_section_num}. {current_section_title}\" if current_section_num else None,\n",
    "                        }\n",
    "                    ))\n",
    "                buffer = []\n",
    "\n",
    "            current_section_num = section_match.group(1)\n",
    "            current_section_title = section_match.group(2).strip()\n",
    "\n",
    "        buffer.append(line)\n",
    "\n",
    "    if buffer:\n",
    "        chunk = \"\\n\".join(buffer).strip()\n",
    "        # 제목만 있는 문서인지 확인\n",
    "        if not is_title_only_document(chunk):\n",
    "            protected = protect_code_blocks(chunk)\n",
    "            documents.append(Document(\n",
    "                page_content=protected,\n",
    "                metadata={\n",
    "                    \"chapter_info\": f\"CH{current_chapter_num} {current_chapter_title}\" if current_chapter_num else None,\n",
    "                    \"section_info\": f\"{current_section_num}. {current_section_title}\" if current_section_num else None,\n",
    "                }\n",
    "            ))\n",
    "\n",
    "    return documents\n",
    "\n",
    "def is_title_only_document(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    문서가 제목만 포함하고 있는지 확인합니다.\n",
    "    \"\"\"\n",
    "    # 공백과 줄바꿈을 제거한 텍스트\n",
    "    cleaned_text = text.strip()\n",
    "    \n",
    "    # 제목 패턴 (---로 시작하고 ---로 끝나거나, ===로 시작하고 ===로 끝나는 패턴)\n",
    "    title_pattern = re.compile(r\"^(---|===).*?(---|===)$\", re.DOTALL)\n",
    "    \n",
    "    # 텍스트가 제목 패턴만 포함하는지 확인\n",
    "    if title_pattern.match(cleaned_text):\n",
    "        # 제목 패턴을 제거한 후 내용이 있는지 확인\n",
    "        content_without_title = re.sub(r\"(---|===).*?(---|===)\", \"\", cleaned_text, flags=re.DOTALL).strip()\n",
    "        return not content_without_title\n",
    "    \n",
    "    return False\n",
    "\n",
    "def process_wikidocs_files(paths: List[str]) -> List[Document]:\n",
    "    all_docs = []\n",
    "    for path in paths:\n",
    "        text = load_txt(path)\n",
    "        docs = split_by_structure_with_code(text)\n",
    "        all_docs.extend(docs)\n",
    "    return all_docs\n",
    "\n",
    "def extract_and_replace_code_blocks(text: str):\n",
    "    code_blocks = []\n",
    "    pattern = re.compile(r\"<CODE_BLOCK>\\s*```.*?\\n.*?```\\s*</CODE_BLOCK>\", re.DOTALL)\n",
    "    def replacer(match):\n",
    "        code_blocks.append(match.group())\n",
    "        return f\"[[CODE:{len(code_blocks) - 1}]]\"\n",
    "    modified_text = pattern.sub(replacer, text)\n",
    "    return modified_text, code_blocks\n",
    "\n",
    "def split_protected_chunks(docs: List[Document], chunk_size=2000, chunk_overlap=50) -> List[Document]:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    chunked_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        mod_text, code_blocks = extract_and_replace_code_blocks(doc.page_content)\n",
    "        temp_doc = Document(page_content=mod_text, metadata=doc.metadata)\n",
    "        split_docs = splitter.split_documents([temp_doc])\n",
    "\n",
    "        for d in split_docs:\n",
    "            # 실제로 사용된 [[CODE:X]]만 찾아서 복원\n",
    "            used_codes = re.findall(r\"\\[\\[CODE:(\\d+)\\]\\]\", d.page_content)\n",
    "            for code_index in set(used_codes):\n",
    "                code_index = int(code_index)\n",
    "                if code_index < len(code_blocks):\n",
    "                    d.page_content = d.page_content.replace(f\"[[CODE:{code_index}]]\", code_blocks[code_index])\n",
    "            chunked_docs.append(d)\n",
    "\n",
    "    return chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 원본 챕터 수: 184\n",
      "총 분할된 문서 수 (임베딩용): 1241\n",
      "--- 샘플 ---\n",
      "--- CH01 LangChain 시작하기 ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Wikidocs 텍스트 파일들을 챕터 단위로 로딩 (설명 + 코드 보존)\n",
    "docs = process_wikidocs_files([\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_01.txt\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_02.txt\",\n",
    "    \"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_03.txt\"\n",
    "])\n",
    "\n",
    "# 2. 임베딩 전용 chunk 단위로 분할 (코드블록 보호됨)\n",
    "chunked_docs = split_protected_chunks(docs)\n",
    "\n",
    "# 3. 확인\n",
    "print(f\"총 원본 챕터 수: {len(docs)}\")\n",
    "print(f\"총 분할된 문서 수 (임베딩용): {len(chunked_docs)}\")\n",
    "print(\"--- 샘플 ---\")\n",
    "print(chunked_docs[1].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document 객체에서 텍스트 내용만 추출\n",
    "text_contents = [doc.page_content for doc in chunked_docs]\n",
    "\n",
    "test_db = Chroma.from_texts(\n",
    "    texts=text_contents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\test_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='--- 04. FlashRank Reranker ---'),\n",
       " Document(metadata={}, page_content='--- 04. FlashRank Reranker ---'),\n",
       " Document(metadata={}, page_content='--- 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) ---'),\n",
       " Document(metadata={}, page_content='--- 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) ---'),\n",
       " Document(metadata={}, page_content='<CODE_BLOCK>\\n```\\nPassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\\n```\\n</CODE_BLOCK>\\nPassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\\n컬럼에 대한 값을 조회하는 예제입니다.\\n# 열 작업 예시입니다.\\ndf_query = \"Age column 을 조회해 주세요.\"\\n# 프롬프트 템플릿을 설정합니다.\\nprompt = PromptTemplate(\\ntemplate=\"Answer the user query.\\\\n{format_instructions}\\\\n{query}\\\\n\",\\ninput_variables=[\"query\"],  # 입력 변수 설정\\npartial_variables={\\n\"format_instructions\": parser.get_format_instructions()\\n},  # 부분 변수 설정\\n)\\n# 체인 생성\\nchain = prompt | model | parser\\n# 체인 실행\\nparser_output = chain.invoke({\"query\": df_query})\\n# 출력\\nformat_parser_output(parser_output)\\n{\\'Age\\': {0: 22.0,\\n1: 38.0,\\n2: 26.0,\\n3: 35.0,\\n4: 35.0,\\n5: nan,\\n6: 54.0,\\n7: 2.0,\\n8: 27.0,\\n9: 14.0,\\n10: 4.0,\\n11: 58.0,\\n12: 20.0,\\n13: 39.0,\\n14: 14.0,\\n15: 55.0,\\n16: 2.0,\\n17: nan,\\n18: 31.0,\\n19: nan}}\\n첫 번째 행을 검색하는 예시입니다.\\n# 행 조회 예시입니다.\\ndf_query = \"Retrieve the first row.\"\\n# 체인 실행\\nparser_output = chain.invoke({\"query\": df_query})\\n# 결과 출력\\nformat_parser_output(parser_output)\\n{\\'0\\': {\\'Age\\': 22.0,\\n\\'Cabin\\': nan,\\n\\'Embarked\\': \\'S\\',\\n\\'Fare\\': 7.25,\\n\\'Name\\': \\'Braund, \\'\\n\\'Mr. \\'\\n\\'Owen \\'\\n\\'Harris\\',\\n\\'Parch\\': 0,\\n\\'PassengerId\\': 1,\\n\\'Pclass\\': 3,\\n\\'Sex\\': \\'male\\',\\n\\'SibSp\\': 1,\\n\\'Survived\\': 0,\\n\\'Ticket\\': \\'A/5 \\'\\n\\'21171\\'}}\\n특정 열에서 일부 행의 평균을 검색하는 작업 예제입니다.\\n# row 0 ~ 4의 평균 나이를 구합니다.\\ndf[\"Age\"].head().mean()\\n31.2\\n# 임의의 Pandas DataFrame 작업 예시, 행의 수를 제한합니다.\\ndf_query = \"Retrieve the average of the Ages from row 0 to 4.\"\\n# 체인 실행\\nparser_output = chain.invoke({\"query\": df_query})\\n# 결과 출력\\nprint(parser_output)\\n{\\'mean\\': 31.2}\\n다음은 요금(Fare) 에 대한 평균 가격을 산정하는 예시입니다.\\n# 잘못 형식화된 쿼리의 예시입니다.\\ndf_query = \"Calculate average `Fare` rate.\"\\n# 체인 실행\\nparser_output = chain.invoke({\"query\": df_query})\\n# 결과 출력\\nprint(parser_output)\\n{\\'mean\\': 22.19937}\\n# 결과 검증\\ndf[\"Fare\"].mean()\\n22.19937\\n\\n==================================================')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}).invoke('랭체인')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 메타데이터:\n",
      "  chapter_info: None\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: 01. 설치 영상보고 따라하기\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: 02. OpenAI API 키 발급 및 테스트\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: 03. LangSmith 추적 설정\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: 04. OpenAI API 사용(GPT-4o 멀티모달)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: 05. LangChain Expression Language(LCEL)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: 06. LCEL 인터페이스\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH01 LangChain 시작하기\n",
      "  section_info: 07. Runnable\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH02 프롬프트(Prompt)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH02 프롬프트(Prompt)\n",
      "  section_info: 01. 프롬프트(Prompt)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH02 프롬프트(Prompt)\n",
      "  section_info: 02. 퓨샷 프롬프트(FewShotPromptTemplate)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH02 프롬프트(Prompt)\n",
      "  section_info: 03. LangChain Hub\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH02 프롬프트(Prompt)\n",
      "  section_info: 04. 개인화된 프롬프트(Hub에 업로드)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 01. Pydantic 출력 파서(PydanticOutputParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 03. 구조화된 출력 파서(StructuredOuputParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 04. JSON 출력 파서(JsonOutputParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 06. 날짜 형식 출력 파서(DatetimeOutputParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 07. 열거형 출력 파서(EnumOutputParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH03 출력 파서(Output Parsers)\n",
      "  section_info: 08. 출력 수정 파서(OutputFixingParser)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 01. 다양한 LLM 모델 활용\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 02. 캐싱(Cache)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 03. 모델 직렬화(Serialization) - 저장 및 불러오기\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 04. 토큰 사용량 확인\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 05. 구글 생성 AI(Google Generative AI)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 06. 허깅페이스 엔드포인트(HuggingFace Endpoints)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 07. 허깅페이스 로컬(HuggingFace Local)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 08. 허깅페이스 파이프라인(HuggingFace Pipeline)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 09. 올라마(Ollama)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 10. GPT4ALL\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH04 모델(Model)\n",
      "  section_info: 11. 비디오(Video) 질의 응답 LLM (Gemini)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 01. 대화 버퍼 메모리(ConversationBufferMemory)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 04. 대화 엔티티 메모리(ConversationEntityMemory)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 05. 대화 지식그래프 메모리(ConversationKGMemory)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 06. 대화 요약 메모리(ConversationSummaryMemory)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 08. LCEL Chain 에 메모리 추가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 09. SQLite 에 대화내용 저장\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH05 메모리(Memory)\n",
      "  section_info: 10. RunnableWithMessageHistory에 ChatMessageHistory추가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 01. 도큐먼트(Document) 의 구조\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 02. PDF\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 03. 한글(HWP)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 04. CSV\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 05. Excel\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 06. Word\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 07. PowerPoint\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 08. 웹 문서(WebBaseLoader)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 09. 텍스트(TextLoader)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 10. JSON\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 11. Arxiv\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 12. UpstageLayoutAnalysisLoader\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH06 문서 로더(Document Loader)\n",
      "  section_info: 13. LlamaParser\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 01. 문자 텍스트 분할(CharacterTextSplitter)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 03. 토큰 텍스트 분할(TokenTextSplitter)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 04. 시멘틱 청커(SemanticChunker)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH07 텍스트 분할(Text Splitter)\n",
      "  section_info: 08. 재귀적 JSON 분할(RecursiveJsonSplitter)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: 01. OpenAIEmbeddings\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: 02. 캐시 임베딩(CacheBackedEmbeddings)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: 03. 허깅페이스 임베딩(HuggingFace Embeddings)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: 04. UpstageEmbeddings\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: 05. OllamaEmbeddings\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: 06. GPT4ALL 임베딩\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH08 임베딩(Embedding)\n",
      "  section_info: 07. Llama CPP 임베딩\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH09 벡터저장소(VectorStore)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH09 벡터저장소(VectorStore)\n",
      "  section_info: 01. Chroma\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH09 벡터저장소(VectorStore)\n",
      "  section_info: 02. FAISS\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH09 벡터저장소(VectorStore)\n",
      "  section_info: 03. Pinecone\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 02. 문맥 압축 검색기(ContextualCompressionRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 03. 앙상블 검색기(EnsembleRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 04. 긴 문맥 재정렬(LongContextReorder)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 05. 상위 문서 검색기(ParentDocumentRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 06. 다중 쿼리 검색기(MultiQueryRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 07. 다중 벡터저장소 검색기(MultiVectorRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 08. 셀프 쿼리 검색기(SelfQueryRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH10 검색기(Retriever)\n",
      "  section_info: 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH11 리랭커(Reranker)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH11 리랭커(Reranker)\n",
      "  section_info: 01. Cross Encoder Reranker\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH11 리랭커(Reranker)\n",
      "  section_info: 02. Cohere Reranker\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH11 리랭커(Reranker)\n",
      "  section_info: 03. Jina Reranker\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH11 리랭커(Reranker)\n",
      "  section_info: 04. FlashRank Reranker\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH12 Retrieval Augmented Generation(RAG)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH12 Retrieval Augmented Generation(RAG)\n",
      "  section_info: 01. PDF 문서 기반 QA(Question-Answer)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH12 Retrieval Augmented Generation(RAG)\n",
      "  section_info: 02. 네이버 뉴스기사 QA(Question-Answer)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH12 Retrieval Augmented Generation(RAG)\n",
      "  section_info: 03. RAG 의 기능별 다양한 모듈 활용기\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH12 Retrieval Augmented Generation(RAG)\n",
      "  section_info: 04. RAPTOR: 긴 문맥 요약(Long Context Summary)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH12 Retrieval Augmented Generation(RAG)\n",
      "  section_info: 05. 대화내용을 기억하는 RAG 체인\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 01. RunnablePassthrough\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 02. Runnable 구조(그래프) 검토\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 03. RunnableLambda\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 05. RunnableParallel\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 06. 동적 속성 지정(configurable_fields, configurable_alternatives)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 07. @chain 데코레이터로 Runnable 구성\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 08. RunnableWithMessageHistory\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 09. 사용자 정의 제네레이터(generator)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 10. Runtime Arguments 바인딩\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH13 LangChain Expression Language(LCEL)\n",
      "  section_info: 11. 폴백(fallback) 모델 지정\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH14 체인(Chains)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH14 체인(Chains)\n",
      "  section_info: 01. 문서 요약\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH14 체인(Chains)\n",
      "  section_info: 02. SQL\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH14 체인(Chains)\n",
      "  section_info: 03. 구조화된 출력 체인(with_structered_output)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 01. 합성 테스트 데이터셋 생성(RAGAS)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 02. RAGAS 를 활용한 평가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 04. LangSmith 데이터셋 생성\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 05. LLM-as-Judge\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 06. 임베딩 기반 평가(embedding_distance)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 07. 사용자 정의(Custom) LLM 평가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 09. 실험(Experiment) 평가 비교\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 10. 요약(Summary) 방식의 평가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 11. Groundedness(할루시네이션) 평가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 12. 실험 비교(Pairwise Evaluation)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 13. 반복 평가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH15 평가(Evaluations)\n",
      "  section_info: 14. 온라인 평가를 활용한 평가 자동화\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 01. 도구(Tools)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 02. 도구 바인딩(Binding Tools)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 03. 에이전트(Agent)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 05. Iteration 기능과 사람 개입(Human-in-the-loop)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 06. Agentic RAG\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 07. CSVExcel 데이터 분석 Agent\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 08. Toolkits 활용 Agent\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 09. RAG + Image Generator Agent(보고서 작성)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH16 에이전트(Agent)\n",
      "  section_info: 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 01. 핵심 기능\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 01. LangGraph 에 자주 등장하는 Python 문법이해\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 02. LangGraph를 활용한 챗봇 구축\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 03. LangGraph를 활용한 Agent 구축\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 04. Agent 에 메모리(memory) 추가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 05. 노드의 단계별 스트리밍 출력\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 06. Human-in-the-loop(사람의 개입)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 07. 중간단계 개입  되돌림을 통한 상태 수정과 Replay\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 08. 사람(Human)에게 물어보는 노드 추가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 09. 메시지 삭제(RemoveMessage)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 10. ToolNode 를 사용하여 도구를 호출하는 방법\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 11. 병렬 노드 실행을 위한 분기 생성 방법\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 12. 대화 기록 요약을 추가하는 방법\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 13. 서브그래프 추가 및 사용 방법\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 14. 서브그래프의 입력과 출력을 변환하는 방법\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 15. LangGraph 스트리밍 모드의 모든 것\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 02. 구조 설계\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 01. 기본 그래프 생성\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 02. Naive RAG\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 03. 관련성 체커(Relevance Checker) 모듈 추가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 04. 웹 검색 모듈 추가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 05. 쿼리 재작성 모듈 추가\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 06. Agentic RAG\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 07. Adaptive RAG\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 03. Use Cases\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 03. CRAG(Corrective RAG)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 04. Self-RAG\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 05. 계획 후 실행(Plan-and-Execute)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 07. 멀티 에이전트 감독자(Multi-Agent Supervisor)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams)\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 09. SQL 데이터베이스와 상호작용하는 에이전트\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH17 LangGraph\n",
      "  section_info: 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH18 기타 정보\n",
      "  section_info: None\n",
      "--------------------------------------------------\n",
      "문서 메타데이터:\n",
      "  chapter_info: CH18 기타 정보\n",
      "  section_info: 01. StreamEvent 타입별 정리\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(f\"문서 메타데이터:\")\n",
    "    for key, value in doc.metadata.items():\n",
    "        if key == 'level':\n",
    "            print(f\"  {'  ' * (int(value) - 1)}└─ {key}: {value}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "# def extract_code_blocks_from_documents(docs: List[Document]) -> List[str]:\n",
    "#     \"\"\"\n",
    "#     각 Document 객체 내의 <CODE_BLOCK>...</CODE_BLOCK> 구간만 추출하여 리스트로 반환\n",
    "#     \"\"\"\n",
    "#     code_blocks = []\n",
    "#     pattern = re.compile(r\"<CODE_BLOCK>\\s*```.*?\\n.*?```\\s*</CODE_BLOCK>\", re.DOTALL)\n",
    "\n",
    "#     for doc in docs:\n",
    "#         matches = pattern.findall(doc.page_content)\n",
    "#         code_blocks.extend(matches)\n",
    "\n",
    "#     return code_blocks\n",
    "\n",
    "# chunked_docs = split_protected_chunks(docs)\n",
    "\n",
    "# code_blocks = extract_code_blocks_from_documents(chunked_docs)\n",
    "\n",
    "# # 출력 확인\n",
    "# for i, code in enumerate(code_blocks[100:150]):\n",
    "#     print(f\"🔹 Code Block {i + 1}:\\n{code}\\n{'-'*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 답변:\n",
      " LangGraph는 LangChain의 구성 요소 중 하나로, 주로 챗봇이나 에이전트를 구축하는 데 사용됩니다. LangGraph는 다양한 언어 모델과 데이터 소스를 연결하여 복잡한 대화 흐름을 관리하고, 사용자와의 상호작용을 보다 자연스럽고 효율적으로 만들어 줍니다. 이를 통해 개발자는 다양한 기능을 가진 챗봇을 쉽게 구축할 수 있으며, LangChain의 다른 도구들과 통합하여 더욱 강력한 애플리케이션을 개발할 수 있습니다. LangGraph는 특히 대화의 맥락을 이해하고, 적절한 응답을 생성하는 데 중점을 두고 설계되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 1. 로컬 LLM (gemma:3.12b)\n",
    "# llm = Ollama(model=\"gemma3:12b\")\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# 4. 메타데이터 필드 정의 (사용 필드만)\n",
    "metadata_field_info = [\n",
    "    {\"name\": \"chapter_info\", \"type\": \"string\"},\n",
    "    {\"name\": \"section_info\", \"type\": \"string\"},\n",
    "]\n",
    "\n",
    "# 5. ParentDocumentRetriever 구성\n",
    "retriever = test_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "# 6. QA Chain\n",
    "prompt = PromptTemplate.from_template(\n",
    "    '''\n",
    "        당신은 랭체인과 관련된 질문에 대해 답변하는 전문가입니다.\n",
    "        랭체인과 관련된 질문이 아니라면, \"랭체인과 관련된 질문이 아닙니다\"라고 답변해주세요.\n",
    "        답변은 한국어로 답변해주세요.\n",
    "\n",
    "        question : \n",
    "        {question}\n",
    "\n",
    "        context :\n",
    "        {context}\n",
    "\n",
    "        answer : \n",
    "    '''\n",
    ")\n",
    "\n",
    "# LCEL 방식으로 체인 구성\n",
    "qa_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 7. 질문 실행\n",
    "question = \"LangGraph에 대해 설명해\"\n",
    "result = qa_chain.invoke(question)\n",
    "\n",
    "# 8. 출력\n",
    "print(\"🧠 답변:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParentDocumentRetriever 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv(r'C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    # 파일을 로드합니다.\n",
    "    TextLoader(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\txt\\wikidocs_01.txt\"),\n",
    "    TextLoader(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\txt\\wikidocs_02.txt\"),\n",
    "    TextLoader(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\txt\\wikidocs_03.txt\"),\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    # 로더를 사용하여 문서를 로드하고 docs 리스트에 추가합니다.\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 자식 분할기를 생성합니다.\n",
    "# child_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "\n",
    "# # 임베딩 모델 설정\n",
    "# # embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# # DB를 생성합니다.\n",
    "# vectorstore = Chroma(\n",
    "#     collection_name=\"test\", \n",
    "#     embedding_function=embeddings, \n",
    "#     # persist_directory = r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\test\"\n",
    "# )\n",
    "\n",
    "# store = InMemoryStore()\n",
    "\n",
    "# # Retriever 를 생성합니다.\n",
    "# retriever = ParentDocumentRetriever(\n",
    "#     vectorstore=vectorstore,\n",
    "#     docstore=store,\n",
    "#     child_splitter=child_splitter,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 문서를 검색기에 추가합니다. docs는 문서 목록이고, ids는 문서의 고유 식별자 목록입니다.\n",
    "# retriever.add_documents(docs, ids=None, add_to_docstore=True)\n",
    "\n",
    "# # 유사도 검색을 수행합니다.\n",
    "# sub_docs = vectorstore.similarity_search(\"Langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1184519c-d2c9-462f-ba18-df1113dd490f', metadata={'doc_id': 'de864918-a334-4bae-bb3b-ce948fde3499', 'source': 'C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_01.txt'}, page_content='==================================================\\n\\n\\n--- 03. LangChain Hub ---'),\n",
       " Document(id='ee3ed590-ed81-4822-b0b1-18136e76cced', metadata={'doc_id': 'de864918-a334-4bae-bb3b-ce948fde3499', 'source': 'C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_01.txt'}, page_content='Overall, the LangChain documentation provides a comprehensive guide to using the LangChain framework and LCEL for building and executing complex chains of operations involving language models and other components. It covers both basic and advanced use cases, offering practical examples and encouraging community involvement.The provided documents from LangChain cover a range of topics related to the LangChain Expression Language (LCEL) and its applications, including interface design, streaming,'),\n",
       " Document(id='868c3b2e-de19-42b8-845a-9d9f05cab10c', metadata={'doc_id': 'de864918-a334-4bae-bb3b-ce948fde3499', 'source': 'C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_01.txt'}, page_content='1. **Introduction to LangChain and LCEL**: LangChain offers a way to build complex chains from basic components, supporting functionalities like streaming, parallelism, and logging. LCEL (LangChain Expression Language) simplifies the process of chaining together prompts, models, and output parsers to perform tasks like generating jokes based on a given topic or conducting retrieval-augmented generation.'),\n",
       " Document(id='0b297c9c-faad-4fd6-bce7-0d43ac85c358', metadata={'doc_id': 'de864918-a334-4bae-bb3b-ce948fde3499', 'source': 'C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\Presentation-Agent\\\\data\\\\txt\\\\wikidocs_01.txt'}, page_content='-\\\\n구경하러 가기!\\\\n② LangChain 한국어 튜토리얼\\\\n바로가기 👀\\\\n③ 랭체인 노트 무료 전자책(wikidocs)\\\\n바로가기 🙌\\\\n④ RAG 비법노트 LangChain 강의오픈\\\\n바로가기 🙌\\\\n⑤ 서울대 PyTorch 딥러닝 강의\\\\n바로가기 🙌\\\\nLangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\\\n2024년 01월 29일\\\\n26 분 소요Retrieval...\\\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\\\n2024년 02월 09일\\\\n41 분 소요\\\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "\n",
      "--- 03. LangChain Hub ---\n"
     ]
    }
   ],
   "source": [
    "# print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 길이: 1800480\n",
      "\n",
      "=====================\n",
      "\n",
      "는 모듈식으로 설계되어, 사용하기 쉽습니다. 이는 개발자가 LangChain 프레임워크를 자유롭게 활용할 수 있게 해줍니다.\n",
      "즉시 사용 가능한 체인 🚀\n",
      "고수준 작업을 수행하기 위한 컴포넌트의 내장 조합을 제공합니다.\n",
      "이러한 체인은 개발 과정을 간소화하고 속도를 높여줍니다.\n",
      "주요 모듈 📌\n",
      "모델 I/O 📃\n",
      "프롬프트 관리, 최적화 및 LLM과의 일반적인 인터페이스와 작업을 위한 유틸리티를 포함합니다.\n",
      "검색 📚\n",
      "'데이터 강화 생성'에 초점을 맞춘 이 모듈은 생성 단계에서 필요한 데이터를 외부 데이터 소스에서 가져오는 작업을 담당합니다.\n",
      "에이전트 🤖\n",
      "언어 모델이 어떤 조치를 취할지 결정하고, 해당 조치를 실행하며, 관찰하고, 필요한 경우 반복하는 과정을 포함합니다.\n",
      "LangChain을 활용하면, 언어 모델 기반 애플리케이션의 개발을 보다 쉽게 시작할 수 있으며, 필요에 맞게 기능을 맞춤 설정하고, 다양한 데이터 소스와 통합하여 복잡한 작업을 처리할 수 있게 됩니다.\n",
      "\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# retrieved_docs = retriever.invoke(\"LangChain\")\n",
    "\n",
    "# # 검색된 문서의 문서의 페이지 내용의 길이를 출력합니다.\n",
    "# print(\n",
    "#     f\"문서의 길이: {len(retrieved_docs[0].page_content)}\",\n",
    "#     end=\"\\n\\n=====================\\n\\n\",\n",
    "# )\n",
    "\n",
    "# # 문서의 일부를 출력합니다.\n",
    "# print(retrieved_docs[0].page_content[2000:2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 250, separators=['==================================================', '---.*?---', '===.*?==='])\n",
    "# 자식 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap = 100)\n",
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소입니다.\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"split_knowledge\", \n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory = r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\split_knowledge\"\n",
    ")\n",
    "# 부모 문서의 저장 계층입니다.\n",
    "parent_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    # 벡터 저장소를 지정합니다.\n",
    "    vectorstore=vectorstore,\n",
    "    # 문서 저장소를 지정합니다.\n",
    "    docstore=parent_store,\n",
    "    # 하위 문서 분할기를 지정합니다.\n",
    "    child_splitter=child_splitter,\n",
    "    # 상위 문서 분할기를 지정합니다.\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "\n",
      "--- 03. LangChain Hub ---\n"
     ]
    }
   ],
   "source": [
    "retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 딥 러닝을 이용한 자연어 처리 입문 ===\n",
      "\n",
      "\n",
      "--- 딥 러닝을 이용한 자연어 처리 입문 ---\n"
     ]
    }
   ],
   "source": [
    "# # 유사도 검색을 수행합니다.\n",
    "# sub_docs = vectorstore.similarity_search(\"딥러닝\")\n",
    "\n",
    "# # sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\n",
    "# print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 딥 러닝을 이용한 자연어 처리 입문 ===\n",
      "\n",
      "\n",
      "--- 딥 러닝을 이용한 자연어 처리 입문 ---\n",
      "\n",
      "25년 1월 기준: 누적 조회수: 1,700만 베스트셀러\n",
      "많은 분들의 피드백으로 수 년간 보완된 현업 연구원들이 작성한 딥 러닝 자연어 처리 교재 입문서입니다.\n",
      "Q) 입문자도 공부 가능한가요?\n",
      "A) 이 책은 애초 AI를 아예 처음 공부하는 입문자가 타겟입니다. 파이썬을 어느 정도 할 줄 아신다면 AI 공부를 할 수 있습니다.\n",
      "유료 E-book/전체 PDF 파일 (https://wikidocs.net/buy/ebook/2155)\n",
      "A) 거의 90% 이상의 내용을 현재 무료로 공개했습니다. 그러니 무료로 편하게 입문하시기 바랍니다.\n",
      "단, 파인 튜닝 등 일부심화 내용은 유료 E-book/전체 PDF 파일에서만 볼 수 있습니다.\n",
      "온라인 강의 (https://bit.ly/4fWkdRa)온라인 강의는 없나요?\n",
      "A) LLM 파인 튜닝을 다루는 입문용 온라인 강의가 존재합니다.\n",
      "🎉할인 쿠폰 코드 입력: '파인튜닝' (할인율 : 20%)\n",
      "오프라인 강의 (https://learningspoons.com/course/detail/llm-master/)오프라인 강의는 없나요?\n",
      "A) 강남에서 매주 현장에서 질답을 받으며 진행되는 LLM 파인 튜닝을 다루는 입문용 오프라인 강의가 존재합니다.\n",
      "존재 (https://wikidocs.net/book/2788)파이토치 버전은 없나요?\n",
      "A) 존재합니다. 목차는 거의 동일하므로 선호하는 책으로 구매하세요.\n",
      "Q) 입문자들이 쉽게 질문하고 소통할 수 있는 공간은 없나요?\n",
      "A) 자연어 처리 입문자들을 위한 오픈 카톡방: https://open.kakao.com/o/gciNJmPg\n",
      "댓글 또는 피드백(질문/지적) 또는 이메일 환영합니다.\n",
      "각 내용에 대한 페이지마다 댓글 버튼 옆을 보면 피드백 버튼이 있습니다.\n",
      "위키독스 회원가입이 번거로우시다면 피드백 버튼으로 의견주셔도 댓글로 답변드립니다.\n",
      "감사합니다.\n"
     ]
    }
   ],
   "source": [
    "# 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(\"딥러닝\")\n",
    "\n",
    "# 검색된 문서의 첫 번째 문서의 페이지 내용의 길이를 반환합니다.\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in retrieved_docs[:5] :\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❓ 질문: 이 프로젝트의 시스템 구조는 어떻게 되나요?\n",
      "💬 답변: 이 프로젝트의 시스템 구조는 크게 데이터 수집, 모델 학습 및 평가, 성능 개선, 그리고 서비스 구현으로 나눌 수 있습니다. 데이터 수집 단계에서는 아동 그림 데이터를 YOLO 모델로 정리하고, 모델 학습 단계에서는 YOLO11n 모델을 통해 그림 요소를 탐지합니다. 이후 성능 개선을 위해 이미지 해상도를 조정하고 학습 속도를 최적화합니다. 마지막으로, 학습된 모델을 서비스에 적용하여 HTP 검사 결과를 자동으로 분석하고 해석하는 기능을 구현합니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: 프로젝트를 좀 더 고도화한다면 어떤 방안을 생각해보셨나요?\n",
      "💬 답변: 프로젝트를 고도화하기 위해, 다음과 같은 방안을 고려할 수 있습니다. 첫째, 다양한 아동 미술 데이터를 추가로 수집하여 모델의 일반화 능력을 향상시킬 수 있습니다. 둘째, 심리 진단의 정확성을 높이기 위해 다중 모달 학습을 도입하여 텍스트와 이미지 데이터를 통합 분석할 수 있습니다. 셋째, 사용자 피드백을 반영한 지속적인 모델 업데이트 및 성능 모니터링 시스템을 구축하여 실시간으로 개선할 수 있습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: 프로젝트의 향후 발전 방향으로 Langchain을 활용하여 RAG 시스템을 고도화하는게 좋아보이는데 거기까지 고려해보셨을까요?\n",
      "💬 답변: 네, Langchain을 활용하여 RAG 시스템을 고도화하는 방향은 매우 유망합니다. 이를 통해 데이터 처리 및 응답 생성의 효율성을 높일 수 있습니다. 현재 시스템의 한계를 보완하고, 더 나은 사용자 경험을 제공하기 위해 Langchain의 도입을 고려할 수 있습니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# # from langchain.llms import Ollama  # 로컬 LLM 쓸 경우 사용\n",
    "\n",
    "# # LLM 초기화\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# # llm = Ollama(model=\"gemma3:12b\")  # 로컬 모델 쓸 경우\n",
    "\n",
    "# # 시스템 프롬프트 불러오기\n",
    "# with open(\"C:/Users/user/Documents/GitHub/Presentation-Agent/data/txt/DeePrint.txt\", encoding=\"utf-8\") as f:\n",
    "#     pt_context = f.read()\n",
    "\n",
    "# # 템플릿 정의\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", f\"당신은 발표자료에 대한 내용을 질문받으면 그에 대한 답을 하는 AI 에이전트입니다.\\n다음은 발표자료에 대한 배경 정보입니다:\\n\\n{pt_context}\\n 답변은 간결하게 100토큰 이내로 답변해주세요.\"),\n",
    "#     (\"human\", \"질문: {question}\\n\\n문서:\\n{documents}\")\n",
    "# ])\n",
    "\n",
    "# # LCEL 체인 구성\n",
    "# rag_chain = (\n",
    "#     {\n",
    "#         \"question\": RunnablePassthrough(),\n",
    "#         \"documents\": retriever\n",
    "#     }\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "\n",
    "# # 질문 목록\n",
    "# questions = [\n",
    "#     \"이 프로젝트의 시스템 구조는 어떻게 되나요?\",\n",
    "#     \"프로젝트를 좀 더 고도화한다면 어떤 방안을 생각해보셨나요?\",\n",
    "#     \"프로젝트의 향후 발전 방향으로 Langchain을 활용하여 RAG 시스템을 고도화하는게 좋아보이는데 거기까지 고려해보셨을까요?\"\n",
    "# ]\n",
    "\n",
    "# # 질문에 대한 응답 생성\n",
    "# for q in questions:\n",
    "#     try:\n",
    "#         response = rag_chain.invoke(q)\n",
    "#         print(f\"\\n❓ 질문: {q}\\n💬 답변: {response}\\n\" + \"-\"*50)\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n❌ 오류 발생: {e}\\n\" + \"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❓ 질문: 이 프로젝트의 시스템 구조는 어떻게 되나요?\n",
      "💬 답변: 프로젝트의 시스템 구조는 사용자가 발표 자료를 업로드하면, AI가 내용을 분석하여 발표 대본을 생성하고, 음성으로 발표까지 진행하는 방식입니다. VectorDB에 문서를 저장하고, LLM이 이를 분석하여 발표 내용을 구성합니다. FastAPI를 통해 API 서비스를 제공하고, Streamlit을 활용하여 사용자 인터페이스를 구축합니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: 프로젝트를 좀 더 고도화한다면 어떤 방안을 생각해보셨나요?\n",
      "💬 답변: 프로젝트를 고도화하기 위한 방안으로는 실시간 상호작용 기능 추가, 사용자 맞춤 발표 스타일 적용, 디지털 아바타 활용, 그리고 다양한 도메인으로의 확장이 있습니다. 이를 통해 발표 경험을 더욱 자연스럽고 개인화된 방식으로 개선할 수 있습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: LangChain 기반으로 RAG 시스템을 고도화하는 것도 고려했나요?\n",
      "💬 답변: LangChain 기반으로 RAG 시스템을 고도화하는 방안은 고려하지 않았습니다. 현재 프로젝트에서는 RAG와 에이전트를 독립적으로 구현하여 운용하고 있으며, LangChain의 사용은 필수가 아닙니다. 대신, LLM의 동작 원리와 RAG의 원리를 이해하는 것이 더 중요하다고 판단하고 있습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: 제가 처음으로 물어본 질문이 뭐였나요?\n",
      "💬 답변: 이전 대화에서 사용자는 프로젝트의 시스템 구조와 고도화 방안에 대해 질문하였고, AI는 시스템 구조를 설명하고 고도화 방안으로 실시간 상호작용, 맞춤 발표 스타일, 디지털 아바타 활용 등을 언급했습니다. 또한, LangChain 기반 RAG 시스템 고도화에 대한 질문에 AI는 현재 프로젝트에서 LangChain 사용이 필수가 아니며, LLM과 RAG의 원리를 이해하는 것이 더 중요하다고 답변했습니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ✅ LLM 설정 (ChatOpenAI 또는 Ollama 사용 가능)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# from langchain.llms import Ollama\n",
    "# llm = Ollama(model=\"gemma3:12b\")\n",
    "\n",
    "# ✅ 시스템 프롬프트 로드\n",
    "with open(\"C:/Users/user/Documents/GitHub/Presentation-Agent/data/txt/pt_context.txt\", encoding=\"utf-8\") as f:\n",
    "    pt_context = f.read()\n",
    "\n",
    "# ✅ 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"당신은 발표자료에 대한 내용을 질문받으면 그에 대한 답을 하는 AI 에이전트입니다.\\n\"\n",
    "               f\"다음은 발표자료에 대한 배경 정보입니다:\\n\\n{pt_context}\\n\\n\"\n",
    "               f\"답변은 간결하게 100토큰 이내로 작성해주세요.\\n\"\n",
    "               f\"사용자가 처음 물어봐서 이전 대화 내용이 없어도 질문에 대한 대답을 하세요. \\n\"\n",
    "               f\"사용자가 이전 대화 내용에 대해 물어보면, 대화 기록을 확인하여 정확히 답변해주세요.\"), \n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"human\", \"문서:\\n{documents}\"),\n",
    "    (\"human\", \"이전 대화 내용:\\n{chat_history}\")\n",
    "])\n",
    "\n",
    "# ✅ 대화 이력 저장용 함수 및 저장소\n",
    "chat_histories = {}\n",
    "\n",
    "def get_message_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_histories:\n",
    "        chat_histories[session_id] = ChatMessageHistory()\n",
    "    return chat_histories[session_id]\n",
    "\n",
    "# ✅ 이전 대화 내용을 문자열로 변환하는 함수\n",
    "def format_chat_history(chat_history):\n",
    "    formatted_history = []\n",
    "    for message in chat_history:\n",
    "        if hasattr(message, 'content') and hasattr(message, 'type'):\n",
    "            formatted_history.append(f\"{message.type}: {message.content}\")\n",
    "    return \"\\n\".join(formatted_history)\n",
    "\n",
    "# ✅ RAG LCEL 체인 구성\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"documents\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"chat_history\": lambda x: format_chat_history(x.get(\"chat_history\", []))\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ✅ RAG + 메모리 연결된 체인 구성\n",
    "chat_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history=get_message_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# ✅ 질의 테스트\n",
    "questions = [\n",
    "    \"이 프로젝트의 시스템 구조는 어떻게 되나요?\",\n",
    "    \"프로젝트를 좀 더 고도화한다면 어떤 방안을 생각해보셨나요?\",\n",
    "    \"LangChain 기반으로 RAG 시스템을 고도화하는 것도 고려했나요?\",\n",
    "    \"제가 처음으로 물어본 질문이 뭐였나요?\"\n",
    "]\n",
    "\n",
    "session_id = \"user-session-1\"\n",
    "for i, q in enumerate(questions):\n",
    "    try:\n",
    "        response = chat_chain.invoke(\n",
    "            {\"question\": q},\n",
    "            config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "        print(f\"\\n❓ 질문: {q}\\n💬 답변: {response}\\n\" + \"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류 발생: {e}\\n\" + \"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❓ 질문: 이 프로젝트의 시스템 구조는 어떻게 되나요?\n",
      "💬 답변: 프로젝트의 시스템 구조는 사용자가 발표 자료를 업로드하면, AI가 내용을 분석하여 발표 대본을 생성하고 음성으로 발표까지 진행하는 방식입니다. 문서는 VectorDB에 저장되고, LLM이 이를 분석하여 발표 내용을 구성합니다. FastAPI를 통해 API 서비스를 제공하고, Streamlit을 활용하여 사용자 인터페이스(UI)를 구축합니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: 프로젝트를 좀 더 고도화한다면 어떤 방안을 생각해보셨나요?\n",
      "💬 답변: 프로젝트를 고도화하기 위한 방안으로는 실시간 상호작용 기능 추가, 인간처럼 자연스럽게 말하는 음성 합성, 사용자별 맞춤 발표 스타일 적용, 디지털 아바타를 활용한 발표 기능, 그리고 도메인 확장이 있습니다. 이러한 개선을 통해 더욱 자연스러운 발표 경험을 제공하고 다양한 환경에서 활용할 수 있도록 할 계획입니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: LangChain 기반으로 RAG 시스템을 고도화하는 것도 고려했나요?\n",
      "💬 답변: 네, LangChain 기반으로 RAG 시스템을 고도화하는 것도 고려하고 있습니다. 이를 통해 문서 검색 및 분석의 효율성을 높이고, 사용자에게 더욱 정확하고 관련성 높은 발표 대본을 제공할 수 있을 것입니다. RAG 시스템의 개선은 발표의 품질을 향상시키는 데 중요한 역할을 할 것입니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "❓ 질문: 제가 이 대화에서 처음으로 물어본 질문이 뭐였나요?\n",
      "💬 답변: 이전 대화 내용에서 사용자가 처음으로 물어본 질문은 \"이 프로젝트의 시스템 구조는 어떻게 되나요?\"입니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "# API 키 정보 로드\n",
    "load_dotenv(r'C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\.env')\n",
    "\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "# loaders = [\n",
    "#     # 파일을 로드합니다.\n",
    "#     TextLoader(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\txt\\wikidocs_01.txt\"),\n",
    "#     TextLoader(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\txt\\wikidocs_02.txt\"),\n",
    "#     TextLoader(r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\txt\\wikidocs_03.txt\"),\n",
    "# ]\n",
    "\n",
    "# docs = []\n",
    "# for loader in loaders:\n",
    "#     # 로더를 사용하여 문서를 로드하고 docs 리스트에 추가합니다.\n",
    "#     docs.extend(loader.load())\n",
    "\n",
    "# 부모 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 250, separators=['==================================================', '---.*?---', '===.*?==='])\n",
    "# 자식 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap = 100)\n",
    "\n",
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소입니다.\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"split_knowledge\", \n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory = r\"C:\\Users\\user\\Documents\\GitHub\\Presentation-Agent\\data\\db\\chromadb\\split_knowledge\"\n",
    ")\n",
    "\n",
    "# retriever.add_documents(docs)\n",
    "\n",
    "# 부모 문서의 저장 계층입니다.\n",
    "parent_store = InMemoryStore()\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    # 벡터 저장소를 지정합니다.\n",
    "    vectorstore=vectorstore,\n",
    "    # 문서 저장소를 지정합니다.\n",
    "    docstore=parent_store,\n",
    "    # 하위 문서 분할기를 지정합니다.\n",
    "    child_splitter=child_splitter,\n",
    "    # 상위 문서 분할기를 지정합니다.\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ✅ LLM 설정 (ChatOpenAI 또는 Ollama 사용 가능)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# from langchain.llms import Ollama\n",
    "# llm = Ollama(model=\"gemma3:12b\")\n",
    "\n",
    "# ✅ 시스템 프롬프트 로드\n",
    "with open(\"C:/Users/user/Documents/GitHub/Presentation-Agent/data/txt/pt_context.txt\", encoding=\"utf-8\") as f:\n",
    "    pt_context = f.read()\n",
    "\n",
    "# ✅ 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"당신은 발표자료에 대한 내용을 질문받으면 그에 대한 답을 하는 AI 에이전트입니다.\\n\"\n",
    "               f\"다음은 발표자료에 대한 배경 정보입니다:\\n\\n{pt_context}\\n\\n\"\n",
    "               f\"답변은 간결하게 100토큰 이내로 작성해주세요.\\n\"\n",
    "               f\"사용자가 처음 물어봐서 이전 대화 내용이 없어도 질문에 대한 대답을 하세요. \\n\"\n",
    "               f\"사용자가 이전 대화 내용에 대해 물어보면, 대화 기록을 확인하여 정확히 답변해주세요.\"), \n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"human\", \"문서:\\n{documents}\"),\n",
    "    (\"human\", \"이전 대화 내용:\\n{chat_history}\")\n",
    "])\n",
    "\n",
    "# ✅ 대화 이력 저장용 함수 및 저장소\n",
    "chat_histories = {}\n",
    "\n",
    "def get_message_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_histories:\n",
    "        chat_histories[session_id] = ChatMessageHistory()\n",
    "    return chat_histories[session_id]\n",
    "\n",
    "# ✅ 이전 대화 내용을 문자열로 변환하는 함수\n",
    "def format_chat_history(chat_history):\n",
    "    formatted_history = []\n",
    "    for message in chat_history:\n",
    "        if hasattr(message, 'content') and hasattr(message, 'type'):\n",
    "            formatted_history.append(f\"{message.type}: {message.content}\")\n",
    "    return \"\\n\".join(formatted_history)\n",
    "\n",
    "# ✅ RAG LCEL 체인 구성\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"documents\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"chat_history\": lambda x: format_chat_history(x.get(\"chat_history\", []))\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ✅ RAG + 메모리 연결된 체인 구성\n",
    "chat_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history=get_message_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# ✅ 질의 테스트\n",
    "questions = [\n",
    "    \"이 프로젝트의 시스템 구조는 어떻게 되나요?\",\n",
    "    \"프로젝트를 좀 더 고도화한다면 어떤 방안을 생각해보셨나요?\",\n",
    "    \"LangChain 기반으로 RAG 시스템을 고도화하는 것도 고려했나요?\",\n",
    "    \"제가 이 대화에서 처음으로 물어본 질문이 뭐였나요?\"\n",
    "]\n",
    "\n",
    "session_id = \"user-session-1\"\n",
    "for i, q in enumerate(questions):\n",
    "    try:\n",
    "        response = chat_chain.invoke(\n",
    "            {\"question\": q},\n",
    "            config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "        print(f\"\\n❓ 질문: {q}\\n💬 답변: {response}\\n\" + \"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류 발생: {e}\\n\" + \"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain.chains import create_retrieval_chain\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.llms import Ollama\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "# 다음 문서를 기반으로 질문에 답변해주세요.\n",
    "# 문서에 관련 정보가 없다면, \"제공된 문서에서 해당 정보를 찾을 수 없습니다\"라고 답변하세요.\n",
    "\n",
    "# 문서:\n",
    "# {context}\n",
    "\n",
    "# 질문:\n",
    "# {input}\n",
    "# \"\"\")\n",
    "\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, max_tokens=1000)\n",
    "# # llm = Ollama(model=\"gemma3:12b\", temperature = 0)\n",
    "\n",
    "# # document_variable_name을 제거해야 오류 없음\n",
    "# document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "\n",
    "# chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# response = chain.invoke({\"input\": \"이 프로젝트를 듣고 난 후에 생길 수 있는 예상 질문을 10개 만들고 그 질문에 대한 답변을 만들어\"})\n",
    "# print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
