{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 형식 예시\n",
    "pdf_data = [\n",
    "    {\n",
    "        \"page\": int,              # 페이지 번호 (1부터 시작)\n",
    "        \"text\": str,              # 페이지에서 추출된 전체 텍스트\n",
    "        \"images\": [               # 해당 페이지에서 추출된 모든 이미지 정보 리스트\n",
    "            {\n",
    "                \"x0\": float,      # 이미지 좌측 상단 x좌표\n",
    "                \"y0\": float,      # 이미지 좌측 상단 y좌표\n",
    "                \"x1\": float,      # 이미지 우측 하단 x좌표\n",
    "                \"y1\": float,      # 이미지 우측 하단 y좌표\n",
    "                \"image\": PIL.Image.Image,   # 이미지 객체 (Pillow)\n",
    "                \"image_type\": str           # GPT-4o가 분류한 타입 (\"그래프/도표\", \"로고\", \"그외\")\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 발표 대본 생성 시스템에서 상태를 관리하는 데이터 구조\n",
    "class ScriptGenState(TypedDict):\n",
    "    '''발표 대본 생성 시스템에서 상태를 관리하는 데이터 구조'''\n",
    "    input_text: str  # PPT에서 추출된 텍스트 (현재 페이지 내용)\n",
    "    input_document = str # PPT에 관한 전체 문서서\n",
    "    previous_script: Annotated[List[str], add_messages]  # 이전 페이지의 발표 대본을 저장하여 문맥을 유지\n",
    "    reasoning: str  # 발표 대본을 생성하는 과정에서 모델이 고려한 사항 (예: 요약, 강조할 부분 등)\n",
    "    documents: List[Document]  # PPT에서 추출된 추가 정보 (OCR된 이미지 텍스트, 표, 캡션 등)\n",
    "    generated_script: str  # 최종 생성된 발표 대본 (현재 페이지에 대한 발표 내용)\n",
    "    mode: str  # 시스템의 동작 모드 (예: \"text_only\", \"image_included\", \"structured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Optional\n",
    "\n",
    "def image_area_ratio_exceeds_threshold(image_size: tuple, page_size: tuple, threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    이미지 크기와 페이지 크기를 비교하여 특정 임계치를 초과하는지 확인하는 메서드\n",
    "    :param image_size: (width, height) 형태의 이미지 크기\n",
    "    :param page_size: (width, height) 형태의 페이지 크기\n",
    "    :param threshold: 임계값 (기본값 0.5)\n",
    "    :return: 이미지 영역 비율이 임계값을 초과하면 True, 아니면 False\n",
    "    \"\"\"\n",
    "    image_area = image_size[0] * image_size[1]\n",
    "    page_area = page_size[0] * page_size[1]\n",
    "    \n",
    "    if page_area == 0:\n",
    "        print('페이지 오류')\n",
    "    \n",
    "    image_ratio = image_area / page_area\n",
    "    return image_ratio >= threshold\n",
    "\n",
    "def analyze_image_content(image_path: str, input_document: str, previous_script: list, use_ocr: bool = False):\n",
    "    \"\"\"\n",
    "    GPT-4V를 사용하여 이미지 내용을 해석하는 메서드.\n",
    "    \n",
    "    :param image_path: 해석할 이미지 파일 경로\n",
    "    :param input_document: PPT 관련 전체 문서 (문맥 제공)\n",
    "    :param previous_script: 이전 페이지의 발표 대본 (연속성 고려)\n",
    "    :param use_ocr: OCR 결과를 함께 보낼지 여부 (기본값 False)\n",
    "    :return: GPT-4V의 이미지 분석 결과\n",
    "    \"\"\"\n",
    "    # 이미지 base64 인코딩\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "\n",
    "    # 선택적으로 OCR 수행\n",
    "    ocr_text = extract_text_from_image(image_path) if use_ocr else None\n",
    "\n",
    "    # GPT-4V 프롬프트 구성\n",
    "    prompt = f\"\"\"\n",
    "    다음은 발표 자료에 대한 정보입니다:\n",
    "    - PPT 관련 문서: {input_document}\n",
    "    - 이전 발표 대본: {previous_script}\n",
    "    \n",
    "    아래 이미지를 분석하고, 발표자가 설명해야 할 내용을 정리해 주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    if use_ocr and ocr_text:\n",
    "        prompt += f\"\\n추출된 이미지 내 텍스트:\\n{ocr_text}\"\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 발표 자료에서 이미지를 분석하여 발표자가 쉽게 설명할 수 있도록 돕는 AI입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt, \"image\": base64_image}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "    except openai.error.OpenAIError as e:\n",
    "        return f\"OpenAI API 호출 오류: {str(e)}\"\n",
    "\n",
    "def generate_presentation_script(input_text: str, input_document: str, previous_script: List[str], use_image: bool):\n",
    "    \"\"\"\n",
    "    GPT-4를 사용하여 페이지별 발표 대본을 생성하는 메서드\n",
    "    :param input_text: 현재 페이지에서 추출한 텍스트\n",
    "    :param input_document: PPT에 관한 전체 문서\n",
    "    :param previous_script: 이전 페이지의 발표 대본\n",
    "    :param use_image: 이미지 사용 여부\n",
    "    :return: 생성된 발표 대본 문자열\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    다음은 발표 자료에 대한 정보입니다:\n",
    "    - 현재 페이지 텍스트: {input_text}\n",
    "    - 전체 문서 정보: {input_document}\n",
    "    - 이전 발표 대본: {previous_script}\n",
    "    - 이미지 사용 여부: {'Yes' if use_image else 'No'}\n",
    "    \n",
    "    위 정보를 바탕으로 발표자가 자연스럽게 발표할 수 있도록 대본을 작성해주세요.\n",
    "    발표 대본은 논리적인 흐름을 유지하고, 강조해야 할 핵심 내용을 포함해야 합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"당신은 발표 대본을 작성하는 AI입니다.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_images(pdf_data):\n",
    "    \"\"\"\n",
    "    이미지 타입에 따라 사용할 이미지를 필터링하는 함수\n",
    "    Args:\n",
    "        pdf_data (list): PDF에서 추출한 페이지별 데이터\n",
    "        \n",
    "    Returns:\n",
    "        list: 필터링된 이미지 정보가 포함된 페이지별 데이터\n",
    "    \"\"\"\n",
    "    filtered_data = []\n",
    "    \n",
    "    for page in pdf_data:\n",
    "        filtered_images = []\n",
    "        for img in page[\"images\"]:\n",
    "            # 그래프/도표만 사용하고 로고와 기타 이미지는 제외\n",
    "            if img[\"image_type\"] == \"그래프/도표\":\n",
    "                filtered_images.append(img)\n",
    "                \n",
    "        filtered_page = {\n",
    "            \"page\": page[\"page\"],\n",
    "            \"text\": page[\"text\"],\n",
    "            \"images\": filtered_images\n",
    "        }\n",
    "        filtered_data.append(filtered_page)\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def generate_script(full_ppt_data, page_text, images, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    PPT 페이지의 텍스트와 이미지 정보를 바탕으로 발표 대본을 생성하는 함수\n",
    "    \n",
    "    Args:\n",
    "        full_ppt_data (list): 전체 PPT 데이터\n",
    "        page_text (str): 현재 페이지의 텍스트\n",
    "        images (list): 현재 페이지의 이미지 정보 리스트\n",
    "        model (str): 사용할 LLM 모델명, 기본값은 mistral:7b\n",
    "        \n",
    "    Returns:\n",
    "        str: 생성된 발표 대본\n",
    "    \"\"\"\n",
    "    \n",
    "    # Chatollama 인스턴스 생성\n",
    "    llm = ChatOpenAI(model=model, temperature=0.5)\n",
    "    \n",
    "    # 이미지 설명 텍스트 생성\n",
    "    image_descriptions = []\n",
    "    for img in images:\n",
    "        if img[\"image_type\"] == \"그래프/도표\":\n",
    "            desc = f\"페이지에 {img['x0']:.1f}, {img['y0']:.1f} 위치에 그래프/도표가 있습니다.\"\n",
    "            image_descriptions.append(desc)\n",
    "    \n",
    "    # 프롬프트 구성\n",
    "    prompt = f\"\"\"\n",
    "다음은 발표 자료의 한 페이지 내용입니다. 이를 바탕으로 자연스러운 발표 대본을 작성해주세요.\n",
    "\n",
    "페이지 텍스트:\n",
    "{page_text}\n",
    "\n",
    "시각자료 정보:\n",
    "{' '.join(image_descriptions)}\n",
    "\n",
    "전체 발표 맥락을 고려하여, 청중이 이해하기 쉽게 설명하는 2-3문단 분량의 대본을 작성해주세요.\n",
    "\"\"\"\n",
    "\n",
    "    # LLM을 통한 대본 생성\n",
    "    response = llm.generate(prompt)\n",
    "    \n",
    "    return response.strip()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
