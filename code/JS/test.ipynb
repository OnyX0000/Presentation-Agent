{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1:\n",
      "Text: 딥러닝 기반 아동 미술 심리 진단 \n",
      "김지민, 박형빈, 정재식\n",
      "DeepPrint\n",
      "Team D.P.\n",
      "Wanted PotenUp\n",
      "3rd Project\n",
      "2025.03.05.\n",
      "--------------------------------------------------\n",
      "Page 2:\n",
      "Text: 오늘의 발표 내용은?\n",
      "01. 프로젝트 개요\n",
      "02. Project Flow\n",
      "03. 서비스 구현\n",
      "--------------------------------------------------\n",
      "Page 3:\n",
      "Text: HTP 검사란?\n",
      "주제 소개\n",
      "House(집), Tree(나무), Person(사람)의 세\n",
      "가지 그림을 그리게 하여 개인의 성격, 정서 상\n",
      "태, 대인 관계 등을 평가하는 투사적 심리 검사\n",
      "특히 아동 및 청소년의 심리 상태를 파악하거나,\n",
      "성인의 무의식적 감정과 스트레스를 이해하는\n",
      "데 유용하게 사용\n",
      "01. 프로젝트 개요\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HTP\n",
      "田田\n",
      "HTP\n",
      "--------------------------------------------------\n",
      "Page 4:\n",
      "Text: HTP 검사의 한계\n",
      "주제 선정 배경\n",
      "주관적 해석의 가능성\n",
      "표준화 부족\n",
      "문화적 차이\n",
      "피검사자의 의도적 왜곡\n",
      "기술적 한계\n",
      "01. 프로젝트 개요\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HTPTESTDRAWING\n",
      "AISGRXNONT\n",
      "田田\n",
      "HOUSE-TREE - PERSON\n",
      "--------------------------------------------------\n",
      "Page 5:\n",
      "Text: Project Work Flow\n",
      "학습 데이터 수집 및 정제\n",
      "1\n",
      "2\n",
      "3\n",
      "모델 학습 및 평가\n",
      "결과 해석\n",
      "AI Hub\n",
      ": AI 기반 아동 미술심리 진단을 위\n",
      "한 그림 데이터 구축\n",
      "Ultralytics YOLO\n",
      ": yolo11n, yolo11s, ...\n",
      "Detection 모델 활용\n",
      "02. Project Flow\n",
      "해석 가능한 요소\n",
      ": 그려진 그림 (탐지된 개체), 그림\n",
      "의 상대적 크기, 그림의 위치 등.\n",
      "--------------------------------------------------\n",
      "Page 6:\n",
      "Text: AI Hub 데이터\n",
      "학습 데이터 수집 (Image)\n",
      "AI 기반 아동 미술심리 진단을 위한 그림 데이터 구축\n",
      "다양한 연령대(7~13)와 성별의 아동 7,000명으로부터 수집한\n",
      "4개 HTP 분류(집, 나무, 여자사람, 남자사람) 그림\n",
      "심리 해석이 포함된 의료 데이터가 아닌 객체 인식을 위한 그림\n",
      "데이터\n",
      "각 HTP 분류 별 Train (11200개), Validation (1400개) 데\n",
      "이터를 포함하고 있고, Test 셋은 정책 상 다운로드 불가능.\n",
      "02. Project Flow\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "--------------------------------------------------\n",
      "Page 7:\n",
      "Text: 1. House (집)\n",
      "2. Tree (나무)\n",
      "3. Person\n",
      "(남자사람, 여자사람)\n",
      "총 15 가지\n",
      "['집전체', '지붕', '집벽', '문', '창문',\n",
      "'굴뚝', '연기', '울타리', '길', '연못',\n",
      "'산', '나무', '꽃', '잔디', '태양']\n",
      "총 14 가지\n",
      "['나무전체', '기둥', '수관', '가지', '뿌\n",
      "리', '나뭇잎', '꽃', '열매', '그네', '새',\n",
      "'다람쥐', '구름', '달', '별']\n",
      "총 18 가지\n",
      "['사람전체', '머리', '얼굴', '눈', '코',\n",
      "'입', '귀', '머리카락', '목', '상체', '팔',\n",
      "'손', '다리', '발', '단추', '주머니', '운동\n",
      "화', '남자구두/여자구두']\n",
      "02. Project Flow\n",
      "학습 데이터 수집 (Label)\n",
      "--------------------------------------------------\n",
      "Page 8:\n",
      "Text: 학습 데이터 정제 (JSON → Label)\n",
      "원본 (JSON)\n",
      "YOLO Format\n",
      "meta\n",
      "데이터 정보 (code, age, sex)\n",
      "annotations\n",
      "bbox (x, y, w, h)\n",
      "shape_description\n",
      "prop_obj_img \n",
      "prop_obj_cls\n",
      "02. Project Flow\n",
      "class_index\n",
      "xc = (x + w/2) / image_width\n",
      "yc = (y + h/2) / image_height\n",
      "width = w / image_width\n",
      "height = h / image_height\n",
      "--------------------------------------------------\n",
      "Page 9:\n",
      "Text: HTP 항목별 모델 구축\n",
      "YOLO11n  학습\n",
      "mAP (mean Average Precision)\n",
      "02. Project Flow\n",
      "모델 학습 및 평가\n",
      "--------------------------------------------------\n",
      "Page 10:\n",
      "Text: 평가 지표\n",
      "IoU가 0.5 이상일 때의 평균 정밀도(Average Precision, AP)를 계산한\n",
      "값이다.\n",
      "즉, 검출한 바운딩 박스가 실제 객체와 2/3 이상 겹치면 정답으로 간주하고\n",
      "계산한다.\n",
      "객체 검출 성능을 대략적으로 평가할 때 많이 사용된다\n",
      "IoU 임계값을 0.50에서 0.95까지 0.05 간격(0.50, 0.55, ..., 0.95) 으로\n",
      "변화시키면서 각각의 AP를 구하고, 그 평균을 낸 값이다.\n",
      "즉, mAP50(B), mAP55(B), ..., mAP95(B) 의 평균이 된다.\n",
      "높은 IoU 임계값(예: 0.90, 0.95)에서는 더 정확한 바운딩 박스를 요구하므\n",
      "로, 모델이 실제로 얼마나 정밀하게 검출하는지를 더 엄격하게 평가하는 지\n",
      "표이다.\n",
      "mAP50 (mean Average Precision)\n",
      "mAP50-95 (mean Average Precision)\n",
      "02. Project Flow\n",
      "IoU :  Intersection over Union\n",
      "=> 실제와 탐지 영역의 교집합 / 합집합\n",
      "--------------------------------------------------\n",
      "Page 11:\n",
      "Text: 성능 개선\n",
      "THEMA\n",
      "imgsz = 640,  epochs = 50\n",
      "mAP50(B)\n",
      "mAP50-95(B)\n",
      "Female\n",
      "0.975\n",
      "0.808\n",
      "Male\n",
      "0.974\n",
      "0.811\n",
      "House\n",
      "0.975\n",
      "0.884\n",
      "Tree\n",
      "0.973\n",
      "0.844\n",
      "THEMA\n",
      "imgsz = 1280,  epochs = 30\n",
      "mAP50(B)\n",
      "mAP50-95(B)\n",
      "Female\n",
      "0.991 (+0.016)\n",
      "0.864 (+0.056)\n",
      "Male\n",
      "0.991 (+0.017)\n",
      "0.862 (+0.051)\n",
      "House\n",
      "0.988 (+0.013)\n",
      "0.925 (+0.041)\n",
      "Tree\n",
      "0.983 (+0.010)\n",
      "0.874 (+0.030)\n",
      "02. Project Flow\n",
      "imgsz 640 → 1280으로 증가시켜 성능을 향상시킴\n",
      "epochs를 50 → 30으로 낮추어 학습속도를 향상시킴\n",
      "--------------------------------------------------\n",
      "Page 12:\n",
      "Text: 성능 개선\n",
      "02. Project Flow\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mountain 0.97\n",
      "House 0.96]\n",
      "Sun 0.97\n",
      "Wall 0.97\n",
      "Pond 0.98\n",
      "Winddw\n",
      "0.88\n",
      "Door 0.88\n",
      "ence0.5\n",
      "Fence 0.89\n",
      "-D-D-0-D0\n",
      "Tree0.97\n",
      "Flover 0.92\n",
      "Mountain 0.96\n",
      "House 0.967\n",
      "Grass\n",
      "Sun0.95\n",
      "Wall0.96\n",
      "Pond0.97\n",
      "Winddw\n",
      "0.87\n",
      "Door 0.93\n",
      "Gruss 0.87\n",
      "rass0.83\n",
      "ence\n",
      "0.95\n",
      "Fence 0.87\n",
      "Fence0.86\n",
      "Tree0.96\n",
      "Flolver 0.92\n",
      "--------------------------------------------------\n",
      "Page 13:\n",
      "Text: 특징 추출 및 해석\n",
      "결과 해석\n",
      "어떤 개체(클래스)가 그려졌는지\n",
      "몇 개나 그려졌는지\n",
      "전체 이미지 크기 대비 어느정도인지\n",
      "해당 개체가 오브젝트에서 어느정도 크기인지\n",
      "위 결과들을 해석하는 레퍼런스 탐색 및 구현\n",
      "02. Project Flow\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HONG NGT\n",
      "rCDIDTOGTG\n",
      "NOROO\n",
      "口\n",
      "门\n",
      "?\n",
      "HTP\n",
      "HTP\n",
      "HOUSE-TREE-PERSON\n",
      "-TEEEPLASCN\n",
      "DEMILED ANALYSIS\n",
      "p:\n",
      "mdrhn\n",
      "DTtoloto  e D s 1\n",
      "LJB\n",
      "Oronloy\n",
      "OVER\n",
      "OVERVIEW\n",
      "DETAILEDANALYSISDEATEDANALYSIS\n",
      "Beenem\n",
      "   \n",
      "ree beitmpto\n",
      "me\n",
      "c ae srsmg wrroanestrgarte\n",
      "te omp tro\n",
      "0 1 p0m 6\n",
      "DETALEDANALYSIS\n",
      "OCMNRGUNRROKT\n",
      "2\n",
      "?\n",
      "OVGERIFEIUW\n",
      "-COIPATELAKALYCITS\n",
      "COLPARATVE\n",
      "REPORT\n",
      "USERFEETBACK\n",
      "Lm10c001\n",
      "--------------------------------------------------\n",
      "Page 14:\n",
      "Text: 결과 해석 예시\n",
      "House (집)\n",
      "Male (남자사람)\n",
      "✔ 집전체에 대한 평가\n",
      "그림에서 집전체 의 위치가 하단에 치우쳐져 있다. 이는 우\n",
      "울, 자존감 문제, 정서불안, 열등감을 표현한 것으로 볼 수 있\n",
      "다.\n",
      "✔ 연기에 대한 평가\n",
      "그림에서 Smoke 의 존재 여부가 TRUE. 이는 우울, 자존감\n",
      "문제을 표현한 것으로 볼 수 있다.\n",
      "✔ 길에 대한 평가\n",
      "그림에서 Fence 의 존재 여부가 TRUE. 이는 사회불안,\n",
      "Avoidance, 자존감 문제, 정서불안, 열등감을 표현한 것으\n",
      "로 볼 수 있다.\n",
      "✔ 사람전체에 대한 평가\n",
      "그림에서 사람전체 의 위치가 하단에 치우쳐져 있다. 이는 사\n",
      "회 불안, 우울, 자존감 문제, 정서불안, 열등감을 표현한 것으로\n",
      "볼 수 있다.\n",
      "✔ 상체에 대한 평가\n",
      "현재 버전에서는 이 항목에 대한 평가 정보가 없습니다.\n",
      "✔ 단추에 대한 평가\n",
      "그림에서 Button 의 크기가 지나치게 크다. 이는 애정결핍,\n",
      "퇴행을 표현한 것으로 볼 수 있다.\n",
      "02. Project Flow\n",
      "--------------------------------------------------\n",
      "Page 15:\n",
      "Text: 기대 효과\n",
      "객관적이고 일관된 분석 가능\n",
      "자동화된 이미지 해석을 통한 시간 단축 \n",
      "데이터 기반 해석 가능\n",
      "전문가와 보완적인 역할 기대\n",
      "03. 서비스 구현\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HTP\n",
      "House-Tree-Person\n",
      "House\n",
      "Person\n",
      "A\n",
      "--------------------------------------------------\n",
      "Page 16:\n",
      "Text: YOLO 모델 \n",
      "HTP 검사 결과를 \n",
      "채점 기준별 점수화\n",
      "Gemini API 활용 과 RAG 적용\n",
      "03. 서비스 구현\n",
      "Gemini API \n",
      "점수화된 데이터를\n",
      "자연스럽고 \n",
      "이해하기 쉬운 \n",
      "문장으로 변환\n",
      "RAG 적용 \n",
      "더 신뢰도 높은 심리\n",
      "평가 문장 생성\n",
      "--------------------------------------------------\n",
      "Page 17:\n",
      "Text: 이미지 업로드 및  해석 화면\n",
      "03. 서비스 구현\n",
      "[페이지 진입 시 초기 화면]\n",
      "[테마 선택 → 이미지 업로드]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "?\n",
      "localhost:8501\n",
      "M Gmail Web DeepL :Aol..\n",
      "\"elohly alol pnis nxleea lool Axaldead 榮Id9ley \n",
      "Deploy\n",
      "DeePrint：AIHTP召人H|\n",
      "?\n",
      "localhost:8501\n",
      "M Gmail Web> DeepL e:AAol.\n",
      "\"elohlyi alolh Apnis nylelea lool Aixaldad 榮ldsieyp \n",
      "Deploy\n",
      "DeePrint：AIHTP召人人H|\n",
      "(jpg/jpeg/.png)\n",
      "Drag and drop file here\n",
      "Browsefiles\n",
      "Limit 200MB per file · JPG, PNG, JPEG\n",
      "--------------------------------------------------\n",
      "Page 18:\n",
      "Text: 이미지 업로드 및  해석 화면\n",
      "03. 서비스 구현\n",
      "[탐지 모드 설정]\n",
      "[선택 보기 → 탐색 객체 선택]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "?\n",
      "localhost:8501\n",
      "品丨M Gmail Web DeepL :4Ao\n",
      "\"elohly alol pnis nxleea lool Axaldead 榮Id9ley \n",
      "Deploy\n",
      "(jpg/jpeg /.png)\n",
      "Drag and drop file here\n",
      "Browse files\n",
      "Limit 200MB per file ·JPG, PNG, JPEG\n",
      "House_8_F_01855.jpg 87.3KB\n",
      "?\n",
      "localhost:8501\n",
      "K)\n",
      "品丨M Gmail Web DeepL :4Ao\n",
      "ChatGPTPerplexityTool Dataiku StudyO目 L\n",
      "Deploy\n",
      "(jpg /.jpeg/.png)\n",
      "Drag and drop file here\n",
      "Browse files\n",
      "Limit 200MB per file ·JPG, PNG, JPEG\n",
      "House_8_F_01855.jpg 87.3KB\n",
      "×\n",
      "×\n",
      "：[，，]\n",
      "--------------------------------------------------\n",
      "Page 19:\n",
      "Text: 이미지 업로드 및  해석 화면\n",
      "03. 서비스 구현\n",
      "[모두 보기 모드]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "app\n",
      "C\n",
      "?\n",
      "localhost:8501\n",
      "K)\n",
      "品\n",
      "\"elohlyb aloh Apnis nxleea lool Axaldlad 榮ld9ieyp \n",
      "“hh号北百化是最b1lo号YoA区\n",
      "“hh号北百化是最b1lo号YoAx\n",
      "-chineyTRUE，对量双\n",
      "SkeTRUE.，对\n",
      "F.，Avoace，\n",
      "F.ae，\n",
      "-对MountainTRUE.0是,Avoidance,对,是\n",
      "Hh\n",
      "TUE，vol是，\n",
      "“h号得亿百化lo号区\n",
      "--------------------------------------------------\n",
      "Page 20:\n",
      "Text: 이미지 업로드 및  해석 화면\n",
      "03. 서비스 구현\n",
      "[선택 모드]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "app\n",
      "C\n",
      "?\n",
      "localhost:8501\n",
      "K)\n",
      "品丨M Gmail Web DeepL :47o\n",
      "\"elohly aloh Apnis nxleea lool Axaldlad 榮ld9ieyp \n",
      "xxxxxx\n",
      "HRbORRA\n",
      "“h号8北百化Rh10lo号YoxR\n",
      "-对 Chmney难0早TRUE 0辛鲁,对香是对是是今双。\n",
      "S\n",
      "TRUE，,Avodnce\n",
      "h\n",
      "--------------------------------------------------\n",
      "Page 21:\n",
      "Text: 이미지 업로드 및  해석 화면\n",
      "03. 서비스 구현\n",
      "[전체 요약 보기]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "app\n",
      "/X\n",
      "Smart Switch1&人|\n",
      "?\n",
      "localhost:8501\n",
      "器丨M Gmail Web DeepL :A7\n",
      "ChatGPTPerplexity Tool Dataiku StudyO目 Lo\n",
      "Deploy\n",
      "Avoidance\n",
      "h百七Il0号Y-\n",
      "h百l0号Y-\n",
      "七品\n",
      "h百l0号Y\n",
      "--------------------------------------------------\n",
      "Page 22:\n",
      "Text: Q & A\n",
      "--------------------------------------------------\n",
      "Page 23:\n",
      "Text: 4월에 다시 만나요\n",
      "  다음 발표는?\n",
      "언제였지...?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "pdf_path = \"C:/wanted/Lang/Presentation-Agent/data/pdf/DeePrint.pdf\"\n",
    "\n",
    "loader = PyMuPDFLoader(pdf_path, extract_images=True)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서 정보 출력\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(f\"Page {idx + 1}:\")\n",
    "    print(\"Text:\", doc.page_content)  # 페이지의 텍스트 출력\n",
    "    if \"images\" in doc.metadata:\n",
    "        print(\"Images:\", doc.metadata[\"images\"])  # 이미지 정보 출력\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19036\\3440955430.py:42: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(\"이 문서를 기반으로 발표 대본을 작성해주세요.\")  # 문서 검색\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 발표 대본\n",
      "\n",
      "---\n",
      "\n",
      "#### 01. 프로젝트 개요\n",
      "\n",
      "안녕하세요, 오늘 발표할 주제는 HTP 검사와 그 한계에 대한 것입니다. HTP 검사는 개인의 심리적 상태를 이해하기 위한 도구로 널리 사용되고 있지만, 여러 가지 한계가 존재합니다. 오늘은 이 한계들을 살펴보고, 이를 해결하기 위한 방안을 모색해보겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 02. HTP 검사의 한계\n",
      "\n",
      "HTP 검사의 한계는 크게 다섯 가지로 나눌 수 있습니다. 첫 번째는 주관적 해석의 가능성입니다. 검사 결과는 해석자의 주관에 따라 달라질 수 있어, 일관된 결과를 도출하기 어렵습니다. 두 번째는 표준화 부족입니다. HTP 검사는 표준화된 절차가 부족하여, 다양한 환경에서 일관된 결과를 얻기 힘듭니다.\n",
      "\n",
      "세 번째는 문화적 차이입니다. HTP 검사는 문화적 배경에 따라 다르게 해석될 수 있어, 다양한 문화적 맥락을 고려하지 않으면 정확한 해석이 어렵습니다. 네 번째는 피검사자의 의도적 왜곡입니다. 피검사자가 자신의 의도를 숨기거나 왜곡할 경우, 검사 결과는 신뢰성을 잃게 됩니다. 마지막으로, 기술적 한계가 있습니다. 현재의 기술로는 HTP 검사의 모든 요소를 정확히 분석하기 어려운 점이 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 03. 주제 선정 배경\n",
      "\n",
      "이러한 한계를 바탕으로, 우리는 HTP 검사의 개선 방안을 모색하기 위해 이 주제를 선정하였습니다. 특히, 주관적 해석의 가능성을 줄이고, 표준화를 높이며, 문화적 차이를 고려한 새로운 접근법이 필요합니다. 또한, 피검사자의 의도적 왜곡을 방지할 수 있는 방법과 기술적 한계를 극복할 수 있는 방안도 함께 고민해야 합니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 04. 서비스 구현\n",
      "\n",
      "이제 우리는 이러한 한계를 극복하기 위한 서비스 구현 방안에 대해 논의하겠습니다. 이미지 업로드 및 해석 화면을 통해, 사용자가 자신의 그림을 업로드하고, AI 기반의 해석을 제공받는 시스템을 구축할 예정입니다. 이를 통해 주관적 해석의 가능성을 줄이고, 보다 객관적인 결과를 도출할 수 있을 것입니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 05. 전체 요약 보기\n",
      "\n",
      "마지막으로, 오늘 발표의 핵심 내용을 요약하겠습니다. HTP 검사는 유용한 도구이지만, 여러 가지 한계가 존재합니다. 이를 극복하기 위해서는 주관적 해석을 줄이고, 표준화된 절차를 마련하며, 문화적 차이를 고려해야 합니다. 또한, 피검사자의 의도적 왜곡을 방지하고, 기술적 한계를 극복하는 방안이 필요합니다. 이러한 방향으로 서비스 구현을 통해 HTP 검사의 신뢰성을 높일 수 있을 것입니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "--- \n",
      "\n",
      "이상으로 발표를 마치겠습니다. 질문이 있으시면 언제든지 해주시기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# PDF 파일 로드 및 페이지 분할\n",
    "loader = PyPDFLoader(\"C:/wanted/Lang/Presentation-Agent/data/pdf/DeePrint.pdf\")  # PDF 파일 경로 설정\n",
    "pages = loader.load_and_split()  # 페이지별로 텍스트 추출\n",
    "\n",
    "# **2. 벡터 스토어 생성**\n",
    "vectorstore = Chroma.from_documents(pages, embedding=OpenAIEmbeddings())  # 임베딩 생성 및 저장\n",
    "retriever = vectorstore.as_retriever()  # 검색기 생성\n",
    "\n",
    "# **3. 검색된 문서 데이터를 문자열로 변환하는 함수**\n",
    "def format_context(docs):\n",
    "    \"\"\"검색된 문서 리스트를 하나의 문자열로 병합\"\"\"\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# **4. 프롬프트 템플릿 정의**\n",
    "template = '''다음 컨텍스트를 기반으로 발표 대본을 작성하세요:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# **5. LLM 모델 초기화**\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# **6. RAG 체인 구성**\n",
    "rag_chain = (\n",
    "    {\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}  # 컨텍스트와 질문 연결\n",
    "    | prompt  # 프롬프트 적용\n",
    "    | model   # 언어 모델 실행\n",
    "    | StrOutputParser()  # 결과 파싱\n",
    ")\n",
    "\n",
    "# **7. 체인 실행**\n",
    "retrieved_docs = retriever.get_relevant_documents(\"이 문서를 기반으로 발표 대본을 작성해주세요.\")  # 문서 검색\n",
    "formatted_context = format_context(retrieved_docs)  # 검색된 문서를 문자열로 변환\n",
    "\n",
    "result = rag_chain.invoke({\n",
    "    \"context\": formatted_context,  # 문자열 형태의 context 전달\n",
    "    \"question\": \"페이지별로 발표 대본을 작성해주세요.\"\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19036\\953420499.py:32: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = model(formatted_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='### 발표 대본\\n\\n---\\n\\n#### 슬라이드 1: 제목 슬라이드\\n안녕하세요, 여러분. 오늘 저희는 \"딥러닝 기반 아동 미술 심리 진단\" 프로젝트에 대해 발표하겠습니다. 저는 김지민입니다. 함께 발표할 박형빈, 정재식입니다. 저희는 DeepPrintTeam D.P. Wanted PotenUp의 3rd Project로, 발표 날짜는 2025년 3월 5일입니다.\\n\\n---\\n\\n#### 슬라이드 2: 오늘의 발표 내용\\n오늘 발표할 내용은 크게 세 가지로 나뉩니다. 첫째, 프로젝트 개요에 대해 설명드리겠습니다. 둘째, Project Flow에 대해 말씀드리겠습니다. 마지막으로, 서비스 구현에 대해 자세히 설명하겠습니다.\\n\\n---\\n\\n#### 슬라이드 3: HTP 검사란?\\n먼저 HTP 검사에 대해 소개하겠습니다. HTP 검사는 House(집), Tree(나무), Person(사람)의 세 가지 그림을 그리게 하여 개인의 성격, 정서 상태, 대인 관계 등을 평가하는 투사적 심리 검사입니다. 이 검사는 특히 아동 및 청소년의 심리 상태를 파악하거나 성인의 무의식적 감정과 스트레스를 이해하는 데 유용합니다.\\n\\n---\\n\\n#### 슬라이드 4: HTP 검사의 한계\\n하지만 HTP 검사에는 몇 가지 한계가 있습니다. 첫째, 주관적 해석의 가능성이 있습니다. 둘째, 표준화가 부족합니다. 셋째, 문화적 차이가 존재합니다. 마지막으로, 피검사자의 의도적 왜곡과 기술적 한계가 있습니다.\\n\\n---\\n\\n#### 슬라이드 5: 프로젝트 개요\\n이러한 한계를 극복하기 위해 저희는 AI 기반 아동 미술 심리 진단 시스템을 개발하게 되었습니다. 이 시스템은 HTP 검사의 객관성을 높이고, 보다 정확한 심리 분석을 제공하는 것을 목표로 하고 있습니다.\\n\\n---\\n\\n#### 슬라이드 6: Project Work Flow\\n이제 Project Flow에 대해 설명드리겠습니다. 첫 번째 단계는 학습 데이터 수집 및 정제입니다. 두 번째 단계는 모델 학습 및 평가입니다. 마지막으로, 결과 해석 단계가 있습니다. 저희는 AI Hub와 Ultralytics YOLO를 활용하여 그림 데이터를 구축하고, 객체 인식 모델을 학습시켰습니다.\\n\\n---\\n\\n#### 슬라이드 7: 학습 데이터 수집\\n저희는 다양한 연령대와 성별의 아동 7,000명으로부터 HTP 분류에 해당하는 그림 데이터를 수집했습니다. 각 HTP 분류별로 Train, Validation, Test 셋을 구성하였습니다.\\n\\n---\\n\\n#### 슬라이드 8: 학습 데이터 정제\\n학습 데이터는 JSON 형식으로 수집되었으며, YOLO 포맷으로 변환하여 정제하였습니다. 이 과정에서 데이터 정보와 주석을 포함하여 모델 학습에 필요한 형식으로 변환하였습니다.\\n\\n---\\n\\n#### 슬라이드 9: HTP 항목별 모델 구축\\n각 HTP 항목별로 YOLO11n 모델을 학습시켰습니다. 이 과정에서 mAP(Mean Average Precision) 지표를 사용하여 모델의 성능을 평가하였습니다.\\n\\n---\\n\\n#### 슬라이드 10: 모델 학습 및 평가\\n모델의 성능을 평가하기 위해 IoU(Intersection over Union) 지표를 사용하였습니다. IoU가 0.5 이상일 때의 평균 정밀도를 계산하여 모델의 객체 검출 성능을 평가하였습니다.\\n\\n---\\n\\n#### 슬라이드 11: 성능 개선\\n모델의 성능을 개선하기 위해 이미지 크기를 640에서 1280으로 증가시키고, epochs를 50에서 30으로 줄여 학습 속도를 향상시켰습니다. 이로 인해 mAP 지표가 개선되었습니다.\\n\\n---\\n\\n#### 슬라이드 12: 특징 추출 및 해석\\n모델이 그려진 그림에서 어떤 개체가 그려졌는지, 몇 개나 그려졌는지, 전체 이미지 크기 대비 어느 정도인지 등을 해석하는 과정을 구현하였습니다.\\n\\n---\\n\\n#### 슬라이드 13: 결과 해석 예시\\n예를 들어, 남자아이가 그린 집 그림에서 집의 위치가 하단에 치우쳐져 있다면, 이는 우울감이나 자존감 문제를 나타낼 수 있습니다. 이러한 해석을 통해 아동의 심리 상태를 보다 명확히 이해할 수 있습니다.\\n\\n---\\n\\n#### 슬라이드 14: 기대 효과\\n이 시스템의 기대 효과는 객관적이고 일관된 분석이 가능하다는 점입니다. 또한, 자동화된 이미지 해석을 통해 시간 단축이 가능하며, 데이터 기반의 해석이 이루어질 수 있습니다.\\n\\n---\\n\\n#### 슬라이드 15: 서비스 구현\\n저희는 YOLO 모델을 활용하여 HTP 검사 결과를 채점 기준별로 점수화하였습니다. Gemini API를 활용하여 점수화된 데이터를 자연스럽고 이해하기 쉬운 문장으로 변환하였습니다.\\n\\n---\\n\\n#### 슬라이드 16: 이미지 업로드 및 해석 화면\\n서비스 구현 화면을 보여드리겠습니다. 사용자는 페이지에 진입하여 테마를 선택하고 이미지를 업로드한 후 해석 결과를 확인할 수 있습니다.\\n\\n---\\n\\n#### 슬라이드 17: 탐지 모드 설정\\n탐지 모드 설정 화면입니다. 사용자는 선택 보기에서 탐색 객체를 선택하여 보다 세부적인 해석을 받을 수 있습니다.\\n\\n---\\n\\n#### 슬라이드 18: 전체 요약 보기\\n마지막으로, 전체 요약 보기 화면입니다. 사용자는 모든 해석 결과를 한눈에 확인할 수 있습니다.\\n\\n---\\n\\n#### 슬라이드 19: Q & A\\n이상으로 저희 발표를 마치겠습니다. 질문이 있으시면 언제든지 해주시기 바랍니다. 4월에 다시 만나요. 다음 발표는 언제였지...?\\n\\n--- \\n\\n이상으로 발표 대본을 마치겠습니다. 감사합니다!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1302, 'prompt_tokens': 2005, 'total_tokens': 3307, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None} id='run-462e3e96-5260-4997-8a11-5ffe4569f82f-0' usage_metadata={'input_tokens': 2005, 'output_tokens': 1302, 'total_tokens': 3307, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# **1. PDF 텍스트 추출**\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"  # 각 페이지의 텍스트를 추가\n",
    "    return text.strip()\n",
    "\n",
    "# PDF 파일 경로 설정\n",
    "pdf_path = \"C:/wanted/Lang/Presentation-Agent/data/pdf/DeePrint.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# **2. 프롬프트 템플릿 정의**\n",
    "template = '''다음 PDF 내용을 기반으로 발표 대본을 작성하세요:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# **3. LLM 모델 초기화**\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# **4. 프롬프트 실행**\n",
    "question = \"페이지별로 발표 대본을 작성해주세요.\"\n",
    "formatted_prompt = prompt.format(context=pdf_text, question=question)\n",
    "\n",
    "result = model(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 발표 대본\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 1: 제목 슬라이드\n",
      "안녕하세요, 여러분. 오늘 저희는 \"딥러닝 기반 아동 미술 심리 진단\" 프로젝트에 대해 발표하겠습니다. 저는 김지민입니다. 함께 발표할 박형빈, 정재식입니다. 저희는 DeepPrintTeam D.P. Wanted PotenUp의 3rd Project로, 발표 날짜는 2025년 3월 5일입니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 2: 오늘의 발표 내용\n",
      "오늘 발표할 내용은 크게 세 가지로 나뉩니다. 첫째, 프로젝트 개요에 대해 설명드리겠습니다. 둘째, Project Flow에 대해 말씀드리겠습니다. 마지막으로, 서비스 구현에 대해 자세히 설명하겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 3: HTP 검사란?\n",
      "먼저 HTP 검사에 대해 소개하겠습니다. HTP 검사는 House(집), Tree(나무), Person(사람)의 세 가지 그림을 그리게 하여 개인의 성격, 정서 상태, 대인 관계 등을 평가하는 투사적 심리 검사입니다. 이 검사는 특히 아동 및 청소년의 심리 상태를 파악하거나 성인의 무의식적 감정과 스트레스를 이해하는 데 유용합니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 4: HTP 검사의 한계\n",
      "하지만 HTP 검사에는 몇 가지 한계가 있습니다. 첫째, 주관적 해석의 가능성이 있습니다. 둘째, 표준화가 부족합니다. 셋째, 문화적 차이가 존재합니다. 마지막으로, 피검사자의 의도적 왜곡과 기술적 한계가 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 5: 프로젝트 개요\n",
      "이러한 한계를 극복하기 위해 저희는 AI 기반 아동 미술 심리 진단 시스템을 개발하게 되었습니다. 이 시스템은 HTP 검사의 객관성을 높이고, 보다 정확한 심리 분석을 제공하는 것을 목표로 하고 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 6: Project Work Flow\n",
      "이제 Project Flow에 대해 설명드리겠습니다. 첫 번째 단계는 학습 데이터 수집 및 정제입니다. 두 번째 단계는 모델 학습 및 평가입니다. 마지막으로, 결과 해석 단계가 있습니다. 저희는 AI Hub와 Ultralytics YOLO를 활용하여 그림 데이터를 구축하고, 객체 인식 모델을 학습시켰습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 7: 학습 데이터 수집\n",
      "저희는 다양한 연령대와 성별의 아동 7,000명으로부터 HTP 분류에 해당하는 그림 데이터를 수집했습니다. 각 HTP 분류별로 Train, Validation, Test 셋을 구성하였습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 8: 학습 데이터 정제\n",
      "학습 데이터는 JSON 형식으로 수집되었으며, YOLO 포맷으로 변환하여 정제하였습니다. 이 과정에서 데이터 정보와 주석을 포함하여 모델 학습에 필요한 형식으로 변환하였습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 9: HTP 항목별 모델 구축\n",
      "각 HTP 항목별로 YOLO11n 모델을 학습시켰습니다. 이 과정에서 mAP(Mean Average Precision) 지표를 사용하여 모델의 성능을 평가하였습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 10: 모델 학습 및 평가\n",
      "모델의 성능을 평가하기 위해 IoU(Intersection over Union) 지표를 사용하였습니다. IoU가 0.5 이상일 때의 평균 정밀도를 계산하여 모델의 객체 검출 성능을 평가하였습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 11: 성능 개선\n",
      "모델의 성능을 개선하기 위해 이미지 크기를 640에서 1280으로 증가시키고, epochs를 50에서 30으로 줄여 학습 속도를 향상시켰습니다. 이로 인해 mAP 지표가 개선되었습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 12: 특징 추출 및 해석\n",
      "모델이 그려진 그림에서 어떤 개체가 그려졌는지, 몇 개나 그려졌는지, 전체 이미지 크기 대비 어느 정도인지 등을 해석하는 과정을 구현하였습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 13: 결과 해석 예시\n",
      "예를 들어, 남자아이가 그린 집 그림에서 집의 위치가 하단에 치우쳐져 있다면, 이는 우울감이나 자존감 문제를 나타낼 수 있습니다. 이러한 해석을 통해 아동의 심리 상태를 보다 명확히 이해할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 14: 기대 효과\n",
      "이 시스템의 기대 효과는 객관적이고 일관된 분석이 가능하다는 점입니다. 또한, 자동화된 이미지 해석을 통해 시간 단축이 가능하며, 데이터 기반의 해석이 이루어질 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 15: 서비스 구현\n",
      "저희는 YOLO 모델을 활용하여 HTP 검사 결과를 채점 기준별로 점수화하였습니다. Gemini API를 활용하여 점수화된 데이터를 자연스럽고 이해하기 쉬운 문장으로 변환하였습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 16: 이미지 업로드 및 해석 화면\n",
      "서비스 구현 화면을 보여드리겠습니다. 사용자는 페이지에 진입하여 테마를 선택하고 이미지를 업로드한 후 해석 결과를 확인할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 17: 탐지 모드 설정\n",
      "탐지 모드 설정 화면입니다. 사용자는 선택 보기에서 탐색 객체를 선택하여 보다 세부적인 해석을 받을 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 18: 전체 요약 보기\n",
      "마지막으로, 전체 요약 보기 화면입니다. 사용자는 모든 해석 결과를 한눈에 확인할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 슬라이드 19: Q & A\n",
      "이상으로 저희 발표를 마치겠습니다. 질문이 있으시면 언제든지 해주시기 바랍니다. 4월에 다시 만나요. 다음 발표는 언제였지...?\n",
      "\n",
      "--- \n",
      "\n",
      "이상으로 발표 대본을 마치겠습니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def time_convert(time_str):\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "def download_audio(url, save_dir, clip_idx, start=None, end=None):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 확장자 포함된 yt-dlp 저장용 임시 파일 경로\n",
    "    temp_template = os.path.join(save_dir, f\"cheo_temp_{clip_idx}.%(ext)s\")\n",
    "    temp_wav = os.path.join(save_dir, f\"cheo_temp_{clip_idx}.wav\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'outtmpl': temp_template,\n",
    "        'quiet': True,\n",
    "        'force_ipv4': True,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "\n",
    "    # 자르고 저장\n",
    "    audio = AudioSegment.from_file(temp_wav, format=\"wav\")\n",
    "    if start and end:\n",
    "        start_ms = time_convert(start) * 1000\n",
    "        end_ms = time_convert(end) * 1000\n",
    "        audio = audio[start_ms:end_ms]\n",
    "\n",
    "    # 최종 파일명: cheo_1.wav, cheo_2.wav ...\n",
    "    final_path = os.path.join(save_dir, f\"winter_{clip_idx}.wav\")\n",
    "    audio.export(final_path, format=\"wav\")\n",
    "\n",
    "    os.remove(temp_wav)\n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=4vS0Bhe5zjA\"\n",
    "save_dir = r\"C:\\wanted\\Lang\\Presentation-Agent\\data\\train_wav\"\n",
    "audio_data = []\n",
    "for i in range(5):\n",
    "    start = f\"{12+i}:00\"\n",
    "    end = f\"{12+i+1}:00\"\n",
    "    saved = download_audio(url, save_dir, clip_idx=i+1, start=start, end=end)\n",
    "    audio_data.append(saved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\wanted\\Lang\\lang\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zonos import 성공\n"
     ]
    }
   ],
   "source": [
    "from zonos.model import Zonos\n",
    "\n",
    "print(\"Zonos import 성공\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jɐ idʑe dwenjɐ ɐn dwenjɐ ']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\eSpeak NG\"\n",
    "os.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = r\"C:\\Program Files\\eSpeak NG\\espeak.dll\"\n",
    "\n",
    "from phonemizer.backend import EspeakBackend\n",
    "\n",
    "backend = EspeakBackend(language='ko')\n",
    "print(backend.phonemize([\"야 이제 되냐 안 되냐\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  14%|█▍        | 358/2588 [01:14<07:43,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔊 sample.wav 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "import torch._dynamo  # suppress warning if needed\n",
    "\n",
    "# ❗ phonemizer용 환경변수 설정 (espeak.dll 대응)\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\eSpeak NG\"\n",
    "os.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = r\"C:\\Program Files\\eSpeak NG\\espeak.dll\"\n",
    "\n",
    "# ❗ torch compile 비활성화 (C++ 컴파일러 없이 실행)\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "# 경로 설정\n",
    "path = r\"C:\\wanted\\Lang\\Presentation-Agent\\data\\train_wav\"\n",
    "\n",
    "# 모델 불러오기\n",
    "device = \"cuda\"  # 또는 \"cpu\"\n",
    "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
    "\n",
    "# 입력 음성 로드\n",
    "wav, sampling_rate = torchaudio.load(os.path.join(path, \"cheo_1.wav\"))\n",
    "\n",
    "# 스피커 임베딩 생성 (제로샷 보이스 클로닝)\n",
    "speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
    "\n",
    "# 텍스트와 스피커로 조건 딕셔너리 구성\n",
    "cond_dict = make_cond_dict(text=\"Project고 무엇이고 다 때려 쳐 버리고 싶다\", speaker=speaker, language=\"ko\")\n",
    "conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "# 음성 생성 (컴파일러 비활성화)\n",
    "codes = model.generate(conditioning, disable_torch_compile=True)\n",
    "wavs = model.autoencoder.decode(codes).cpu()\n",
    "\n",
    "# 결과 저장\n",
    "torchaudio.save(os.path.join(path, \"sample.wav\"), wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "print(\"🔊 sample.wav 생성 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "������ ��θ� ã�� �� �����ϴ�.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q kokoro>=0.9.2 soundfile\n",
    "# !apt-get -qq -y install espeak-ng > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\wanted\\Lang\\lang\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from kokoro import KPipeline\n",
    "from IPython.display import display, Audio\n",
    "import soundfile as sf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "('ko', {'a': 'American English', 'b': 'British English', 'e': 'es', 'f': 'fr-fr', 'h': 'hi', 'i': 'it', 'p': 'pt-br', 'j': 'Japanese', 'z': 'Mandarin Chinese'})",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 🇺🇸 'a' => 미국 영어, 🇬🇧 'b' => 영국 영어\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 🇯🇵 'j' => 일본어: pip install misaki[ja]\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 🇨🇳 'z' => 중국어(보통화): pip install misaki[zh]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pipeline = \u001b[43mKPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang_code\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mko\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <= lang_code가 목소리 언어와 일치하는지 확인할 것\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 이 텍스트는 데모용이며, 학습 중에는 사용되지 않았습니다\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\wanted\\Lang\\lang\\Lib\\site-packages\\kokoro\\pipeline.py:88\u001b[39m, in \u001b[36mKPipeline.__init__\u001b[39m\u001b[34m(self, lang_code, repo_id, model, trf, en_callable, device)\u001b[39m\n\u001b[32m     86\u001b[39m lang_code = lang_code.lower()\n\u001b[32m     87\u001b[39m lang_code = ALIASES.get(lang_code, lang_code)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m lang_code \u001b[38;5;129;01min\u001b[39;00m LANG_CODES, (lang_code, LANG_CODES)\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m.lang_code = lang_code\n\u001b[32m     90\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: ('ko', {'a': 'American English', 'b': 'British English', 'e': 'es', 'f': 'fr-fr', 'h': 'hi', 'i': 'it', 'p': 'pt-br', 'j': 'Japanese', 'z': 'Mandarin Chinese'})"
     ]
    }
   ],
   "source": [
    "# 🇺🇸 'a' => 미국 영어, 🇬🇧 'b' => 영국 영어\n",
    "# 🇯🇵 'j' => 일본어: pip install misaki[ja]\n",
    "# 🇨🇳 'z' => 중국어(보통화): pip install misaki[zh]\n",
    "pipeline = KPipeline(lang_code='ko') # <= lang_code가 목소리 언어와 일치하는지 확인할 것\n",
    "\n",
    "# 이 텍스트는 데모용이며, 학습 중에는 사용되지 않았습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
